{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api': '1.0', 'billed_pages': 30, 'elements': [{'bounding_box': [{'x': 305, 'y': 679}, {'x': 788, 'y': 679}, {'x': 788, 'y': 773}, {'x': 305, 'y': 773}], 'category': 'paragraph', 'html': \"<p id='0' style='font-size:20px'>Chapter 1</p>\", 'id': 0, 'page': 1, 'text': 'Chapter 1'}, {'bounding_box': [{'x': 304, 'y': 933}, {'x': 1017, 'y': 933}, {'x': 1017, 'y': 1036}, {'x': 304, 'y': 1036}], 'category': 'paragraph', 'html': \"<p id='1' style='font-size:22px'>Introduction</p>\", 'id': 1, 'page': 1, 'text': 'Introduction'}, {'bounding_box': [{'x': 303, 'y': 1260}, {'x': 2239, 'y': 1260}, {'x': 2239, 'y': 1588}, {'x': 303, 'y': 1588}], 'category': 'paragraph', 'html': \"<p id='2' style='font-size:18px'>Inventors have long dreamed of creating machines that think. This desire dates<br>back to at least the time of ancient Greece. The mythical figures Pygmalion,<br>Daedalus, and Hephaestus may all be interpreted as legendary inventors, and<br>Galatea, Talos, and Pandora may all be regarded as artificial life (Ovid and Martin,<br>2004; Sparkes, 1996; Tandy, 1997).</p>\", 'id': 2, 'page': 1, 'text': 'Inventors have long dreamed of creating machines that think. This desire dates\\nback to at least the time of ancient Greece. The mythical figures Pygmalion,\\nDaedalus, and Hephaestus may all be interpreted as legendary inventors, and\\nGalatea, Talos, and Pandora may all be regarded as artificial life (Ovid and Martin,\\n2004; Sparkes, 1996; Tandy, 1997).'}, {'bounding_box': [{'x': 303, 'y': 1617}, {'x': 2239, 'y': 1617}, {'x': 2239, 'y': 2016}, {'x': 303, 'y': 2016}], 'category': 'paragraph', 'html': \"<p id='3' style='font-size:14px'>When programmable computers were first conceived, people wondered whether<br>they might become intelligent, over a hundred years before one was built (Lovelace,<br>1842). Today, artificial intelligence (AI) is a thriving field with many practical<br>applications and active research topics. We look to intelligent software to automate<br>routine labor, understand speech or images, make diagnoses in medicine and<br>support basic scientific research.</p>\", 'id': 3, 'page': 1, 'text': 'When programmable computers were first conceived, people wondered whether\\nthey might become intelligent, over a hundred years before one was built (Lovelace,\\n1842). Today, artificial intelligence (AI) is a thriving field with many practical\\napplications and active research topics. We look to intelligent software to automate\\nroutine labor, understand speech or images, make diagnoses in medicine and\\nsupport basic scientific research.'}, {'bounding_box': [{'x': 303, 'y': 2041}, {'x': 2239, 'y': 2041}, {'x': 2239, 'y': 2507}, {'x': 303, 'y': 2507}], 'category': 'paragraph', 'html': \"<br><p id='4' style='font-size:16px'>In the early days of artificial intelligence, the field rapidly tackled and solved<br>problems that are intellectually difficult for human beings but relatively straight-<br>forward for computers problems that can be described by a list of formal, math-<br>ematical rules. The true challenge to artificial intelligence proved to be solving<br>the tasks that are easy for people to perform but hard for people to describe<br>formally problems that we solve intuitively, that feel automatic, like recognizing<br>spoken words or faces in images.</p>\", 'id': 4, 'page': 1, 'text': 'In the early days of artificial intelligence, the field rapidly tackled and solved\\nproblems that are intellectually difficult for human beings but relatively straight-\\nforward for computers problems that can be described by a list of formal, math-\\nematical rules. The true challenge to artificial intelligence proved to be solving\\nthe tasks that are easy for people to perform but hard for people to describe\\nformally problems that we solve intuitively, that feel automatic, like recognizing\\nspoken words or faces in images.'}, {'bounding_box': [{'x': 302, 'y': 2537}, {'x': 2238, 'y': 2537}, {'x': 2238, 'y': 2999}, {'x': 302, 'y': 2999}], 'category': 'paragraph', 'html': \"<p id='5' style='font-size:14px'>This book is about a solution to these more intuitive problems. This solution is<br>to allow computers to learn from experience and understand the world in terms of a<br>hierarchy of concepts, with each concept defined in terms of its relation to simpler<br>concepts. By gathering knowledge from experience, this approach avoids the need<br>for human operators to formally specify all of the knowledge that the computer<br>needs. The hierarchy of concepts allows the computer to learn complicated concepts<br>by building them out of simpler ones. If we draw a graph showing how these</p>\", 'id': 5, 'page': 1, 'text': 'This book is about a solution to these more intuitive problems. This solution is\\nto allow computers to learn from experience and understand the world in terms of a\\nhierarchy of concepts, with each concept defined in terms of its relation to simpler\\nconcepts. By gathering knowledge from experience, this approach avoids the need\\nfor human operators to formally specify all of the knowledge that the computer\\nneeds. The hierarchy of concepts allows the computer to learn complicated concepts\\nby building them out of simpler ones. If we draw a graph showing how these'}, {'bounding_box': [{'x': 1252, 'y': 3036}, {'x': 1279, 'y': 3036}, {'x': 1279, 'y': 3081}, {'x': 1252, 'y': 3081}], 'category': 'footer', 'html': \"<footer id='6' style='font-size:14px'>1</footer>\", 'id': 6, 'page': 1, 'text': '1'}, {'bounding_box': [{'x': 295, 'y': 121}, {'x': 997, 'y': 121}, {'x': 997, 'y': 170}, {'x': 295, 'y': 170}], 'category': 'header', 'html': \"<header id='7' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 7, 'page': 2, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 299, 'y': 314}, {'x': 2242, 'y': 314}, {'x': 2242, 'y': 441}, {'x': 299, 'y': 441}], 'category': 'paragraph', 'html': \"<p id='8' style='font-size:18px'>concepts are built on top of each other, the graph is deep, with many layers. For<br>this reason, we call this approach to AI deep learning.</p>\", 'id': 8, 'page': 2, 'text': 'concepts are built on top of each other, the graph is deep, with many layers. For\\nthis reason, we call this approach to AI deep learning.'}, {'bounding_box': [{'x': 299, 'y': 464}, {'x': 2244, 'y': 464}, {'x': 2244, 'y': 1138}, {'x': 299, 'y': 1138}], 'category': 'paragraph', 'html': \"<br><p id='9' style='font-size:20px'>Many of the early successes of AI took place in relatively sterile and formal<br>environments and did not require computers to have much knowledge about<br>the world. For example, IBM's Deep Blue chess-playing system defeated world<br>champion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simple<br>world, containing only sixty-four locations and thirty-two pieces that can move<br>in only rigidly circumscribed ways. Devising a successful chess strategy is a<br>tremendous accomplishment, but the challenge is not due to the difficulty of<br>describing the set of chess pieces and allowable moves to the computer. Chess<br>can be completely described by a very brief list of completely formal rules, easily<br>provided ahead of time by the programmer.</p>\", 'id': 9, 'page': 2, 'text': \"Many of the early successes of AI took place in relatively sterile and formal\\nenvironments and did not require computers to have much knowledge about\\nthe world. For example, IBM's Deep Blue chess-playing system defeated world\\nchampion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simple\\nworld, containing only sixty-four locations and thirty-two pieces that can move\\nin only rigidly circumscribed ways. Devising a successful chess strategy is a\\ntremendous accomplishment, but the challenge is not due to the difficulty of\\ndescribing the set of chess pieces and allowable moves to the computer. Chess\\ncan be completely described by a very brief list of completely formal rules, easily\\nprovided ahead of time by the programmer.\"}, {'bounding_box': [{'x': 300, 'y': 1161}, {'x': 2244, 'y': 1161}, {'x': 2244, 'y': 1767}, {'x': 300, 'y': 1767}], 'category': 'paragraph', 'html': \"<br><p id='10' style='font-size:18px'>Ironically, abstract and formal tasks that are among the most difficult mental<br>undertakings for a human being are among the easiest for a computer. Computers<br>have long been able to defeat even the best human chess player, but are only<br>recently matching some of the abilities of average human beings to recognize objects<br>or speech. A person's everyday life requires an immense amount of knowledge<br>about the world. Much of this knowledge is subjective and intuitive, and therefore<br>difficult to articulate in a formal way. Computers need to capture this same<br>knowledge in order to behave in an intelligent way. One of the key challenges in<br>artificial intelligence is how to get this informal knowledge into a computer.</p>\", 'id': 10, 'page': 2, 'text': \"Ironically, abstract and formal tasks that are among the most difficult mental\\nundertakings for a human being are among the easiest for a computer. Computers\\nhave long been able to defeat even the best human chess player, but are only\\nrecently matching some of the abilities of average human beings to recognize objects\\nor speech. A person's everyday life requires an immense amount of knowledge\\nabout the world. Much of this knowledge is subjective and intuitive, and therefore\\ndifficult to articulate in a formal way. Computers need to capture this same\\nknowledge in order to behave in an intelligent way. One of the key challenges in\\nartificial intelligence is how to get this informal knowledge into a computer.\"}, {'bounding_box': [{'x': 300, 'y': 1793}, {'x': 2245, 'y': 1793}, {'x': 2245, 'y': 2735}, {'x': 300, 'y': 2735}], 'category': 'paragraph', 'html': '<br><p id=\\'11\\' style=\\'font-size:18px\\'>Several artificial intelligence projects have sought to hard-code knowledge about<br>the world in formal languages. A computer can reason about statements in these<br>formal languages automatically using logical inference rules. This is known as the<br>knowledge base approach to artificial intelligence. None of these projects has led to<br>a major success. One of the most famous such projects is Cyc (Lenat and Guha,<br>1989). Cyc is an inference engine and a database of statements in a language<br>called CycL. These statements are entered by a staff of human supervisors. It is an<br>unwieldy process. People struggle to devise formal rules with enough complexity<br>to accurately describe the world. For example, Cyc failed to understand a story<br>about a person named Fred shaving in the morning (Linde, 1992). Its inference<br>engine detected an inconsistency in the story: it knew that people do not have<br>electrical parts, but because Fred was holding an electric razor, it believed the<br>entity \"FredWhileShaving\" contained electrical parts. It therefore asked whether<br>Fred was still a person while he was shaving.</p>', 'id': 11, 'page': 2, 'text': 'Several artificial intelligence projects have sought to hard-code knowledge about\\nthe world in formal languages. A computer can reason about statements in these\\nformal languages automatically using logical inference rules. This is known as the\\nknowledge base approach to artificial intelligence. None of these projects has led to\\na major success. One of the most famous such projects is Cyc (Lenat and Guha,\\n1989). Cyc is an inference engine and a database of statements in a language\\ncalled CycL. These statements are entered by a staff of human supervisors. It is an\\nunwieldy process. People struggle to devise formal rules with enough complexity\\nto accurately describe the world. For example, Cyc failed to understand a story\\nabout a person named Fred shaving in the morning (Linde, 1992). Its inference\\nengine detected an inconsistency in the story: it knew that people do not have\\nelectrical parts, but because Fred was holding an electric razor, it believed the\\nentity \"FredWhileShaving\" contained electrical parts. It therefore asked whether\\nFred was still a person while he was shaving.'}, {'bounding_box': [{'x': 296, 'y': 2760}, {'x': 2245, 'y': 2760}, {'x': 2245, 'y': 2956}, {'x': 296, 'y': 2956}], 'category': 'paragraph', 'html': \"<br><p id='12' style='font-size:18px'>The difficulties faced by systems relying on hard-coded knowledge suggest that<br>AI systems need the ability to acquire their own knowledge, by extracting patterns<br>from raw data. This capability is known as machine learning. The introduction</p>\", 'id': 12, 'page': 2, 'text': 'The difficulties faced by systems relying on hard-coded knowledge suggest that\\nAI systems need the ability to acquire their own knowledge, by extracting patterns\\nfrom raw data. This capability is known as machine learning. The introduction'}, {'bounding_box': [{'x': 1251, 'y': 3039}, {'x': 1278, 'y': 3039}, {'x': 1278, 'y': 3082}, {'x': 1251, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='13' style='font-size:14px'>2</footer>\", 'id': 13, 'page': 2, 'text': '2'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='14' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 14, 'page': 3, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 300, 'y': 312}, {'x': 2244, 'y': 312}, {'x': 2244, 'y': 645}, {'x': 300, 'y': 645}], 'category': 'paragraph', 'html': \"<p id='15' style='font-size:22px'>of machine learning allowed computers to tackle problems involving knowledge<br>of the real world and make decisions that appear subjective. A simple machine<br>learning algorithm called logistic regression can determine whether to recommend<br>cesarean delivery (Mor- Yosef et al., 1990). A simple machine learning algorithm<br>called naive Bayes can separate legitimate e-mail from spam e-mail.</p>\", 'id': 15, 'page': 3, 'text': 'of machine learning allowed computers to tackle problems involving knowledge\\nof the real world and make decisions that appear subjective. A simple machine\\nlearning algorithm called logistic regression can determine whether to recommend\\ncesarean delivery (Mor- Yosef et al., 1990). A simple machine learning algorithm\\ncalled naive Bayes can separate legitimate e-mail from spam e-mail.'}, {'bounding_box': [{'x': 300, 'y': 669}, {'x': 2245, 'y': 669}, {'x': 2245, 'y': 1478}, {'x': 300, 'y': 1478}], 'category': 'paragraph', 'html': \"<br><p id='16' style='font-size:20px'>The performance of these simple machine learning algorithms depends heavily<br>on the representation of the data they are given. For example, when logistic<br>regression is used to recommend cesarean delivery, the AI system does not examine<br>the patient directly. Instead, the doctor tells the system several pieces of relevant<br>information, such as the presence or absence of a uterine scar. Each piece of<br>information included in the representation of the patient is known as a feature.<br>Logistic regression learns how each of these features of the patient correlates with<br>various outcomes. However, it cannot influence the way that the features are<br>defined in any way. If logistic regression was given an MRI scan of the patient,<br>rather than the doctor's formalized report, it would not be able to make useful<br>predictions. Individual pixels in an MRI scan have negligible correlation with any<br>complications that might occur during delivery.</p>\", 'id': 16, 'page': 3, 'text': \"The performance of these simple machine learning algorithms depends heavily\\non the representation of the data they are given. For example, when logistic\\nregression is used to recommend cesarean delivery, the AI system does not examine\\nthe patient directly. Instead, the doctor tells the system several pieces of relevant\\ninformation, such as the presence or absence of a uterine scar. Each piece of\\ninformation included in the representation of the patient is known as a feature.\\nLogistic regression learns how each of these features of the patient correlates with\\nvarious outcomes. However, it cannot influence the way that the features are\\ndefined in any way. If logistic regression was given an MRI scan of the patient,\\nrather than the doctor's formalized report, it would not be able to make useful\\npredictions. Individual pixels in an MRI scan have negligible correlation with any\\ncomplications that might occur during delivery.\"}, {'bounding_box': [{'x': 299, 'y': 1504}, {'x': 2245, 'y': 1504}, {'x': 2245, 'y': 2038}, {'x': 299, 'y': 2038}], 'category': 'paragraph', 'html': \"<br><p id='17' style='font-size:18px'>This dependence on representations is a general phenomenon that appears<br>throughout computer science and even daily life. In computer science, opera-<br>tions such as searching a collection of data can proceed exponentially faster if<br>the collection is structured and indexed intelligently. People can easily perform<br>arithmetic on Arabic numerals, but find arithmetic on Roman numerals much<br>more time-consuming. It is not surprising that the choice of representation has an<br>enormous effect on the performance of machine learning algorithms. For a simple<br>visual example, see Fig. 1.1.</p>\", 'id': 17, 'page': 3, 'text': 'This dependence on representations is a general phenomenon that appears\\nthroughout computer science and even daily life. In computer science, opera-\\ntions such as searching a collection of data can proceed exponentially faster if\\nthe collection is structured and indexed intelligently. People can easily perform\\narithmetic on Arabic numerals, but find arithmetic on Roman numerals much\\nmore time-consuming. It is not surprising that the choice of representation has an\\nenormous effect on the performance of machine learning algorithms. For a simple\\nvisual example, see Fig. 1.1.'}, {'bounding_box': [{'x': 299, 'y': 2064}, {'x': 2245, 'y': 2064}, {'x': 2245, 'y': 2394}, {'x': 299, 'y': 2394}], 'category': 'paragraph', 'html': \"<br><p id='18' style='font-size:20px'>Many artificial intelligence tasks can be solved by designing the right set of<br>features to extract for that task, then providing these features to a simple machine<br>learning algorithm. For example, a useful feature for speaker identification from<br>sound is an estimate of the size of speaker's vocal tract. It therefore gives a strong<br>clue as to whether the speaker is a man, woman, or child.</p>\", 'id': 18, 'page': 3, 'text': \"Many artificial intelligence tasks can be solved by designing the right set of\\nfeatures to extract for that task, then providing these features to a simple machine\\nlearning algorithm. For example, a useful feature for speaker identification from\\nsound is an estimate of the size of speaker's vocal tract. It therefore gives a strong\\nclue as to whether the speaker is a man, woman, or child.\"}, {'bounding_box': [{'x': 297, 'y': 2421}, {'x': 2245, 'y': 2421}, {'x': 2245, 'y': 2955}, {'x': 297, 'y': 2955}], 'category': 'paragraph', 'html': \"<br><p id='19' style='font-size:18px'>However, for many tasks, it is difficult to know what features should be extracted.<br>For example, suppose that we would like to write a program to detect cars in<br>photographs. We know that cars have wheels, SO we might like to use the presence<br>of a wheel as a feature. Unfortunately, it is difficult to describe exactly what a<br>wheel looks like in terms of pixel values. A wheel has a simple geometric shape but<br>its image may be complicated by shadows falling on the wheel, the sun glaring off<br>the metal parts of the wheel, the fender of the car or an object in the foreground<br>obscuring part of the wheel, and SO on.</p>\", 'id': 19, 'page': 3, 'text': 'However, for many tasks, it is difficult to know what features should be extracted.\\nFor example, suppose that we would like to write a program to detect cars in\\nphotographs. We know that cars have wheels, SO we might like to use the presence\\nof a wheel as a feature. Unfortunately, it is difficult to describe exactly what a\\nwheel looks like in terms of pixel values. A wheel has a simple geometric shape but\\nits image may be complicated by shadows falling on the wheel, the sun glaring off\\nthe metal parts of the wheel, the fender of the car or an object in the foreground\\nobscuring part of the wheel, and SO on.'}, {'bounding_box': [{'x': 1250, 'y': 3040}, {'x': 1277, 'y': 3040}, {'x': 1277, 'y': 3083}, {'x': 1250, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='20' style='font-size:14px'>3</footer>\", 'id': 20, 'page': 3, 'text': '3'}, {'bounding_box': [{'x': 295, 'y': 122}, {'x': 996, 'y': 122}, {'x': 996, 'y': 170}, {'x': 295, 'y': 170}], 'category': 'header', 'html': \"<header id='21' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 21, 'page': 4, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 608, 'y': 311}, {'x': 1905, 'y': 311}, {'x': 1905, 'y': 1064}, {'x': 608, 'y': 1064}], 'category': 'figure', 'html': '<figure><img id=\\'22\\' style=\\'font-size:18px\\' alt=\"Cartesian coordinates Polar coordinates\" data-coord=\"top-left:(608,311); bottom-right:(1905,1064)\" /></figure>', 'id': 22, 'page': 4, 'text': 'Cartesian coordinates Polar coordinates'}, {'bounding_box': [{'x': 296, 'y': 1137}, {'x': 2250, 'y': 1137}, {'x': 2250, 'y': 1432}, {'x': 296, 'y': 1432}], 'category': 'caption', 'html': \"<caption id='23' style='font-size:16px'>Figure 1.1: Example of different representations: suppose we want to separate two<br>categories of data by drawing a line between them in a scatterplot. In the plot on the left,<br>we represent some data using Cartesian coordinates, and the task is impossible. In the plot<br>on the right, we represent the data with polar coordinates and the task becomes simple to<br>solve with a vertical line. (Figure produced in collaboration with David Warde-Farley)</caption>\", 'id': 23, 'page': 4, 'text': 'Figure 1.1: Example of different representations: suppose we want to separate two\\ncategories of data by drawing a line between them in a scatterplot. In the plot on the left,\\nwe represent some data using Cartesian coordinates, and the task is impossible. In the plot\\non the right, we represent the data with polar coordinates and the task becomes simple to\\nsolve with a vertical line. (Figure produced in collaboration with David Warde-Farley)'}, {'bounding_box': [{'x': 298, 'y': 1548}, {'x': 2242, 'y': 1548}, {'x': 2242, 'y': 2150}, {'x': 298, 'y': 2150}], 'category': 'paragraph', 'html': \"<p id='24' style='font-size:20px'>One solution to this problem is to use machine learning to discover not only<br>the mapping from representation to output but also the representation itself.<br>This approach is known as representation learning. Learned representations often<br>result in much better performance than can be obtained with hand-designed<br>representations. They also allow AI systems to rapidly adapt to new tasks, with<br>minimal human intervention. A representation learning algorithm can discover a<br>good set of features for a simple task in minutes, or a complex task in hours to<br>months. Manually designing features for a complex task requires a great deal of<br>human time and effort; it can take decades for an entire community of researchers.</p>\", 'id': 24, 'page': 4, 'text': 'One solution to this problem is to use machine learning to discover not only\\nthe mapping from representation to output but also the representation itself.\\nThis approach is known as representation learning. Learned representations often\\nresult in much better performance than can be obtained with hand-designed\\nrepresentations. They also allow AI systems to rapidly adapt to new tasks, with\\nminimal human intervention. A representation learning algorithm can discover a\\ngood set of features for a simple task in minutes, or a complex task in hours to\\nmonths. Manually designing features for a complex task requires a great deal of\\nhuman time and effort; it can take decades for an entire community of researchers.'}, {'bounding_box': [{'x': 297, 'y': 2176}, {'x': 2241, 'y': 2176}, {'x': 2241, 'y': 2711}, {'x': 297, 'y': 2711}], 'category': 'paragraph', 'html': \"<br><p id='25' style='font-size:18px'>The quintessential example of a representation learning algorithm is the au-<br>toencoder. An autoencoder is the combination of an encoder function that converts<br>the input data into a different representation, and a decoder function that converts<br>the new representation back into the original format. Autoencoders are trained to<br>preserve as much information as possible when an input is run through the encoder<br>and then the decoder, but are also trained to make the new representation have<br>various nice properties. Different kinds of autoencoders aim to achieve different<br>kinds of properties.</p>\", 'id': 25, 'page': 4, 'text': 'The quintessential example of a representation learning algorithm is the au-\\ntoencoder. An autoencoder is the combination of an encoder function that converts\\nthe input data into a different representation, and a decoder function that converts\\nthe new representation back into the original format. Autoencoders are trained to\\npreserve as much information as possible when an input is run through the encoder\\nand then the decoder, but are also trained to make the new representation have\\nvarious nice properties. Different kinds of autoencoders aim to achieve different\\nkinds of properties.'}, {'bounding_box': [{'x': 298, 'y': 2737}, {'x': 2241, 'y': 2737}, {'x': 2241, 'y': 2999}, {'x': 298, 'y': 2999}], 'category': 'paragraph', 'html': '<br><p id=\\'26\\' style=\\'font-size:22px\\'>When designing features or algorithms for learning features, our goal is usually<br>to separate the factors of variation that explain the observed data. In this context,<br>we use the word \"factors\" simply to refer to separate sources of influence; the factors<br>are usually not combined by multiplication. Such factors are often not quantities</p>', 'id': 26, 'page': 4, 'text': 'When designing features or algorithms for learning features, our goal is usually\\nto separate the factors of variation that explain the observed data. In this context,\\nwe use the word \"factors\" simply to refer to separate sources of influence; the factors\\nare usually not combined by multiplication. Such factors are often not quantities'}, {'bounding_box': [{'x': 1252, 'y': 3043}, {'x': 1278, 'y': 3043}, {'x': 1278, 'y': 3084}, {'x': 1252, 'y': 3084}], 'category': 'footer', 'html': \"<footer id='27' style='font-size:14px'>4</footer>\", 'id': 27, 'page': 4, 'text': '4'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='28' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 28, 'page': 5, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 299, 'y': 313}, {'x': 2244, 'y': 313}, {'x': 2244, 'y': 915}, {'x': 299, 'y': 915}], 'category': 'paragraph', 'html': \"<p id='29' style='font-size:18px'>that are directly observed. Instead, they may exist either as unobserved objects<br>or unobserved forces in the physical world that affect observable quantities. They<br>may also exist as constructs in the human mind that provide useful simplifying<br>explanations or inferred causes of the observed data. They can be thought of as<br>concepts or abstractions that help us make sense of the rich variability in the data.<br>When analyzing a speech recording, the factors of variation include the speaker's<br>age, their sex, their accent and the words that they are speaking. When analyzing<br>an image of a car, the factors of variation include the position of the car, its color,<br>and the angle and brightness of the sun.</p>\", 'id': 29, 'page': 5, 'text': \"that are directly observed. Instead, they may exist either as unobserved objects\\nor unobserved forces in the physical world that affect observable quantities. They\\nmay also exist as constructs in the human mind that provide useful simplifying\\nexplanations or inferred causes of the observed data. They can be thought of as\\nconcepts or abstractions that help us make sense of the rich variability in the data.\\nWhen analyzing a speech recording, the factors of variation include the speaker's\\nage, their sex, their accent and the words that they are speaking. When analyzing\\nan image of a car, the factors of variation include the position of the car, its color,\\nand the angle and brightness of the sun.\"}, {'bounding_box': [{'x': 300, 'y': 943}, {'x': 2245, 'y': 943}, {'x': 2245, 'y': 1340}, {'x': 300, 'y': 1340}], 'category': 'paragraph', 'html': \"<p id='30' style='font-size:18px'>A major source of difficulty in many real-world artificial intelligence applications<br>is that many of the factors of variation influence every single piece of data we are<br>able to observe. The individual pixels in an image of a red car might be very close<br>to black at night. The shape of the car's silhouette depends on the viewing angle.<br>Most applications require us to disentangle the factors of variation and discard the<br>ones that we do not care about.</p>\", 'id': 30, 'page': 5, 'text': \"A major source of difficulty in many real-world artificial intelligence applications\\nis that many of the factors of variation influence every single piece of data we are\\nable to observe. The individual pixels in an image of a red car might be very close\\nto black at night. The shape of the car's silhouette depends on the viewing angle.\\nMost applications require us to disentangle the factors of variation and discard the\\nones that we do not care about.\"}, {'bounding_box': [{'x': 300, 'y': 1368}, {'x': 2244, 'y': 1368}, {'x': 2244, 'y': 1699}, {'x': 300, 'y': 1699}], 'category': 'paragraph', 'html': \"<br><p id='31' style='font-size:18px'>Of course, it can be very difficult to extract such high-level, abstract features<br>from raw data. Many of these factors of variation, such as a speaker's accent,<br>can be identified only using sophisticated, nearly human-level understanding of<br>the data. When it is nearly as difficult to obtain a representation as to solve the<br>original problem, representation learning does not, at first glance, seem to help us.</p>\", 'id': 31, 'page': 5, 'text': \"Of course, it can be very difficult to extract such high-level, abstract features\\nfrom raw data. Many of these factors of variation, such as a speaker's accent,\\ncan be identified only using sophisticated, nearly human-level understanding of\\nthe data. When it is nearly as difficult to obtain a representation as to solve the\\noriginal problem, representation learning does not, at first glance, seem to help us.\"}, {'bounding_box': [{'x': 299, 'y': 1723}, {'x': 2244, 'y': 1723}, {'x': 2244, 'y': 2123}, {'x': 299, 'y': 2123}], 'category': 'paragraph', 'html': \"<br><p id='32' style='font-size:20px'>Deep learning solves this central problem in representation learning by introduc-<br>ing representations that are expressed in terms of other, simpler representations.<br>Deep learning allows the computer to build complex concepts out of simpler con-<br>cepts. Fig. 1.2 shows how a deep learning system can represent the concept of an<br>image of a person by combining simpler concepts, such as corners and contours,<br>which are in turn defined in terms of edges.</p>\", 'id': 32, 'page': 5, 'text': 'Deep learning solves this central problem in representation learning by introduc-\\ning representations that are expressed in terms of other, simpler representations.\\nDeep learning allows the computer to build complex concepts out of simpler con-\\ncepts. Fig. 1.2 shows how a deep learning system can represent the concept of an\\nimage of a person by combining simpler concepts, such as corners and contours,\\nwhich are in turn defined in terms of edges.'}, {'bounding_box': [{'x': 300, 'y': 2146}, {'x': 2245, 'y': 2146}, {'x': 2245, 'y': 2481}, {'x': 300, 'y': 2481}], 'category': 'paragraph', 'html': \"<br><p id='33' style='font-size:20px'>The quintessential example of a deep learning model is the feedforward deep<br>network or multilayer perceptron (MLP). A multilayer perceptron is just a mathe-<br>matical function mapping some set of input values to output values. The function<br>is formed by composing many simpler functions. We can think of each application<br>of a different mathematical function as providing a new representation of the input.</p>\", 'id': 33, 'page': 5, 'text': 'The quintessential example of a deep learning model is the feedforward deep\\nnetwork or multilayer perceptron (MLP). A multilayer perceptron is just a mathe-\\nmatical function mapping some set of input values to output values. The function\\nis formed by composing many simpler functions. We can think of each application\\nof a different mathematical function as providing a new representation of the input.'}, {'bounding_box': [{'x': 300, 'y': 2505}, {'x': 2244, 'y': 2505}, {'x': 2244, 'y': 2975}, {'x': 300, 'y': 2975}], 'category': 'paragraph', 'html': \"<br><p id='34' style='font-size:18px'>The idea of learning the right representation for the data provides one perspec-<br>tive on deep learning. Another perspective on deep learning is that depth allows the<br>computer to learn a multi-step computer program. Each layer of the representation<br>can be thought of as the state of the computer's memory after executing another<br>set of instructions in parallel. Networks with greater depth can execute more<br>instructions in sequence. Sequential instructions offer great power because later<br>instructions can refer back to the results of earlier instructions. According to this</p>\", 'id': 34, 'page': 5, 'text': \"The idea of learning the right representation for the data provides one perspec-\\ntive on deep learning. Another perspective on deep learning is that depth allows the\\ncomputer to learn a multi-step computer program. Each layer of the representation\\ncan be thought of as the state of the computer's memory after executing another\\nset of instructions in parallel. Networks with greater depth can execute more\\ninstructions in sequence. Sequential instructions offer great power because later\\ninstructions can refer back to the results of earlier instructions. According to this\"}, {'bounding_box': [{'x': 1250, 'y': 3041}, {'x': 1277, 'y': 3041}, {'x': 1277, 'y': 3083}, {'x': 1250, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='35' style='font-size:14px'>5</footer>\", 'id': 35, 'page': 5, 'text': '5'}, {'bounding_box': [{'x': 294, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='36' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 36, 'page': 6, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 465, 'y': 352}, {'x': 2046, 'y': 352}, {'x': 2046, 'y': 1679}, {'x': 465, 'y': 1679}], 'category': 'figure', 'html': '<figure><img id=\\'37\\' style=\\'font-size:18px\\' alt=\"Output\\nCAR PERSON ANIMAL\\n(object identity)\\n3rd hidden layer\\n(object parts)\\n2nd hidden layer\\n(corners and\\ncontours)\\n1st hidden layer\\n(edges)\\nVisible layer\\n(input pixels)\" data-coord=\"top-left:(465,352); bottom-right:(2046,1679)\" /></figure>', 'id': 37, 'page': 6, 'text': 'Output\\nCAR PERSON ANIMAL\\n(object identity)\\n3rd hidden layer\\n(object parts)\\n2nd hidden layer\\n(corners and\\ncontours)\\n1st hidden layer\\n(edges)\\nVisible layer\\n(input pixels)'}, {'bounding_box': [{'x': 303, 'y': 1721}, {'x': 2253, 'y': 1721}, {'x': 2253, 'y': 2918}, {'x': 303, 'y': 2918}], 'category': 'caption', 'html': \"<caption id='38'></caption>\", 'id': 38, 'page': 6, 'text': ''}, {'bounding_box': [{'x': 303, 'y': 1720}, {'x': 2254, 'y': 1720}, {'x': 2254, 'y': 2919}, {'x': 303, 'y': 2919}], 'category': 'paragraph', 'html': '<br><p id=\\'39\\' style=\\'font-size:20px\\'>Figure 1.2: Illustration of a deep learning model. It is difficult for a computer to understand<br>the meaning of raw sensory input data, such as this image represented as a collection<br>of pixel values. The function mapping from a set of pixels to an object identity is very<br>complicated. Learning or evaluating this mapping seems insurmountable if tackled directly.<br>Deep learning resolves this difficulty by breaking the desired complicated mapping into a<br>series of nested simple mappings, each described by a different layer of the model. The<br>input is presented at the visible layer, SO named because it contains the variables that we<br>are able to observe. Then a series of hidden layers extracts increasingly abstract features<br>from the image. These layers are called \"hidden\" because their values are not given in<br>the data; instead the model must determine which concepts are useful for explaining<br>the relationships in the observed data. The images here are visualizations of the kind<br>of feature represented by each hidden unit. Given the pixels, the first layer can easily<br>identify edges, by comparing the brightness of neighboring pixels. Given the first hidden<br>layer\\'s description of the edges, the second hidden layer can easily search for corners and<br>extended contours, which are recognizable as collections of edges. Given the second hidden<br>layer\\'s description of the image in terms of corners and contours, the third hidden layer<br>can detect entire parts of specific objects, by finding specific collections of contours and<br>corners. Finally, this description of the image in terms of the object parts it contains can<br>be used to recognize the objects present in the image. Images reproduced with permission<br>from Zeiler and Fergus (2014).</p>', 'id': 39, 'page': 6, 'text': 'Figure 1.2: Illustration of a deep learning model. It is difficult for a computer to understand\\nthe meaning of raw sensory input data, such as this image represented as a collection\\nof pixel values. The function mapping from a set of pixels to an object identity is very\\ncomplicated. Learning or evaluating this mapping seems insurmountable if tackled directly.\\nDeep learning resolves this difficulty by breaking the desired complicated mapping into a\\nseries of nested simple mappings, each described by a different layer of the model. The\\ninput is presented at the visible layer, SO named because it contains the variables that we\\nare able to observe. Then a series of hidden layers extracts increasingly abstract features\\nfrom the image. These layers are called \"hidden\" because their values are not given in\\nthe data; instead the model must determine which concepts are useful for explaining\\nthe relationships in the observed data. The images here are visualizations of the kind\\nof feature represented by each hidden unit. Given the pixels, the first layer can easily\\nidentify edges, by comparing the brightness of neighboring pixels. Given the first hidden\\nlayer\\'s description of the edges, the second hidden layer can easily search for corners and\\nextended contours, which are recognizable as collections of edges. Given the second hidden\\nlayer\\'s description of the image in terms of corners and contours, the third hidden layer\\ncan detect entire parts of specific objects, by finding specific collections of contours and\\ncorners. Finally, this description of the image in terms of the object parts it contains can\\nbe used to recognize the objects present in the image. Images reproduced with permission\\nfrom Zeiler and Fergus (2014).'}, {'bounding_box': [{'x': 1251, 'y': 3041}, {'x': 1277, 'y': 3041}, {'x': 1277, 'y': 3083}, {'x': 1251, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='40' style='font-size:14px'>6</footer>\", 'id': 40, 'page': 6, 'text': '6'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 997, 'y': 121}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='41' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 41, 'page': 7, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 495, 'y': 297}, {'x': 2039, 'y': 297}, {'x': 2039, 'y': 1096}, {'x': 495, 'y': 1096}], 'category': 'figure', 'html': '<figure><img id=\\'42\\' style=\\'font-size:14px\\' alt=\"Element\\nElement 0 Set\\nSet\\nLogistic Logistic\\nRegression Regression\\nw\\nX1 u X2\\nw 1\" data-coord=\"top-left:(495,297); bottom-right:(2039,1096)\" /></figure>', 'id': 42, 'page': 7, 'text': 'Element\\nElement 0 Set\\nSet\\nLogistic Logistic\\nRegression Regression\\nw\\nX1 u X2\\nw 1'}, {'bounding_box': [{'x': 296, 'y': 1144}, {'x': 2254, 'y': 1144}, {'x': 2254, 'y': 1562}, {'x': 296, 'y': 1562}], 'category': 'caption', 'html': \"<caption id='43' style='font-size:18px'>Figure 1.3: Illustration of computational graphs mapping an input to an output where<br>each node performs an operation. Depth is the length of the longest path from input to<br>output but depends on the definition of what constitutes a possible computational step.<br>The computation depicted in these graphs is the output of a logistic regression model,<br>o(wT x), where 0 is the logistic sigmoid function. If we use addition, multiplication and<br>logistic sigmoids as the elements of our computer language, then this model has depth<br>three. If we view logistic regression as an element itself, then this model has depth one.</caption>\", 'id': 43, 'page': 7, 'text': 'Figure 1.3: Illustration of computational graphs mapping an input to an output where\\neach node performs an operation. Depth is the length of the longest path from input to\\noutput but depends on the definition of what constitutes a possible computational step.\\nThe computation depicted in these graphs is the output of a logistic regression model,\\no(wT x), where 0 is the logistic sigmoid function. If we use addition, multiplication and\\nlogistic sigmoids as the elements of our computer language, then this model has depth\\nthree. If we view logistic regression as an element itself, then this model has depth one.'}, {'bounding_box': [{'x': 296, 'y': 1675}, {'x': 2247, 'y': 1675}, {'x': 2247, 'y': 2074}, {'x': 296, 'y': 2074}], 'category': 'paragraph', 'html': \"<p id='44' style='font-size:20px'>view of deep learning, not all of the information in a layer's activations necessarily<br>encodes factors of variation that explain the input. The representation also stores<br>state information that helps to execute a program that can make sense of the input.<br>This state information could be analogous to a counter or pointer in a traditional<br>computer program. It has nothing to do with the content of the input specifically,<br>but it helps the model to organize its processing.</p>\", 'id': 44, 'page': 7, 'text': \"view of deep learning, not all of the information in a layer's activations necessarily\\nencodes factors of variation that explain the input. The representation also stores\\nstate information that helps to execute a program that can make sense of the input.\\nThis state information could be analogous to a counter or pointer in a traditional\\ncomputer program. It has nothing to do with the content of the input specifically,\\nbut it helps the model to organize its processing.\"}, {'bounding_box': [{'x': 299, 'y': 2101}, {'x': 2246, 'y': 2101}, {'x': 2246, 'y': 2703}, {'x': 299, 'y': 2703}], 'category': 'paragraph', 'html': \"<br><p id='45' style='font-size:20px'>There are two main ways of measuring the depth of a model. The first view is<br>based on the number of sequential instructions that must be executed to evaluate<br>the architecture. We can think of this as the length of the longest path through<br>a flow chart that describes how to compute each of the model's outputs given<br>its inputs. Just as two equivalent computer programs will have different lengths<br>depending on which language the program is written in, the same function may be<br>drawn as a flowchart with different depths depending on which functions we allow<br>to be used as individual steps in the flowchart. Fig. 1.3 illustrates how this choice<br>of language can give two different measurements for the same architecture.</p>\", 'id': 45, 'page': 7, 'text': \"There are two main ways of measuring the depth of a model. The first view is\\nbased on the number of sequential instructions that must be executed to evaluate\\nthe architecture. We can think of this as the length of the longest path through\\na flow chart that describes how to compute each of the model's outputs given\\nits inputs. Just as two equivalent computer programs will have different lengths\\ndepending on which language the program is written in, the same function may be\\ndrawn as a flowchart with different depths depending on which functions we allow\\nto be used as individual steps in the flowchart. Fig. 1.3 illustrates how this choice\\nof language can give two different measurements for the same architecture.\"}, {'bounding_box': [{'x': 300, 'y': 2732}, {'x': 2246, 'y': 2732}, {'x': 2246, 'y': 2992}, {'x': 300, 'y': 2992}], 'category': 'paragraph', 'html': \"<br><p id='46' style='font-size:22px'>Another approach, used by deep probabilistic models, regards the depth of a<br>model as being not the depth of the computational graph but the depth of the<br>graph describing how concepts are related to each other. In this case, the depth<br>of the flowchart of the computations needed to compute the representation of</p>\", 'id': 46, 'page': 7, 'text': 'Another approach, used by deep probabilistic models, regards the depth of a\\nmodel as being not the depth of the computational graph but the depth of the\\ngraph describing how concepts are related to each other. In this case, the depth\\nof the flowchart of the computations needed to compute the representation of'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='47' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 47, 'page': 8, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 297, 'y': 313}, {'x': 2243, 'y': 313}, {'x': 2243, 'y': 848}, {'x': 297, 'y': 848}], 'category': 'paragraph', 'html': \"<p id='48' style='font-size:18px'>each concept may be much deeper than the graph of the concepts themselves.<br>This is because the system's understanding of the simpler concepts can be refined<br>given information about the more complex concepts. For example, an AI system<br>observing an image of a face with one eye in shadow may initially only see one eye.<br>After detecting that a face is present, it can then infer that a second eye is probably<br>present as well. In this case, the graph of concepts only includes two layers -a<br>layer for eyes and a layer for faces- but the graph of computations includes 2n<br>layers if we refine our estimate of each concept given the other n times.</p>\", 'id': 48, 'page': 8, 'text': \"each concept may be much deeper than the graph of the concepts themselves.\\nThis is because the system's understanding of the simpler concepts can be refined\\ngiven information about the more complex concepts. For example, an AI system\\nobserving an image of a face with one eye in shadow may initially only see one eye.\\nAfter detecting that a face is present, it can then infer that a second eye is probably\\npresent as well. In this case, the graph of concepts only includes two layers -a\\nlayer for eyes and a layer for faces- but the graph of computations includes 2n\\nlayers if we refine our estimate of each concept given the other n times.\"}, {'bounding_box': [{'x': 299, 'y': 874}, {'x': 2244, 'y': 874}, {'x': 2244, 'y': 1478}, {'x': 299, 'y': 1478}], 'category': 'paragraph', 'html': '<br><p id=\\'49\\' style=\\'font-size:20px\\'>Because it is not always clear which of these two views- the depth of the<br>computational graph, or the depth of the probabilistic modeling graph is most<br>relevant, and because different people choose different sets of smallest elements<br>from which to construct their graphs, there is no single correct value for the<br>depth of an architecture, just as there is no single correct value for the length of<br>a computer program. Nor is there a consensus about how much depth a model<br>requires to qualify as \"deep.\" However, deep learning can safely be regarded as the<br>study of models that either involve a greater amount of composition of learned<br>functions or learned concepts than traditional machine learning does.</p>', 'id': 49, 'page': 8, 'text': 'Because it is not always clear which of these two views- the depth of the\\ncomputational graph, or the depth of the probabilistic modeling graph is most\\nrelevant, and because different people choose different sets of smallest elements\\nfrom which to construct their graphs, there is no single correct value for the\\ndepth of an architecture, just as there is no single correct value for the length of\\na computer program. Nor is there a consensus about how much depth a model\\nrequires to qualify as \"deep.\" However, deep learning can safely be regarded as the\\nstudy of models that either involve a greater amount of composition of learned\\nfunctions or learned concepts than traditional machine learning does.'}, {'bounding_box': [{'x': 299, 'y': 1505}, {'x': 2244, 'y': 1505}, {'x': 2244, 'y': 2173}, {'x': 299, 'y': 2173}], 'category': 'paragraph', 'html': \"<br><p id='50' style='font-size:20px'>To summarize, deep learning, the subject of this book, is an approach to AI.<br>Specifically, it is a type of machine learning, a technique that allows computer<br>systems to improve with experience and data. According to the authors of this<br>book, machine learning is the only viable approach to building AI systems that<br>can operate in complicated, real-world environments. Deep learning is a particular<br>kind of machine learning that achieves great power and flexibility by learning to<br>represent the world as a nested hierarchy of concepts, with each concept defined in<br>relation to simpler concepts, and more abstract representations computed in terms<br>of less abstract ones. Fig. 1.4 illustrates the relationship between these different<br>AI disciplines. Fig. 1.5 gives a high-level schematic of how each works.</p>\", 'id': 50, 'page': 8, 'text': 'To summarize, deep learning, the subject of this book, is an approach to AI.\\nSpecifically, it is a type of machine learning, a technique that allows computer\\nsystems to improve with experience and data. According to the authors of this\\nbook, machine learning is the only viable approach to building AI systems that\\ncan operate in complicated, real-world environments. Deep learning is a particular\\nkind of machine learning that achieves great power and flexibility by learning to\\nrepresent the world as a nested hierarchy of concepts, with each concept defined in\\nrelation to simpler concepts, and more abstract representations computed in terms\\nof less abstract ones. Fig. 1.4 illustrates the relationship between these different\\nAI disciplines. Fig. 1.5 gives a high-level schematic of how each works.'}, {'bounding_box': [{'x': 300, 'y': 2287}, {'x': 1537, 'y': 2287}, {'x': 1537, 'y': 2364}, {'x': 300, 'y': 2364}], 'category': 'paragraph', 'html': \"<p id='51' style='font-size:22px'>1.1 Who Should Read This Book?</p>\", 'id': 51, 'page': 8, 'text': '1.1 Who Should Read This Book?'}, {'bounding_box': [{'x': 296, 'y': 2442}, {'x': 2245, 'y': 2442}, {'x': 2245, 'y': 2979}, {'x': 296, 'y': 2979}], 'category': 'paragraph', 'html': \"<p id='52' style='font-size:20px'>This book can be useful for a variety of readers, but we wrote it with two main<br>target audiences in mind. One of these target audiences is university students<br>(undergraduate or graduate) learning about machine learning, including those who<br>are beginning a career in deep learning and artificial intelligence research. The<br>other target audience is software engineers who do not have a machine learning<br>or statistics background, but want to rapidly acquire one and begin using deep<br>learning in their product or platform. Deep learning has already proven useful in<br>many software disciplines including computer vision, speech and audio processing,</p>\", 'id': 52, 'page': 8, 'text': 'This book can be useful for a variety of readers, but we wrote it with two main\\ntarget audiences in mind. One of these target audiences is university students\\n(undergraduate or graduate) learning about machine learning, including those who\\nare beginning a career in deep learning and artificial intelligence research. The\\nother target audience is software engineers who do not have a machine learning\\nor statistics background, but want to rapidly acquire one and begin using deep\\nlearning in their product or platform. Deep learning has already proven useful in\\nmany software disciplines including computer vision, speech and audio processing,'}, {'bounding_box': [{'x': 1251, 'y': 3041}, {'x': 1277, 'y': 3041}, {'x': 1277, 'y': 3083}, {'x': 1251, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='53' style='font-size:14px'>8</footer>\", 'id': 53, 'page': 8, 'text': '8'}, {'bounding_box': [{'x': 294, 'y': 123}, {'x': 997, 'y': 123}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='54' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 54, 'page': 9, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 514, 'y': 749}, {'x': 2032, 'y': 749}, {'x': 2032, 'y': 2308}, {'x': 514, 'y': 2308}], 'category': 'figure', 'html': '<figure><img id=\\'55\\' style=\\'font-size:18px\\' alt=\"Deep learning Example:\\nShallow\\nExample: Example:\\nExample: autoencoders\\nLogistic Knowledge\\nMLPs\\nregression bases\\nRepresentation learning\\nMachine learning\\nAI\" data-coord=\"top-left:(514,749); bottom-right:(2032,2308)\" /></figure>', 'id': 55, 'page': 9, 'text': 'Deep learning Example:\\nShallow\\nExample: Example:\\nExample: autoencoders\\nLogistic Knowledge\\nMLPs\\nregression bases\\nRepresentation learning\\nMachine learning\\nAI'}, {'bounding_box': [{'x': 296, 'y': 2354}, {'x': 2254, 'y': 2354}, {'x': 2254, 'y': 2531}, {'x': 296, 'y': 2531}], 'category': 'caption', 'html': \"<caption id='56' style='font-size:20px'>Figure 1.4: A Venn diagram showing how deep learning is a kind of representation learning,<br>which is in turn a kind of machine learning, which is used for many but not all approaches<br>to AI. Each section of the Venn diagram includes an example of an AI technology.</caption>\", 'id': 56, 'page': 9, 'text': 'Figure 1.4: A Venn diagram showing how deep learning is a kind of representation learning,\\nwhich is in turn a kind of machine learning, which is used for many but not all approaches\\nto AI. Each section of the Venn diagram includes an example of an AI technology.'}, {'bounding_box': [{'x': 1251, 'y': 3041}, {'x': 1276, 'y': 3041}, {'x': 1276, 'y': 3083}, {'x': 1251, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='57' style='font-size:14px'>9</footer>\", 'id': 57, 'page': 9, 'text': '9'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 997, 'y': 121}, {'x': 997, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='58' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 58, 'page': 10, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 543, 'y': 481}, {'x': 1993, 'y': 481}, {'x': 1993, 'y': 2563}, {'x': 543, 'y': 2563}], 'category': 'figure', 'html': '<figure><img id=\\'59\\' style=\\'font-size:16px\\' alt=\"Output\\nMapping from\\nOutput Output\\nfeatures\\nAdditional\\nMapping from Mapping from layers of more\\nOutput\\nfeatures features abstract\\nfeatures\\nHand- Hand-\\nSimple\\ndesigned designed Features\\nfeatures\\nprogram features\\nInput Input Input Input\\nDeep\\nClassic\\nRule-based learning\\nmachine\\nsystems Representation\\nlearning\\nlearning\" data-coord=\"top-left:(543,481); bottom-right:(1993,2563)\" /></figure>', 'id': 59, 'page': 10, 'text': 'Output\\nMapping from\\nOutput Output\\nfeatures\\nAdditional\\nMapping from Mapping from layers of more\\nOutput\\nfeatures features abstract\\nfeatures\\nHand- Hand-\\nSimple\\ndesigned designed Features\\nfeatures\\nprogram features\\nInput Input Input Input\\nDeep\\nClassic\\nRule-based learning\\nmachine\\nsystems Representation\\nlearning\\nlearning'}, {'bounding_box': [{'x': 298, 'y': 2615}, {'x': 2250, 'y': 2615}, {'x': 2250, 'y': 2789}, {'x': 298, 'y': 2789}], 'category': 'caption', 'html': \"<caption id='60' style='font-size:20px'>Figure 1.5: Flowcharts showing how the different parts of an AI system relate to each<br>other within different AI disciplines. Shaded boxes indicate components that are able to<br>learn from data.</caption>\", 'id': 60, 'page': 10, 'text': 'Figure 1.5: Flowcharts showing how the different parts of an AI system relate to each\\nother within different AI disciplines. Shaded boxes indicate components that are able to\\nlearn from data.'}, {'bounding_box': [{'x': 1244, 'y': 3039}, {'x': 1295, 'y': 3039}, {'x': 1295, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='61' style='font-size:14px'>10</footer>\", 'id': 61, 'page': 10, 'text': '10'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='62' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 62, 'page': 11, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 299, 'y': 315}, {'x': 2245, 'y': 315}, {'x': 2245, 'y': 440}, {'x': 299, 'y': 440}], 'category': 'paragraph', 'html': \"<p id='63' style='font-size:20px'>natural language processing, robotics, bioinformatics and chemistry, video games,<br>search engines, online advertising and finance.</p>\", 'id': 63, 'page': 11, 'text': 'natural language processing, robotics, bioinformatics and chemistry, video games,\\nsearch engines, online advertising and finance.'}, {'bounding_box': [{'x': 296, 'y': 466}, {'x': 2243, 'y': 466}, {'x': 2243, 'y': 798}, {'x': 296, 'y': 798}], 'category': 'paragraph', 'html': \"<br><p id='64' style='font-size:18px'>This book has been organized into three parts in order to best accommodate a<br>variety of readers. Part I introduces basic mathematical tools and machine learning<br>concepts. Part II describes the most established deep learning algorithms that are<br>essentially solved technologies. Part III describes more speculative ideas that are<br>widely believed to be important for future research in deep learning.</p>\", 'id': 64, 'page': 11, 'text': 'This book has been organized into three parts in order to best accommodate a\\nvariety of readers. Part I introduces basic mathematical tools and machine learning\\nconcepts. Part II describes the most established deep learning algorithms that are\\nessentially solved technologies. Part III describes more speculative ideas that are\\nwidely believed to be important for future research in deep learning.'}, {'bounding_box': [{'x': 299, 'y': 821}, {'x': 2244, 'y': 821}, {'x': 2244, 'y': 1221}, {'x': 299, 'y': 1221}], 'category': 'paragraph', 'html': \"<br><p id='65' style='font-size:20px'>Readers should feel free to skip parts that are not relevant given their interests<br>or background. Readers familiar with linear algebra, probability, and fundamental<br>machine learning concepts can skip Part I, for example, while readers who just want<br>to implement a working system need not read beyond Part II. To help choose which<br>chapters to read, Fig. 1.6 provides a flowchart showing the high-level organization<br>of the book.</p>\", 'id': 65, 'page': 11, 'text': 'Readers should feel free to skip parts that are not relevant given their interests\\nor background. Readers familiar with linear algebra, probability, and fundamental\\nmachine learning concepts can skip Part I, for example, while readers who just want\\nto implement a working system need not read beyond Part II. To help choose which\\nchapters to read, Fig. 1.6 provides a flowchart showing the high-level organization\\nof the book.'}, {'bounding_box': [{'x': 300, 'y': 1248}, {'x': 2243, 'y': 1248}, {'x': 2243, 'y': 1511}, {'x': 300, 'y': 1511}], 'category': 'paragraph', 'html': \"<br><p id='66' style='font-size:18px'>We do assume that all readers come from a computer science background. We<br>assume familiarity with programming, a basic understanding of computational<br>performance issues, complexity theory, introductory level calculus and some of the<br>terminology of graph theory.</p>\", 'id': 66, 'page': 11, 'text': 'We do assume that all readers come from a computer science background. We\\nassume familiarity with programming, a basic understanding of computational\\nperformance issues, complexity theory, introductory level calculus and some of the\\nterminology of graph theory.'}, {'bounding_box': [{'x': 303, 'y': 1625}, {'x': 1710, 'y': 1625}, {'x': 1710, 'y': 1703}, {'x': 303, 'y': 1703}], 'category': 'paragraph', 'html': \"<p id='67' style='font-size:22px'>1.2 Historical Trends in Deep Learning</p>\", 'id': 67, 'page': 11, 'text': '1.2 Historical Trends in Deep Learning'}, {'bounding_box': [{'x': 300, 'y': 1782}, {'x': 2244, 'y': 1782}, {'x': 2244, 'y': 1909}, {'x': 300, 'y': 1909}], 'category': 'paragraph', 'html': \"<p id='68' style='font-size:18px'>It is easiest to understand deep learning with some historical context. Rather than<br>providing a detailed history of deep learning, we identify a few key trends:</p>\", 'id': 68, 'page': 11, 'text': 'It is easiest to understand deep learning with some historical context. Rather than\\nproviding a detailed history of deep learning, we identify a few key trends:'}, {'bounding_box': [{'x': 383, 'y': 1976}, {'x': 2243, 'y': 1976}, {'x': 2243, 'y': 2174}, {'x': 383, 'y': 2174}], 'category': 'paragraph', 'html': \"<p id='69' style='font-size:18px'> Deep learning has had a long and rich history, but has gone by many names<br>reflecting different philosophical viewpoints, and has waxed and waned in<br>popularity.</p>\", 'id': 69, 'page': 11, 'text': ' Deep learning has had a long and rich history, but has gone by many names\\nreflecting different philosophical viewpoints, and has waxed and waned in\\npopularity.'}, {'bounding_box': [{'x': 384, 'y': 2227}, {'x': 2243, 'y': 2227}, {'x': 2243, 'y': 2352}, {'x': 384, 'y': 2352}], 'category': 'paragraph', 'html': \"<p id='70' style='font-size:16px'> Deep learning has become more useful as the amount of available training<br>data has increased.</p>\", 'id': 70, 'page': 11, 'text': ' Deep learning has become more useful as the amount of available training\\ndata has increased.'}, {'bounding_box': [{'x': 385, 'y': 2406}, {'x': 2244, 'y': 2406}, {'x': 2244, 'y': 2532}, {'x': 385, 'y': 2532}], 'category': 'paragraph', 'html': \"<p id='71' style='font-size:16px'> Deep learning models have grown in size over time as computer hardware<br>and software infrastructure for deep learning has improved.</p>\", 'id': 71, 'page': 11, 'text': ' Deep learning models have grown in size over time as computer hardware\\nand software infrastructure for deep learning has improved.'}, {'bounding_box': [{'x': 383, 'y': 2587}, {'x': 2244, 'y': 2587}, {'x': 2244, 'y': 2716}, {'x': 383, 'y': 2716}], 'category': 'paragraph', 'html': \"<p id='72' style='font-size:20px'> Deep learning has solved increasingly complicated applications with increasing<br>accuracy over time.</p>\", 'id': 72, 'page': 11, 'text': ' Deep learning has solved increasingly complicated applications with increasing\\naccuracy over time.'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1292, 'y': 3039}, {'x': 1292, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='73' style='font-size:14px'>11</footer>\", 'id': 73, 'page': 11, 'text': '11'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 997, 'y': 121}, {'x': 997, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='74' style='font-size:20px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 74, 'page': 12, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 1140, 'y': 359}, {'x': 1405, 'y': 359}, {'x': 1405, 'y': 405}, {'x': 1140, 'y': 405}], 'category': 'paragraph', 'html': \"<p id='75' style='font-size:14px'>1. Introduction</p>\", 'id': 75, 'page': 12, 'text': '1. Introduction'}, {'bounding_box': [{'x': 811, 'y': 540}, {'x': 1732, 'y': 540}, {'x': 1732, 'y': 586}, {'x': 811, 'y': 586}], 'category': 'caption', 'html': \"<caption id='76' style='font-size:18px'>Part I: Applied Math and Machine Learning Basics</caption>\", 'id': 76, 'page': 12, 'text': 'Part I: Applied Math and Machine Learning Basics'}, {'bounding_box': [{'x': 516, 'y': 638}, {'x': 2014, 'y': 638}, {'x': 2014, 'y': 2819}, {'x': 516, 'y': 2819}], 'category': 'figure', 'html': '<figure><img id=\\'77\\' style=\\'font-size:18px\\' alt=\"3. Probability and\\n2. Linear Algebra\\nInformation Theory\\n4. Numerical 5. Machine Learning\\nComputation Basics\\nPart II: Deep Networks: Modern Practices\\n6. Deep Feedforward\\nNetworks\\n7. Regularization 8. Optimization 9. CNNs 10. RNNs\\n11. Practical\\n12. Applications\\nMethodology\\nPart III: Deep Learning Research\\n13. Linear Factor 15. Representation\\n14. Autoencoders\\nModels Learning\\n16. Structured 17. Monte Carlo\\nProbabilistic Models Methods\\n18. Partition\\n19. Inference\\nFunction\\n20. Deep Generative\\nModels\" data-coord=\"top-left:(516,638); bottom-right:(2014,2819)\" /></figure>', 'id': 77, 'page': 12, 'text': '3. Probability and\\n2. Linear Algebra\\nInformation Theory\\n4. Numerical 5. Machine Learning\\nComputation Basics\\nPart II: Deep Networks: Modern Practices\\n6. Deep Feedforward\\nNetworks\\n7. Regularization 8. Optimization 9. CNNs 10. RNNs\\n11. Practical\\n12. Applications\\nMethodology\\nPart III: Deep Learning Research\\n13. Linear Factor 15. Representation\\n14. Autoencoders\\nModels Learning\\n16. Structured 17. Monte Carlo\\nProbabilistic Models Methods\\n18. Partition\\n19. Inference\\nFunction\\n20. Deep Generative\\nModels'}, {'bounding_box': [{'x': 299, 'y': 2872}, {'x': 2251, 'y': 2872}, {'x': 2251, 'y': 2988}, {'x': 299, 'y': 2988}], 'category': 'caption', 'html': \"<caption id='78' style='font-size:22px'>Figure 1.6: The high-level organization of the book. An arrow from one chapter to another<br>indicates that the former chapter is prerequisite material for understanding the latter.</caption>\", 'id': 78, 'page': 12, 'text': 'Figure 1.6: The high-level organization of the book. An arrow from one chapter to another\\nindicates that the former chapter is prerequisite material for understanding the latter.'}, {'bounding_box': [{'x': 1244, 'y': 3040}, {'x': 1294, 'y': 3040}, {'x': 1294, 'y': 3082}, {'x': 1244, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='79' style='font-size:16px'>12</footer>\", 'id': 79, 'page': 12, 'text': '12'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='80' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 80, 'page': 13, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 305, 'y': 306}, {'x': 2261, 'y': 306}, {'x': 2261, 'y': 444}, {'x': 305, 'y': 444}], 'category': 'paragraph', 'html': \"<p id='81' style='font-size:22px'>1.2.1 The Many N ames and Changing Fortunes of Neural Net-<br>works</p>\", 'id': 81, 'page': 13, 'text': '1.2.1 The Many N ames and Changing Fortunes of Neural Net-\\nworks'}, {'bounding_box': [{'x': 296, 'y': 500}, {'x': 2244, 'y': 500}, {'x': 2244, 'y': 1039}, {'x': 296, 'y': 1039}], 'category': 'paragraph', 'html': '<p id=\\'82\\' style=\\'font-size:16px\\'>We expect that many readers of this book have heard of deep learning as an<br>exciting new technology, and are surprised to see a mention of \"history\" in a book<br>about an emerging field. In fact, deep learning dates back to the 1940s. Deep<br>learning only appears to be new, because it was relatively unpopular for several<br>years preceding its current popularity, and because it has gone through many<br>different names, and has only recently become called \"deep learning.\" The field<br>has been rebranded many times, reflecting the influence of different researchers<br>and different perspectives.</p>', 'id': 82, 'page': 13, 'text': 'We expect that many readers of this book have heard of deep learning as an\\nexciting new technology, and are surprised to see a mention of \"history\" in a book\\nabout an emerging field. In fact, deep learning dates back to the 1940s. Deep\\nlearning only appears to be new, because it was relatively unpopular for several\\nyears preceding its current popularity, and because it has gone through many\\ndifferent names, and has only recently become called \"deep learning.\" The field\\nhas been rebranded many times, reflecting the influence of different researchers\\nand different perspectives.'}, {'bounding_box': [{'x': 299, 'y': 1063}, {'x': 2246, 'y': 1063}, {'x': 2246, 'y': 1465}, {'x': 299, 'y': 1465}], 'category': 'paragraph', 'html': \"<br><p id='83' style='font-size:20px'>A comprehensive history of deep learning is beyond the scope of this textbook.<br>However, some basic context is useful for understanding deep learning. Broadly<br>speaking, there have been three waves of development of deep learning: deep learn-<br>ing known as cybernetics in the 1940s-1960s, deep learning known as connectionism<br>in the 1980s-1990s, and the current resurgence under the name deep learning<br>beginning in 2006. This is quantitatively illustrated in Fig. 1.7.</p>\", 'id': 83, 'page': 13, 'text': 'A comprehensive history of deep learning is beyond the scope of this textbook.\\nHowever, some basic context is useful for understanding deep learning. Broadly\\nspeaking, there have been three waves of development of deep learning: deep learn-\\ning known as cybernetics in the 1940s-1960s, deep learning known as connectionism\\nin the 1980s-1990s, and the current resurgence under the name deep learning\\nbeginning in 2006. This is quantitatively illustrated in Fig. 1.7.'}, {'bounding_box': [{'x': 303, 'y': 1487}, {'x': 2246, 'y': 1487}, {'x': 2246, 'y': 2638}, {'x': 303, 'y': 2638}], 'category': 'paragraph', 'html': \"<br><p id='84' style='font-size:18px'>Some of the earliest learning algorithms we recognize today were intended<br>to be computational models of biological learning, i.e. models of how learning<br>happens or could happen in the brain. As a result, one of the names that deep<br>learning has gone by is artificial neural networks (ANNs). The corresponding<br>perspective on deep learning models is that they are engineered systems inspired<br>by the biological brain (whether the human brain or the brain of another animal).<br>While the kinds of neural networks used for machine learning have sometimes<br>been used to understand brain function (Hinton and Shallice, 1991), they are<br>generally not designed to be realistic models of biological function. The neural<br>perspective on deep learning is motivated by two main ideas. One idea is that<br>the brain provides a proof by example that intelligent behavior is possible, and a<br>conceptually straightforward path to building intelligence is to reverse engineer the<br>computational principles behind the brain and duplicate its functionality. Another<br>perspective is that it would be deeply interesting to understand the brain and the<br>principles that underlie human intelligence, SO machine learning models that shed<br>light on these basic scientific questions are useful apart from their ability to solve<br>engineering applications.</p>\", 'id': 84, 'page': 13, 'text': 'Some of the earliest learning algorithms we recognize today were intended\\nto be computational models of biological learning, i.e. models of how learning\\nhappens or could happen in the brain. As a result, one of the names that deep\\nlearning has gone by is artificial neural networks (ANNs). The corresponding\\nperspective on deep learning models is that they are engineered systems inspired\\nby the biological brain (whether the human brain or the brain of another animal).\\nWhile the kinds of neural networks used for machine learning have sometimes\\nbeen used to understand brain function (Hinton and Shallice, 1991), they are\\ngenerally not designed to be realistic models of biological function. The neural\\nperspective on deep learning is motivated by two main ideas. One idea is that\\nthe brain provides a proof by example that intelligent behavior is possible, and a\\nconceptually straightforward path to building intelligence is to reverse engineer the\\ncomputational principles behind the brain and duplicate its functionality. Another\\nperspective is that it would be deeply interesting to understand the brain and the\\nprinciples that underlie human intelligence, SO machine learning models that shed\\nlight on these basic scientific questions are useful apart from their ability to solve\\nengineering applications.'}, {'bounding_box': [{'x': 299, 'y': 2661}, {'x': 2245, 'y': 2661}, {'x': 2245, 'y': 2925}, {'x': 299, 'y': 2925}], 'category': 'paragraph', 'html': '<br><p id=\\'85\\' style=\\'font-size:16px\\'>The modern term \"deep learning\" goes beyond the neuroscientific perspective<br>on the current breed of machine learning models. It appeals to a more general<br>principle of learning multiple levels of composition, which can be applied in machine<br>learning frameworks that are not necessarily neurally inspired.</p>', 'id': 85, 'page': 13, 'text': 'The modern term \"deep learning\" goes beyond the neuroscientific perspective\\non the current breed of machine learning models. It appeals to a more general\\nprinciple of learning multiple levels of composition, which can be applied in machine\\nlearning frameworks that are not necessarily neurally inspired.'}, {'bounding_box': [{'x': 1244, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='86' style='font-size:14px'>13</footer>\", 'id': 86, 'page': 13, 'text': '13'}, {'bounding_box': [{'x': 294, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='87' style='font-size:18px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 87, 'page': 14, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 521, 'y': 908}, {'x': 2014, 'y': 908}, {'x': 2014, 'y': 1610}, {'x': 521, 'y': 1610}], 'category': 'figure', 'html': '<figure><img id=\\'88\\' style=\\'font-size:14px\\' alt=\"Phrase 0.000250\\n0.000200 cybernetics\\nor\\nWord\\n0.000150\\n(connectionism + neural networks)\\nJo\\n0.000100\\nFrequency\\n0.000050\\n0.000000\\n1940\\n1950\\n1960\\n1970\\n1980\\nYear 1990\\n2000\" data-coord=\"top-left:(521,908); bottom-right:(2014,1610)\" /></figure>', 'id': 88, 'page': 14, 'text': 'Phrase 0.000250\\n0.000200 cybernetics\\nor\\nWord\\n0.000150\\n(connectionism + neural networks)\\nJo\\n0.000100\\nFrequency\\n0.000050\\n0.000000\\n1940\\n1950\\n1960\\n1970\\n1980\\nYear 1990\\n2000'}, {'bounding_box': [{'x': 296, 'y': 1699}, {'x': 2252, 'y': 1699}, {'x': 2252, 'y': 2418}, {'x': 296, 'y': 2418}], 'category': 'caption', 'html': '<caption id=\\'89\\' style=\\'font-size:20px\\'>Figure 1.7: The figure shows two of the three historical waves of artificial neural nets<br>research, as measured by the frequency of the phrases \"cybernetics\" and \"connectionism\" or<br>\"neural networks\" according to Google Books (the third wave is too recent to appear). The<br>first wave started with cybernetics in the 1940s-1960s, with the development of theories<br>of biological learning (McCulloch and Pitts, 1943; Hebb, 1949) and implementations of<br>the first models such as the perceptron (Rosenblatt, 1958) allowing the training of a single<br>neuron. The second wave started with the connectionist approach of the 1980-1995 period,<br>with back-propagation (Rumelhart et al., 1986a) to train a neural network with one or two<br>hidden layers. The current and third wave, deep learning, started around 2006 (Hinton<br>et al., 2006; Bengio et al., 2007; Ranzato et al., 2007a), and is just now appearing in book<br>form as of 2016. The other two waves similarly appeared in book form much later than<br>the corresponding scientific activity occurred.</caption>', 'id': 89, 'page': 14, 'text': 'Figure 1.7: The figure shows two of the three historical waves of artificial neural nets\\nresearch, as measured by the frequency of the phrases \"cybernetics\" and \"connectionism\" or\\n\"neural networks\" according to Google Books (the third wave is too recent to appear). The\\nfirst wave started with cybernetics in the 1940s-1960s, with the development of theories\\nof biological learning (McCulloch and Pitts, 1943; Hebb, 1949) and implementations of\\nthe first models such as the perceptron (Rosenblatt, 1958) allowing the training of a single\\nneuron. The second wave started with the connectionist approach of the 1980-1995 period,\\nwith back-propagation (Rumelhart et al., 1986a) to train a neural network with one or two\\nhidden layers. The current and third wave, deep learning, started around 2006 (Hinton\\net al., 2006; Bengio et al., 2007; Ranzato et al., 2007a), and is just now appearing in book\\nform as of 2016. The other two waves similarly appeared in book form much later than\\nthe corresponding scientific activity occurred.'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='90' style='font-size:16px'>14</footer>\", 'id': 90, 'page': 14, 'text': '14'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='91' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 91, 'page': 15, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 296, 'y': 313}, {'x': 2242, 'y': 313}, {'x': 2242, 'y': 713}, {'x': 296, 'y': 713}], 'category': 'paragraph', 'html': \"<p id='92' style='font-size:16px'>The earliest predecessors of modern deep learning were simple linear models<br>motivated from a neuroscientific perspective. These models were designed to<br>take a set of n input values X1,    , Xn and associate them with an output y.<br>These models would learn a set of weights w1,    , Wn and compute their output<br>f(x, w) = x1w1 +    + Xn Wn. This first wave of neural networks research was<br>known as cybernetics, as illustrated in Fig. 1.7.</p>\", 'id': 92, 'page': 15, 'text': 'The earliest predecessors of modern deep learning were simple linear models\\nmotivated from a neuroscientific perspective. These models were designed to\\ntake a set of n input values X1,    , Xn and associate them with an output y.\\nThese models would learn a set of weights w1,    , Wn and compute their output\\nf(x, w) = x1w1 +    + Xn Wn. This first wave of neural networks research was\\nknown as cybernetics, as illustrated in Fig. 1.7.'}, {'bounding_box': [{'x': 298, 'y': 741}, {'x': 2242, 'y': 741}, {'x': 2242, 'y': 1409}, {'x': 298, 'y': 1409}], 'category': 'paragraph', 'html': \"<p id='93' style='font-size:22px'>The McCulloch-Pitts Neuron (McCulloch and Pitts, 1943) was an early model<br>of brain function. This linear model could recognize two different categories of<br>inputs by testing whether f (x, w) is positive or negative. Of course, for the model<br>to correspond to the desired definition of the categories, the weights needed to be<br>set correctly. These weights could be set by the human operator. In the 1950s,<br>the perceptron (Rosenblatt, 1958, 1962) became the first model that could learn<br>the weights defining the categories given examples of inputs from each category.<br>The adaptive linear element (ADALINE), which dates from about the same time,<br>simply returned the value of f(x) itself to predict a real number (Widrow and<br>Hoff, 1960), and could also learn to predict these numbers from data.</p>\", 'id': 93, 'page': 15, 'text': 'The McCulloch-Pitts Neuron (McCulloch and Pitts, 1943) was an early model\\nof brain function. This linear model could recognize two different categories of\\ninputs by testing whether f (x, w) is positive or negative. Of course, for the model\\nto correspond to the desired definition of the categories, the weights needed to be\\nset correctly. These weights could be set by the human operator. In the 1950s,\\nthe perceptron (Rosenblatt, 1958, 1962) became the first model that could learn\\nthe weights defining the categories given examples of inputs from each category.\\nThe adaptive linear element (ADALINE), which dates from about the same time,\\nsimply returned the value of f(x) itself to predict a real number (Widrow and\\nHoff, 1960), and could also learn to predict these numbers from data.'}, {'bounding_box': [{'x': 300, 'y': 1436}, {'x': 2242, 'y': 1436}, {'x': 2242, 'y': 1766}, {'x': 300, 'y': 1766}], 'category': 'paragraph', 'html': \"<p id='94' style='font-size:22px'>These simple learning algorithms greatly affected the modern landscape of<br>machine learning. The training algorithm used to adapt the weights of the ADA-<br>LINE was a special case of an algorithm called stochastic gradient descent. Slightly<br>modified versions of the stochastic gradient descent algorithm remain the dominant<br>training algorithms for deep learning models today.</p>\", 'id': 94, 'page': 15, 'text': 'These simple learning algorithms greatly affected the modern landscape of\\nmachine learning. The training algorithm used to adapt the weights of the ADA-\\nLINE was a special case of an algorithm called stochastic gradient descent. Slightly\\nmodified versions of the stochastic gradient descent algorithm remain the dominant\\ntraining algorithms for deep learning models today.'}, {'bounding_box': [{'x': 297, 'y': 1794}, {'x': 2240, 'y': 1794}, {'x': 2240, 'y': 2056}, {'x': 297, 'y': 2056}], 'category': 'paragraph', 'html': \"<br><p id='95' style='font-size:20px'>Models based on the f(x, w) used by the perceptron and ADALINE are called<br>linear models. These models remain some of the most widely used machine learning<br>models, though in many cases they are trained in different ways than the original<br>models were trained.</p>\", 'id': 95, 'page': 15, 'text': 'Models based on the f(x, w) used by the perceptron and ADALINE are called\\nlinear models. These models remain some of the most widely used machine learning\\nmodels, though in many cases they are trained in different ways than the original\\nmodels were trained.'}, {'bounding_box': [{'x': 296, 'y': 2080}, {'x': 2242, 'y': 2080}, {'x': 2242, 'y': 2413}, {'x': 296, 'y': 2413}], 'category': 'paragraph', 'html': \"<p id='96' style='font-size:22px'>Linear models have many limitations. Most famously, they cannot learn the<br>XOR function, where f ([0,1] , w) = 1 and f([1, 0], w) = 1 but f([1, 1], w) = 0<br>and f ([0, 0], w) = 0. Critics who observed these flaws in linear models caused<br>a backlash against biologically inspired learning in general (Minsky and Papert,<br>1969). This was the first major dip in the popularity of neural networks.</p>\", 'id': 96, 'page': 15, 'text': 'Linear models have many limitations. Most famously, they cannot learn the\\nXOR function, where f ([0,1] , w) = 1 and f([1, 0], w) = 1 but f([1, 1], w) = 0\\nand f ([0, 0], w) = 0. Critics who observed these flaws in linear models caused\\na backlash against biologically inspired learning in general (Minsky and Papert,\\n1969). This was the first major dip in the popularity of neural networks.'}, {'bounding_box': [{'x': 301, 'y': 2439}, {'x': 2241, 'y': 2439}, {'x': 2241, 'y': 2564}, {'x': 301, 'y': 2564}], 'category': 'paragraph', 'html': \"<br><p id='97' style='font-size:18px'>Today, neuroscience is regarded as an important source of inspiration for deep<br>learning researchers, but it is no longer the predominant guide for the field.</p>\", 'id': 97, 'page': 15, 'text': 'Today, neuroscience is regarded as an important source of inspiration for deep\\nlearning researchers, but it is no longer the predominant guide for the field.'}, {'bounding_box': [{'x': 299, 'y': 2594}, {'x': 2242, 'y': 2594}, {'x': 2242, 'y': 2989}, {'x': 299, 'y': 2989}], 'category': 'paragraph', 'html': \"<p id='98' style='font-size:18px'>The main reason for the diminished role of neuroscience in deep learning<br>research today is that we simply do not have enough information about the brain<br>to use it as a guide. To obtain a deep understanding of the actual algorithms used<br>by the brain, we would need to be able to monitor the activity of (at the very<br>least) thousands of interconnected neurons simultaneously. Because we are not<br>able to do this, we are far from understanding even some of the most simple and</p>\", 'id': 98, 'page': 15, 'text': 'The main reason for the diminished role of neuroscience in deep learning\\nresearch today is that we simply do not have enough information about the brain\\nto use it as a guide. To obtain a deep understanding of the actual algorithms used\\nby the brain, we would need to be able to monitor the activity of (at the very\\nleast) thousands of interconnected neurons simultaneously. Because we are not\\nable to do this, we are far from understanding even some of the most simple and'}, {'bounding_box': [{'x': 1244, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='99' style='font-size:14px'>15</footer>\", 'id': 99, 'page': 15, 'text': '15'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='100' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 100, 'page': 16, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 294, 'y': 313}, {'x': 1723, 'y': 313}, {'x': 1723, 'y': 372}, {'x': 294, 'y': 372}], 'category': 'paragraph', 'html': \"<p id='101' style='font-size:20px'>well-studied parts of the brain (Olshausen and Field, 2005).</p>\", 'id': 101, 'page': 16, 'text': 'well-studied parts of the brain (Olshausen and Field, 2005).'}, {'bounding_box': [{'x': 296, 'y': 396}, {'x': 2242, 'y': 396}, {'x': 2242, 'y': 1069}, {'x': 296, 'y': 1069}], 'category': 'paragraph', 'html': '<br><p id=\\'102\\' style=\\'font-size:18px\\'>Neuroscience has given us a reason to hope that a single deep learning algorithm<br>can solve many different tasks. Neuroscientists have found that ferrets can learn to<br>\"see\" with the auditory processing region of their brain if their brains are rewired<br>to send visual signals to that area (Von Melchner et al., 2000). This suggests that<br>much of the mammalian brain might use a single algorithm to solve most of the<br>different tasks that the brain solves. Before this hypothesis, machine learning<br>research was more fragmented, with different communities of researchers studying<br>natural language processing, vision, motion planning and speech recognition. Today,<br>these application communities are still separate, but it is common for deep learning<br>research groups to study many or even all of these application areas simultaneously.</p>', 'id': 102, 'page': 16, 'text': 'Neuroscience has given us a reason to hope that a single deep learning algorithm\\ncan solve many different tasks. Neuroscientists have found that ferrets can learn to\\n\"see\" with the auditory processing region of their brain if their brains are rewired\\nto send visual signals to that area (Von Melchner et al., 2000). This suggests that\\nmuch of the mammalian brain might use a single algorithm to solve most of the\\ndifferent tasks that the brain solves. Before this hypothesis, machine learning\\nresearch was more fragmented, with different communities of researchers studying\\nnatural language processing, vision, motion planning and speech recognition. Today,\\nthese application communities are still separate, but it is common for deep learning\\nresearch groups to study many or even all of these application areas simultaneously.'}, {'bounding_box': [{'x': 298, 'y': 1089}, {'x': 2244, 'y': 1089}, {'x': 2244, 'y': 2381}, {'x': 298, 'y': 2381}], 'category': 'paragraph', 'html': \"<br><p id='103' style='font-size:18px'>We are able to draw some rough guidelines from neuroscience. The basic idea of<br>having many computational units that become intelligent only via their interactions<br>with each other is inspired by the brain. The Neocognitron (Fukushima, 1980)<br>introduced a powerful model architecture for processing images that was inspired<br>by the structure of the mammalian visual system and later became the basis for<br>the modern convolutional network (LeCun et al., 1998b), as we will see in Sec. 9.10.<br>Most neural networks today are based on a model neuron called the rectified linear<br>unit. The original Cognitron (Fukushima, 1975) introduced a more complicated<br>version that was highly inspired by our knowledge of brain function. The simplified<br>modern version was developed incorporating ideas from many viewpoints, with Nair<br>and Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence, and<br>Jarrett et al. (2009) citing more engineering-oriented influences. While neuroscience<br>is an important source of inspiration, it need not be taken as a rigid guide. We<br>know that actual neurons compute very different functions than modern rectified<br>linear units, but greater neural realism has not yet led to an improvement in<br>machine learning performance. Also, while neuroscience has successfully inspired<br>several neural network architectures, we do not yet know enough about biological<br>learning for neuroscience to offer much guidance for the learning algorithms we<br>use to train these architectures.</p>\", 'id': 103, 'page': 16, 'text': 'We are able to draw some rough guidelines from neuroscience. The basic idea of\\nhaving many computational units that become intelligent only via their interactions\\nwith each other is inspired by the brain. The Neocognitron (Fukushima, 1980)\\nintroduced a powerful model architecture for processing images that was inspired\\nby the structure of the mammalian visual system and later became the basis for\\nthe modern convolutional network (LeCun et al., 1998b), as we will see in Sec. 9.10.\\nMost neural networks today are based on a model neuron called the rectified linear\\nunit. The original Cognitron (Fukushima, 1975) introduced a more complicated\\nversion that was highly inspired by our knowledge of brain function. The simplified\\nmodern version was developed incorporating ideas from many viewpoints, with Nair\\nand Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence, and\\nJarrett et al. (2009) citing more engineering-oriented influences. While neuroscience\\nis an important source of inspiration, it need not be taken as a rigid guide. We\\nknow that actual neurons compute very different functions than modern rectified\\nlinear units, but greater neural realism has not yet led to an improvement in\\nmachine learning performance. Also, while neuroscience has successfully inspired\\nseveral neural network architectures, we do not yet know enough about biological\\nlearning for neuroscience to offer much guidance for the learning algorithms we\\nuse to train these architectures.'}, {'bounding_box': [{'x': 296, 'y': 2401}, {'x': 2243, 'y': 2401}, {'x': 2243, 'y': 2941}, {'x': 296, 'y': 2941}], 'category': 'paragraph', 'html': \"<br><p id='104' style='font-size:18px'>Media accounts often emphasize the similarity of deep learning to the brain.<br>While it is true that deep learning researchers are more likely to cite the brain as an<br>influence than researchers working in other machine learning fields such as kernel<br>machines or Bayesian statistics, one should not view deep learning as an attempt<br>to simulate the brain. Modern deep learning draws inspiration from many fields,<br>especially applied math fundamentals like linear algebra, probability, information<br>theory, and numerical optimization. While some deep learning researchers cite<br>neuroscience as an important source of inspiration, others are not concerned with</p>\", 'id': 104, 'page': 16, 'text': 'Media accounts often emphasize the similarity of deep learning to the brain.\\nWhile it is true that deep learning researchers are more likely to cite the brain as an\\ninfluence than researchers working in other machine learning fields such as kernel\\nmachines or Bayesian statistics, one should not view deep learning as an attempt\\nto simulate the brain. Modern deep learning draws inspiration from many fields,\\nespecially applied math fundamentals like linear algebra, probability, information\\ntheory, and numerical optimization. While some deep learning researchers cite\\nneuroscience as an important source of inspiration, others are not concerned with'}, {'bounding_box': [{'x': 1244, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='105' style='font-size:14px'>16</footer>\", 'id': 105, 'page': 16, 'text': '16'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='106' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 106, 'page': 17, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 302, 'y': 317}, {'x': 758, 'y': 317}, {'x': 758, 'y': 371}, {'x': 302, 'y': 371}], 'category': 'paragraph', 'html': \"<p id='107' style='font-size:16px'>neuroscience at all.</p>\", 'id': 107, 'page': 17, 'text': 'neuroscience at all.'}, {'bounding_box': [{'x': 296, 'y': 397}, {'x': 2243, 'y': 397}, {'x': 2243, 'y': 933}, {'x': 296, 'y': 933}], 'category': 'paragraph', 'html': '<br><p id=\\'108\\' style=\\'font-size:20px\\'>It is worth noting that the effort to understand how the brain works on<br>an algorithmic level is alive and well. This endeavor is primarily known as<br>\"computational neuroscience\" and is a separate field of study from deep learning.<br>It is common for researchers to move back and forth between both fields. The<br>field of deep learning is primarily concerned with how to build computer systems<br>that are able to successfully solve tasks requiring intelligence, while the field of<br>computational neuroscience is primarily concerned with building more accurate<br>models of how the brain actually works.</p>', 'id': 108, 'page': 17, 'text': 'It is worth noting that the effort to understand how the brain works on\\nan algorithmic level is alive and well. This endeavor is primarily known as\\n\"computational neuroscience\" and is a separate field of study from deep learning.\\nIt is common for researchers to move back and forth between both fields. The\\nfield of deep learning is primarily concerned with how to build computer systems\\nthat are able to successfully solve tasks requiring intelligence, while the field of\\ncomputational neuroscience is primarily concerned with building more accurate\\nmodels of how the brain actually works.'}, {'bounding_box': [{'x': 297, 'y': 957}, {'x': 2241, 'y': 957}, {'x': 2241, 'y': 1699}, {'x': 297, 'y': 1699}], 'category': 'paragraph', 'html': \"<br><p id='109' style='font-size:22px'>In the 1980s, the second wave of neural network research emerged in great part<br>via a movement called connectionism or parallel distributed processing (Rumelhart<br>et al., 1986c; McClelland et al., 1995). Connectionism arose in the context of<br>cognitive science. Cognitive science is an interdisciplinary approach to understand-<br>ing the mind, combining multiple different levels of analysis. During the early<br>1980s, most cognitive scientists studied models of symbolic reasoning. Despite their<br>popularity, symbolic models were difficult to explain in terms of how the brain<br>could actually implement them using neurons. The connectionists began to study<br>models of cognition that could actually be grounded in neural implementations<br>(Touretzky and Minton, 1985), reviving many ideas dating back to the work of<br>psychologist Donald Hebb in the 1940s (Hebb, 1949).</p>\", 'id': 109, 'page': 17, 'text': 'In the 1980s, the second wave of neural network research emerged in great part\\nvia a movement called connectionism or parallel distributed processing (Rumelhart\\net al., 1986c; McClelland et al., 1995). Connectionism arose in the context of\\ncognitive science. Cognitive science is an interdisciplinary approach to understand-\\ning the mind, combining multiple different levels of analysis. During the early\\n1980s, most cognitive scientists studied models of symbolic reasoning. Despite their\\npopularity, symbolic models were difficult to explain in terms of how the brain\\ncould actually implement them using neurons. The connectionists began to study\\nmodels of cognition that could actually be grounded in neural implementations\\n(Touretzky and Minton, 1985), reviving many ideas dating back to the work of\\npsychologist Donald Hebb in the 1940s (Hebb, 1949).'}, {'bounding_box': [{'x': 299, 'y': 1722}, {'x': 2243, 'y': 1722}, {'x': 2243, 'y': 1989}, {'x': 299, 'y': 1989}], 'category': 'paragraph', 'html': \"<br><p id='110' style='font-size:18px'>The central idea in connectionism is that a large number of simple computational<br>units can achieve intelligent behavior when networked together. This insight<br>applies equally to neurons in biological nervous systems and to hidden units in<br>computational models.</p>\", 'id': 110, 'page': 17, 'text': 'The central idea in connectionism is that a large number of simple computational\\nunits can achieve intelligent behavior when networked together. This insight\\napplies equally to neurons in biological nervous systems and to hidden units in\\ncomputational models.'}, {'bounding_box': [{'x': 301, 'y': 2013}, {'x': 2243, 'y': 2013}, {'x': 2243, 'y': 2137}, {'x': 301, 'y': 2137}], 'category': 'paragraph', 'html': \"<br><p id='111' style='font-size:20px'>Several key concepts arose during the connectionism movement of the 1980s<br>that remain central to today's deep learning.</p>\", 'id': 111, 'page': 17, 'text': \"Several key concepts arose during the connectionism movement of the 1980s\\nthat remain central to today's deep learning.\"}, {'bounding_box': [{'x': 297, 'y': 2166}, {'x': 2242, 'y': 2166}, {'x': 2242, 'y': 2975}, {'x': 297, 'y': 2975}], 'category': 'paragraph', 'html': \"<p id='112' style='font-size:18px'>One of these concepts is that of distributed representation (Hinton et al., 1986).<br>This is the idea that each input to a system should be represented by many features,<br>and each feature should be involved in the representation of many possible inputs.<br>For example, suppose we have a vision system that can recognize cars, trucks, and<br>birds and these objects can each be red, green, or blue. One way of representing<br>these inputs would be to have a separate neuron or hidden unit that activates for<br>each of the nine possible combinations: red truck, red car, red bird, green truck, and<br>SO on. This requires nine different neurons, and each neuron must independently<br>learn the concept of color and object identity. One way to improve on this situation<br>is to use a distributed representation, with three neurons describing the color and<br>three neurons describing the object identity. This requires only six neurons total<br>instead of nine, and the neuron describing redness is able to learn about redness</p>\", 'id': 112, 'page': 17, 'text': 'One of these concepts is that of distributed representation (Hinton et al., 1986).\\nThis is the idea that each input to a system should be represented by many features,\\nand each feature should be involved in the representation of many possible inputs.\\nFor example, suppose we have a vision system that can recognize cars, trucks, and\\nbirds and these objects can each be red, green, or blue. One way of representing\\nthese inputs would be to have a separate neuron or hidden unit that activates for\\neach of the nine possible combinations: red truck, red car, red bird, green truck, and\\nSO on. This requires nine different neurons, and each neuron must independently\\nlearn the concept of color and object identity. One way to improve on this situation\\nis to use a distributed representation, with three neurons describing the color and\\nthree neurons describing the object identity. This requires only six neurons total\\ninstead of nine, and the neuron describing redness is able to learn about redness'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='113' style='font-size:14px'>17</footer>\", 'id': 113, 'page': 17, 'text': '17'}, {'bounding_box': [{'x': 293, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='114' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 114, 'page': 18, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 296, 'y': 314}, {'x': 2242, 'y': 314}, {'x': 2242, 'y': 508}, {'x': 296, 'y': 508}], 'category': 'paragraph', 'html': \"<p id='115' style='font-size:18px'>from images of cars, trucks and birds, not only from images of one specific category<br>of objects. The concept of distributed representation is central to this book, and<br>will be described in greater detail in Chapter 15.</p>\", 'id': 115, 'page': 18, 'text': 'from images of cars, trucks and birds, not only from images of one specific category\\nof objects. The concept of distributed representation is central to this book, and\\nwill be described in greater detail in Chapter 15.'}, {'bounding_box': [{'x': 297, 'y': 534}, {'x': 2245, 'y': 534}, {'x': 2245, 'y': 868}, {'x': 297, 'y': 868}], 'category': 'paragraph', 'html': \"<br><p id='116' style='font-size:18px'>Another major accomplishment of the connectionist movement was the suc-<br>cessful use of back-propagation to train deep neural networks with internal repre-<br>sentations and the popularization of the back-propagation algorithm (Rumelhart<br>et al., 1986a; LeCun, 1987). This algorithm has waxed and waned in popularity<br>but as of this writing is currently the dominant approach to training deep models.</p>\", 'id': 116, 'page': 18, 'text': 'Another major accomplishment of the connectionist movement was the suc-\\ncessful use of back-propagation to train deep neural networks with internal repre-\\nsentations and the popularization of the back-propagation algorithm (Rumelhart\\net al., 1986a; LeCun, 1987). This algorithm has waxed and waned in popularity\\nbut as of this writing is currently the dominant approach to training deep models.'}, {'bounding_box': [{'x': 296, 'y': 890}, {'x': 2242, 'y': 890}, {'x': 2242, 'y': 1360}, {'x': 296, 'y': 1360}], 'category': 'paragraph', 'html': \"<br><p id='117' style='font-size:20px'>During the 1990s, researchers made important advances in modeling sequences<br>with neural networks. Hochreiter (1991) and Bengio et al. (1994) identified some<br>of the fundamental mathematical difficulties in modeling long sequences, described<br>in Sec. 10.7. Hochreiter and Schmidhuber (1997) introduced the long short-term<br>memory or LSTM network to resolve some of these difficulties. Today, the LSTM<br>is widely used for many sequence modeling tasks, including many natural language<br>processing tasks at Google.</p>\", 'id': 117, 'page': 18, 'text': 'During the 1990s, researchers made important advances in modeling sequences\\nwith neural networks. Hochreiter (1991) and Bengio et al. (1994) identified some\\nof the fundamental mathematical difficulties in modeling long sequences, described\\nin Sec. 10.7. Hochreiter and Schmidhuber (1997) introduced the long short-term\\nmemory or LSTM network to resolve some of these difficulties. Today, the LSTM\\nis widely used for many sequence modeling tasks, including many natural language\\nprocessing tasks at Google.'}, {'bounding_box': [{'x': 297, 'y': 1383}, {'x': 2245, 'y': 1383}, {'x': 2245, 'y': 1921}, {'x': 297, 'y': 1921}], 'category': 'paragraph', 'html': \"<br><p id='118' style='font-size:20px'>The second wave of neural networks research lasted until the mid-1990s. Ven-<br>tures based on neural networks and other AI technologies began to make unrealisti-<br>cally ambitious claims while seeking investments. When AI research did not fulfill<br>these unreasonable expectations, investors were disappointed. Simultaneously,<br>other fields of machine learning made advances. Kernel machines (Boser et al.,<br>1992; Cortes and Vapnik, 1995; Scholkopf et al., 1999) and graphical models (Jor-<br>dan, 1998) both achieved good results on many important tasks. These two factors<br>led to a decline in the popularity of neural networks that lasted until 2007.</p>\", 'id': 118, 'page': 18, 'text': 'The second wave of neural networks research lasted until the mid-1990s. Ven-\\ntures based on neural networks and other AI technologies began to make unrealisti-\\ncally ambitious claims while seeking investments. When AI research did not fulfill\\nthese unreasonable expectations, investors were disappointed. Simultaneously,\\nother fields of machine learning made advances. Kernel machines (Boser et al.,\\n1992; Cortes and Vapnik, 1995; Scholkopf et al., 1999) and graphical models (Jor-\\ndan, 1998) both achieved good results on many important tasks. These two factors\\nled to a decline in the popularity of neural networks that lasted until 2007.'}, {'bounding_box': [{'x': 297, 'y': 1943}, {'x': 2243, 'y': 1943}, {'x': 2243, 'y': 2549}, {'x': 297, 'y': 2549}], 'category': 'paragraph', 'html': \"<br><p id='119' style='font-size:22px'>During this time, neural networks continued to obtain impressive performance<br>on some tasks (LeCun et al., 1998b; Bengio et al., 2001). The Canadian Institute<br>for Advanced Research (CIFAR) helped to keep neural networks research alive<br>via its Neural Computation and Adaptive Perception (NCAP) research initiative.<br>This program united machine learning research groups led by Geoffrey Hinton<br>at University of Toronto, Yoshua Bengio at University of Montreal, and Yann<br>LeCun at New York University. The CIFAR NCAP research initiative had a<br>multi-disciplinary nature that also included neuroscientists and experts in human<br>and computer vision.</p>\", 'id': 119, 'page': 18, 'text': 'During this time, neural networks continued to obtain impressive performance\\non some tasks (LeCun et al., 1998b; Bengio et al., 2001). The Canadian Institute\\nfor Advanced Research (CIFAR) helped to keep neural networks research alive\\nvia its Neural Computation and Adaptive Perception (NCAP) research initiative.\\nThis program united machine learning research groups led by Geoffrey Hinton\\nat University of Toronto, Yoshua Bengio at University of Montreal, and Yann\\nLeCun at New York University. The CIFAR NCAP research initiative had a\\nmulti-disciplinary nature that also included neuroscientists and experts in human\\nand computer vision.'}, {'bounding_box': [{'x': 297, 'y': 2573}, {'x': 2242, 'y': 2573}, {'x': 2242, 'y': 2905}, {'x': 297, 'y': 2905}], 'category': 'paragraph', 'html': \"<br><p id='120' style='font-size:18px'>At this point in time, deep networks were generally believed to be very difficult<br>to train. We now know that algorithms that have existed since the 1980s work<br>quite well, but this was not apparent circa 2006. The issue is perhaps simply that<br>these algorithms were too computationally costly to allow much experimentation<br>with the hardware available at the time.</p>\", 'id': 120, 'page': 18, 'text': 'At this point in time, deep networks were generally believed to be very difficult\\nto train. We now know that algorithms that have existed since the 1980s work\\nquite well, but this was not apparent circa 2006. The issue is perhaps simply that\\nthese algorithms were too computationally costly to allow much experimentation\\nwith the hardware available at the time.'}, {'bounding_box': [{'x': 384, 'y': 2929}, {'x': 2239, 'y': 2929}, {'x': 2239, 'y': 2988}, {'x': 384, 'y': 2988}], 'category': 'paragraph', 'html': \"<br><p id='121' style='font-size:16px'>The third wave of neural networks research began with a breakthrough in</p>\", 'id': 121, 'page': 18, 'text': 'The third wave of neural networks research began with a breakthrough in'}, {'bounding_box': [{'x': 1244, 'y': 3040}, {'x': 1294, 'y': 3040}, {'x': 1294, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='122' style='font-size:14px'>18</footer>\", 'id': 122, 'page': 18, 'text': '18'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 171}, {'x': 294, 'y': 171}], 'category': 'header', 'html': \"<header id='123' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 123, 'page': 19, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 298, 'y': 310}, {'x': 2249, 'y': 310}, {'x': 2249, 'y': 1597}, {'x': 298, 'y': 1597}], 'category': 'paragraph', 'html': \"<p id='124' style='font-size:20px'>2006. Geoffrey Hinton showed that a kind of neural network called a deep belief<br>network could be efficiently trained using a strategy called greedy layer-wise<br>pretraining (Hinton et al., 2006), which will be described in more detail in Sec.<br>15.1. The other CIFAR-affiliated research groups quickly showed that the same<br>strategy could be used to train many other kinds of deep networks (Bengio et al.,<br>2007; Ranzato et al., 2007a) and systematically helped to improve generalization<br>on test examples. This wave of neural networks research popularized the use of the<br>term deep learning to emphasize that researchers were now able to train deeper<br>neural networks than had been possible before, and to focus attention on the<br>theoretical importance of depth (Bengio and LeCun, 2007; Delalleau and Bengio,<br>2011; Pascanu et al., 2014a; Montufar et al., 2014). At this time, deep neural<br>networks outperformed competing AI systems based on other machine learning<br>technologies as well as hand-designed functionality. This third wave of popularity<br>of neural networks continues to the time of this writing, though the focus of deep<br>learning research has changed dramatically within the time of this wave. The<br>third wave began with a focus on new unsupervised learning techniques and the<br>ability of deep models to generalize well from small datasets, but today there is<br>more interest in much older supervised learning algorithms and the ability of deep<br>models to leverage large labeled datasets.</p>\", 'id': 124, 'page': 19, 'text': '2006. Geoffrey Hinton showed that a kind of neural network called a deep belief\\nnetwork could be efficiently trained using a strategy called greedy layer-wise\\npretraining (Hinton et al., 2006), which will be described in more detail in Sec.\\n15.1. The other CIFAR-affiliated research groups quickly showed that the same\\nstrategy could be used to train many other kinds of deep networks (Bengio et al.,\\n2007; Ranzato et al., 2007a) and systematically helped to improve generalization\\non test examples. This wave of neural networks research popularized the use of the\\nterm deep learning to emphasize that researchers were now able to train deeper\\nneural networks than had been possible before, and to focus attention on the\\ntheoretical importance of depth (Bengio and LeCun, 2007; Delalleau and Bengio,\\n2011; Pascanu et al., 2014a; Montufar et al., 2014). At this time, deep neural\\nnetworks outperformed competing AI systems based on other machine learning\\ntechnologies as well as hand-designed functionality. This third wave of popularity\\nof neural networks continues to the time of this writing, though the focus of deep\\nlearning research has changed dramatically within the time of this wave. The\\nthird wave began with a focus on new unsupervised learning techniques and the\\nability of deep models to generalize well from small datasets, but today there is\\nmore interest in much older supervised learning algorithms and the ability of deep\\nmodels to leverage large labeled datasets.'}, {'bounding_box': [{'x': 301, 'y': 1695}, {'x': 1238, 'y': 1695}, {'x': 1238, 'y': 1762}, {'x': 301, 'y': 1762}], 'category': 'paragraph', 'html': \"<p id='125' style='font-size:22px'>1.2.2 Increasing Dataset Sizes</p>\", 'id': 125, 'page': 19, 'text': '1.2.2 Increasing Dataset Sizes'}, {'bounding_box': [{'x': 303, 'y': 1816}, {'x': 2251, 'y': 1816}, {'x': 2251, 'y': 2969}, {'x': 303, 'y': 2969}], 'category': 'paragraph', 'html': \"<p id='126' style='font-size:18px'>One may wonder why deep learning has only recently become recognized as a<br>crucial technology though the first experiments with artificial neural networks were<br>conducted in the 1950s. Deep learning has been successfully used in commercial<br>applications since the 1990s, but was often regarded as being more of an art than<br>a technology and something that only an expert could use, until recently. It is true<br>that some skill is required to get good performance from a deep learning algorithm.<br>Fortunately, the amount of skill required reduces as the amount of training data<br>increases. The learning algorithms reaching human performance on complex tasks<br>today are nearly identical to the learning algorithms that struggled to solve toy<br>problems in the 1980s, though the models we train with these algorithms have<br>undergone changes that simplify the training of very deep architectures. The most<br>important new development is that today we can provide these algorithms with<br>the resources they need to succeed. Fig. 1.8 shows how the size of benchmark<br>datasets has increased remarkably over time. This trend is driven by the increasing<br>digitization of society. As more and more of our activities take place on computers,<br>more and more of what we do is recorded. As our computers are increasingly<br>networked together, it becomes easier to centralize these records and curate them</p>\", 'id': 126, 'page': 19, 'text': 'One may wonder why deep learning has only recently become recognized as a\\ncrucial technology though the first experiments with artificial neural networks were\\nconducted in the 1950s. Deep learning has been successfully used in commercial\\napplications since the 1990s, but was often regarded as being more of an art than\\na technology and something that only an expert could use, until recently. It is true\\nthat some skill is required to get good performance from a deep learning algorithm.\\nFortunately, the amount of skill required reduces as the amount of training data\\nincreases. The learning algorithms reaching human performance on complex tasks\\ntoday are nearly identical to the learning algorithms that struggled to solve toy\\nproblems in the 1980s, though the models we train with these algorithms have\\nundergone changes that simplify the training of very deep architectures. The most\\nimportant new development is that today we can provide these algorithms with\\nthe resources they need to succeed. Fig. 1.8 shows how the size of benchmark\\ndatasets has increased remarkably over time. This trend is driven by the increasing\\ndigitization of society. As more and more of our activities take place on computers,\\nmore and more of what we do is recorded. As our computers are increasingly\\nnetworked together, it becomes easier to centralize these records and curate them'}, {'bounding_box': [{'x': 1244, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3082}, {'x': 1244, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='127' style='font-size:14px'>19</footer>\", 'id': 127, 'page': 19, 'text': '19'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='128' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 128, 'page': 20, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 300, 'y': 313}, {'x': 2244, 'y': 313}, {'x': 2244, 'y': 1052}, {'x': 300, 'y': 1052}], 'category': 'paragraph', 'html': '<p id=\\'129\\' style=\\'font-size:20px\\'>into a dataset appropriate for machine learning applications. The age of \"Big<br>Data\" has made machine learning much easier because the key burden of statistical<br>estimation generalizing well to new data after observing only a small amount<br>of data has been considerably lightened. As of 2016, a rough rule of thumb<br>is that a supervised deep learning algorithm will generally achieve acceptable<br>performance with around 5,000 labeled examples per category, and will match or<br>exceed human performance when trained with a dataset containing at least 10<br>million labeled examples. Working successfully with datasets smaller than this is<br>an important research area, focusing in particular on how we can take advantage<br>of large quantities of unlabeled examples, with unsupervised or semi-supervised<br>learning.</p>', 'id': 129, 'page': 20, 'text': 'into a dataset appropriate for machine learning applications. The age of \"Big\\nData\" has made machine learning much easier because the key burden of statistical\\nestimation generalizing well to new data after observing only a small amount\\nof data has been considerably lightened. As of 2016, a rough rule of thumb\\nis that a supervised deep learning algorithm will generally achieve acceptable\\nperformance with around 5,000 labeled examples per category, and will match or\\nexceed human performance when trained with a dataset containing at least 10\\nmillion labeled examples. Working successfully with datasets smaller than this is\\nan important research area, focusing in particular on how we can take advantage\\nof large quantities of unlabeled examples, with unsupervised or semi-supervised\\nlearning.'}, {'bounding_box': [{'x': 302, 'y': 1151}, {'x': 1196, 'y': 1151}, {'x': 1196, 'y': 1216}, {'x': 302, 'y': 1216}], 'category': 'paragraph', 'html': \"<p id='130' style='font-size:22px'>1.2.3 Increasing Model Sizes</p>\", 'id': 130, 'page': 20, 'text': '1.2.3 Increasing Model Sizes'}, {'bounding_box': [{'x': 298, 'y': 1277}, {'x': 2246, 'y': 1277}, {'x': 2246, 'y': 1609}, {'x': 298, 'y': 1609}], 'category': 'paragraph', 'html': \"<p id='131' style='font-size:18px'>Another key reason that neural networks are wildly successful today after enjoying<br>comparatively little success since the 1980s is that we have the computational<br>resources to run much larger models today. One of the main insights of connection-<br>ism is that animals become intelligent when many of their neurons work together.<br>An individual neuron or small collection of neurons is not particularly useful.</p>\", 'id': 131, 'page': 20, 'text': 'Another key reason that neural networks are wildly successful today after enjoying\\ncomparatively little success since the 1980s is that we have the computational\\nresources to run much larger models today. One of the main insights of connection-\\nism is that animals become intelligent when many of their neurons work together.\\nAn individual neuron or small collection of neurons is not particularly useful.'}, {'bounding_box': [{'x': 297, 'y': 1635}, {'x': 2247, 'y': 1635}, {'x': 2247, 'y': 1829}, {'x': 297, 'y': 1829}], 'category': 'paragraph', 'html': \"<br><p id='132' style='font-size:16px'>Biological neurons are not especially densely connected. As seen in Fig. 1.10,<br>our machine learning models have had a number of connections per neuron that<br>was within an order of magnitude of even mammalian brains for decades.</p>\", 'id': 132, 'page': 20, 'text': 'Biological neurons are not especially densely connected. As seen in Fig. 1.10,\\nour machine learning models have had a number of connections per neuron that\\nwas within an order of magnitude of even mammalian brains for decades.'}, {'bounding_box': [{'x': 300, 'y': 1854}, {'x': 2246, 'y': 1854}, {'x': 2246, 'y': 2527}, {'x': 300, 'y': 2527}], 'category': 'paragraph', 'html': \"<br><p id='133' style='font-size:20px'>In terms of the total number of neurons, neural networks have been astonishingly<br>small until quite recently, as shown in Fig. 1.11. Since the introduction of hidden<br>units, artificial neural networks have doubled in size roughly every 2.4 years. This<br>growth is driven by faster computers with larger memory and by the availability<br>of larger datasets. Larger networks are able to achieve higher accuracy on more<br>complex tasks. This trend looks set to continue for decades. Unless new technologies<br>allow faster scaling, artificial neural networks will not have the same number of<br>neurons as the human brain until at least the 2050s. Biological neurons may<br>represent more complicated functions than current artificial neurons, SO biological<br>neural networks may be even larger than this plot portrays.</p>\", 'id': 133, 'page': 20, 'text': 'In terms of the total number of neurons, neural networks have been astonishingly\\nsmall until quite recently, as shown in Fig. 1.11. Since the introduction of hidden\\nunits, artificial neural networks have doubled in size roughly every 2.4 years. This\\ngrowth is driven by faster computers with larger memory and by the availability\\nof larger datasets. Larger networks are able to achieve higher accuracy on more\\ncomplex tasks. This trend looks set to continue for decades. Unless new technologies\\nallow faster scaling, artificial neural networks will not have the same number of\\nneurons as the human brain until at least the 2050s. Biological neurons may\\nrepresent more complicated functions than current artificial neurons, SO biological\\nneural networks may be even larger than this plot portrays.'}, {'bounding_box': [{'x': 301, 'y': 2550}, {'x': 2245, 'y': 2550}, {'x': 2245, 'y': 2884}, {'x': 301, 'y': 2884}], 'category': 'paragraph', 'html': \"<br><p id='134' style='font-size:20px'>In retrospect, it is not particularly surprising that neural networks with fewer<br>neurons than a leech were unable to solve sophisticated artificial intelligence prob-<br>lems. Even today's networks, which we consider quite large from a computational<br>systems point of view, are smaller than the nervous system of even relatively<br>primitive vertebrate animals like frogs.</p>\", 'id': 134, 'page': 20, 'text': \"In retrospect, it is not particularly surprising that neural networks with fewer\\nneurons than a leech were unable to solve sophisticated artificial intelligence prob-\\nlems. Even today's networks, which we consider quite large from a computational\\nsystems point of view, are smaller than the nervous system of even relatively\\nprimitive vertebrate animals like frogs.\"}, {'bounding_box': [{'x': 385, 'y': 2908}, {'x': 2246, 'y': 2908}, {'x': 2246, 'y': 2966}, {'x': 385, 'y': 2966}], 'category': 'paragraph', 'html': \"<br><p id='135' style='font-size:18px'>The increase in model size over time, due to the availability of faster CPUs,</p>\", 'id': 135, 'page': 20, 'text': 'The increase in model size over time, due to the availability of faster CPUs,'}, {'bounding_box': [{'x': 1243, 'y': 3038}, {'x': 1296, 'y': 3038}, {'x': 1296, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='136' style='font-size:14px'>20</footer>\", 'id': 136, 'page': 20, 'text': '20'}, {'bounding_box': [{'x': 294, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='137' style='font-size:18px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 137, 'page': 21, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 527, 'y': 629}, {'x': 1970, 'y': 629}, {'x': 1970, 'y': 1397}, {'x': 527, 'y': 1397}], 'category': 'figure', 'html': '<figure><img id=\\'138\\' style=\\'font-size:14px\\' alt=\"Increasing dataset size over time\\n109\\nexamples) 107\\n108 Canadian Hansard\\nWMT Sports-1M\\nImageNet10k\\n106 Publie SVHN\\n(number\\n105 Criminals ILSVRC 2014\\nImageNet\\n104\\nMNIST CIF AR-10\\nsize\\n103\\nDataset\\n102 Rotated T VS C\\nTvs Gvs F\\nIris\\n101\\n10\\n1900 1950 1985 2000 2015\" data-coord=\"top-left:(527,629); bottom-right:(1970,1397)\" /></figure>', 'id': 138, 'page': 21, 'text': 'Increasing dataset size over time\\n109\\nexamples) 107\\n108 Canadian Hansard\\nWMT Sports-1M\\nImageNet10k\\n106 Publie SVHN\\n(number\\n105 Criminals ILSVRC 2014\\nImageNet\\n104\\nMNIST CIF AR-10\\nsize\\n103\\nDataset\\n102 Rotated T VS C\\nTvs Gvs F\\nIris\\n101\\n10\\n1900 1950 1985 2000 2015'}, {'bounding_box': [{'x': 299, 'y': 1459}, {'x': 2257, 'y': 1459}, {'x': 2257, 'y': 2660}, {'x': 299, 'y': 2660}], 'category': 'caption', 'html': \"<caption id='139'></caption>\", 'id': 139, 'page': 21, 'text': ''}, {'bounding_box': [{'x': 299, 'y': 1460}, {'x': 2257, 'y': 1460}, {'x': 2257, 'y': 2660}, {'x': 299, 'y': 2660}], 'category': 'paragraph', 'html': \"<br><p id='140' style='font-size:20px'>Figure 1.8: Dataset sizes have increased greatly over time. In the early 1900s, statisticians<br>studied datasets using hundreds or thousands of manually compiled measurements (Garson,<br>1900; Gosset, 1908; Anderson, 1935; Fisher, 1936). In the 1950s through 1980s, the pioneers<br>of biologically inspired machine learning often worked with small, synthetic datasets, such<br>as low-resolution bitmaps of letters, that were designed to incur low computational cost and<br>demonstrate that neural networks were able to learn specific kinds of functions (Widrow<br>and Hoff, 1960; Rumelhart et al., 1986b). In the 1980s and 1990s, machine learning<br>became more statistical in nature and began to leverage larger datasets containing tens<br>of thousands of examples such as the MNIST dataset (shown in Fig. 1.9) of scans of<br>handwritten numbers (LeCun et al. , 1998b). In the first decade of the 2000s, more<br>sophisticated datasets of this same size, such as the CIFAR-10 dataset (Krizhevsky and<br>Hinton, 2009) continued to be produced. Toward the end of that decade and throughout<br>the first half of the 2010s, significantly larger datasets, containing hundreds of thousands<br>to tens of millions of examples, completely changed what was possible with deep learning.<br>These datasets included the public Street View House Numbers dataset (Netzer et al.,<br>2011), various versions of the ImageNet dataset (Deng et al., 2009, 2010a; Russakovsky<br>et al., 2014a), and the Sports-1M dataset (Karpathy et al., 2014). At the top of the<br>graph, we see that datasets of translated sentences, such as IBM's dataset constructed<br>from the Canadian Hansard (Brown et al., 1990) and the WMT 2014 English to French<br>dataset (Schwenk, 2014) are typically far ahead of other dataset sizes.</p>\", 'id': 140, 'page': 21, 'text': \"Figure 1.8: Dataset sizes have increased greatly over time. In the early 1900s, statisticians\\nstudied datasets using hundreds or thousands of manually compiled measurements (Garson,\\n1900; Gosset, 1908; Anderson, 1935; Fisher, 1936). In the 1950s through 1980s, the pioneers\\nof biologically inspired machine learning often worked with small, synthetic datasets, such\\nas low-resolution bitmaps of letters, that were designed to incur low computational cost and\\ndemonstrate that neural networks were able to learn specific kinds of functions (Widrow\\nand Hoff, 1960; Rumelhart et al., 1986b). In the 1980s and 1990s, machine learning\\nbecame more statistical in nature and began to leverage larger datasets containing tens\\nof thousands of examples such as the MNIST dataset (shown in Fig. 1.9) of scans of\\nhandwritten numbers (LeCun et al. , 1998b). In the first decade of the 2000s, more\\nsophisticated datasets of this same size, such as the CIFAR-10 dataset (Krizhevsky and\\nHinton, 2009) continued to be produced. Toward the end of that decade and throughout\\nthe first half of the 2010s, significantly larger datasets, containing hundreds of thousands\\nto tens of millions of examples, completely changed what was possible with deep learning.\\nThese datasets included the public Street View House Numbers dataset (Netzer et al.,\\n2011), various versions of the ImageNet dataset (Deng et al., 2009, 2010a; Russakovsky\\net al., 2014a), and the Sports-1M dataset (Karpathy et al., 2014). At the top of the\\ngraph, we see that datasets of translated sentences, such as IBM's dataset constructed\\nfrom the Canadian Hansard (Brown et al., 1990) and the WMT 2014 English to French\\ndataset (Schwenk, 2014) are typically far ahead of other dataset sizes.\"}, {'bounding_box': [{'x': 1242, 'y': 3038}, {'x': 1292, 'y': 3038}, {'x': 1292, 'y': 3083}, {'x': 1242, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='141' style='font-size:16px'>21</footer>\", 'id': 141, 'page': 21, 'text': '21'}, {'bounding_box': [{'x': 293, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='142' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 142, 'page': 22, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 475, 'y': 530}, {'x': 2047, 'y': 530}, {'x': 2047, 'y': 2105}, {'x': 475, 'y': 2105}], 'category': 'figure', 'html': '<figure><img id=\\'143\\' style=\\'font-size:20px\\' alt=\"8 9 0 1 2 3 7 8 9 0 1 2 3 6 7 8 6\\n4 2 6 4 7 / 7 9 2 9 3 2 0 5\\n0 7 0 4 7  0 5 0 8\\n3 0 4 / 6\\n7 5 7 9 2 5\\n3 7 7 0\\n/ 2 9\\n3 7 6\\n1 0 6\\n8 7 4 /\\n6 6 7\\n8  5\\n4 7 O\\n4 2 1\\n7\\n/ 8 8 4\\n7 5 7 I\\n9  X 2 3\\n4 3\\n9 9 3 7 7 9 4 4\\n4 7 5 8 / 4 4 / 8 6 6 6 3 7 2 5 9\" data-coord=\"top-left:(475,530); bottom-right:(2047,2105)\" /></figure>', 'id': 143, 'page': 22, 'text': '8 9 0 1 2 3 7 8 9 0 1 2 3 6 7 8 6\\n4 2 6 4 7 / 7 9 2 9 3 2 0 5\\n0 7 0 4 7  0 5 0 8\\n3 0 4 / 6\\n7 5 7 9 2 5\\n3 7 7 0\\n/ 2 9\\n3 7 6\\n1 0 6\\n8 7 4 /\\n6 6 7\\n8  5\\n4 7 O\\n4 2 1\\n7\\n/ 8 8 4\\n7 5 7 I\\n9  X 2 3\\n4 3\\n9 9 3 7 7 9 4 4\\n4 7 5 8 / 4 4 / 8 6 6 6 3 7 2 5 9'}, {'bounding_box': [{'x': 297, 'y': 2146}, {'x': 2255, 'y': 2146}, {'x': 2255, 'y': 2745}, {'x': 297, 'y': 2745}], 'category': 'caption', 'html': '<caption id=\\'144\\' style=\\'font-size:20px\\'>Figure 1.9: Example inputs from the MNIST dataset. The \"NIST\" stands for National<br>Institute of Standards and Technology, the agency that originally collected this data.<br>The \"M\" stands for \"modified,\" since the data has been preprocessed for easier use with<br>machine learning algorithms. The MNIST dataset consists of scans of handwritten digits<br>and associated labels describing which digit 0-9 is contained in each image. This simple<br>classification problem is one of the simplest and most widely used tests in deep learning<br>research. It remains popular despite being quite easy for modern techniques to solve.<br>Geoffrey Hinton has described it as \"the drosophila of machine learning,\" meaning that<br>it allows machine learning researchers to study their algorithms in controlled laboratory<br>conditions, much as biologists often study fruit flies.</caption>', 'id': 144, 'page': 22, 'text': 'Figure 1.9: Example inputs from the MNIST dataset. The \"NIST\" stands for National\\nInstitute of Standards and Technology, the agency that originally collected this data.\\nThe \"M\" stands for \"modified,\" since the data has been preprocessed for easier use with\\nmachine learning algorithms. The MNIST dataset consists of scans of handwritten digits\\nand associated labels describing which digit 0-9 is contained in each image. This simple\\nclassification problem is one of the simplest and most widely used tests in deep learning\\nresearch. It remains popular despite being quite easy for modern techniques to solve.\\nGeoffrey Hinton has described it as \"the drosophila of machine learning,\" meaning that\\nit allows machine learning researchers to study their algorithms in controlled laboratory\\nconditions, much as biologists often study fruit flies.'}, {'bounding_box': [{'x': 297, 'y': 2144}, {'x': 2255, 'y': 2144}, {'x': 2255, 'y': 2745}, {'x': 297, 'y': 2745}], 'category': 'paragraph', 'html': \"<br><p id='145'></p>\", 'id': 145, 'page': 22, 'text': ''}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3082}, {'x': 1243, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='146' style='font-size:14px'>22</footer>\", 'id': 146, 'page': 22, 'text': '22'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 171}, {'x': 294, 'y': 171}], 'category': 'header', 'html': \"<header id='147' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 147, 'page': 23, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 299, 'y': 313}, {'x': 2243, 'y': 313}, {'x': 2243, 'y': 578}, {'x': 299, 'y': 578}], 'category': 'paragraph', 'html': \"<p id='148' style='font-size:18px'>the advent of general purpose GPUs (described in Sec. 12.1.2), faster network<br>connectivity and better software infrastructure for distributed computing, is one of<br>the most important trends in the history of deep learning. This trend is generally<br>expected to continue well into the future.</p>\", 'id': 148, 'page': 23, 'text': 'the advent of general purpose GPUs (described in Sec. 12.1.2), faster network\\nconnectivity and better software infrastructure for distributed computing, is one of\\nthe most important trends in the history of deep learning. This trend is generally\\nexpected to continue well into the future.'}, {'bounding_box': [{'x': 300, 'y': 677}, {'x': 2221, 'y': 677}, {'x': 2221, 'y': 743}, {'x': 300, 'y': 743}], 'category': 'paragraph', 'html': \"<p id='149' style='font-size:22px'>1.2.4 Increasing Accuracy, Complexity and Real- World Impact</p>\", 'id': 149, 'page': 23, 'text': '1.2.4 Increasing Accuracy, Complexity and Real- World Impact'}, {'bounding_box': [{'x': 300, 'y': 799}, {'x': 2245, 'y': 799}, {'x': 2245, 'y': 994}, {'x': 300, 'y': 994}], 'category': 'paragraph', 'html': \"<p id='150' style='font-size:18px'>Since the 1980s, deep learning has consistently improved in its ability to provide<br>accurate recognition or prediction. Moreover, deep learning has consistently been<br>applied with success to broader and broader sets of applications.</p>\", 'id': 150, 'page': 23, 'text': 'Since the 1980s, deep learning has consistently improved in its ability to provide\\naccurate recognition or prediction. Moreover, deep learning has consistently been\\napplied with success to broader and broader sets of applications.'}, {'bounding_box': [{'x': 301, 'y': 1022}, {'x': 2245, 'y': 1022}, {'x': 2245, 'y': 2306}, {'x': 301, 'y': 2306}], 'category': 'paragraph', 'html': \"<br><p id='151' style='font-size:18px'>The earliest deep models were used to recognize individual objects in tightly<br>cropped, extremely small images (Rumelhart et al., 1986a). Since then there has<br>been a gradual increase in the size of images neural networks could process. Modern<br>object recognition networks process rich high-resolution photographs and do not<br>have a requirement that the photo be cropped near the object to be recognized<br>(Krizhevsky et al., 2012). Similarly, the earliest networks could only recognize<br>two kinds of objects (or in some cases, the absence or presence of a single kind of<br>object), while these modern networks typically recognize at least 1,000 different<br>categories of objects. The largest contest in object recognition is the ImageNet<br>Large-Scale Visual Recognition Challenge (ILSVRC) held each year. A dramatic<br>moment in the meteoric rise of deep learning came when a convolutional network<br>won this challenge for the first time and by a wide margin, bringing down the<br>state-of-the-art top-5 error rate from 26.1% to 15.3% (Krizhevsky et al., 2012),<br>meaning that the convolutional network produces a ranked list of possible categories<br>for each image and the correct category appeared in the first five entries of this<br>list for all but 15.3% of the test examples. Since then, these competitions are<br>consistently won by deep convolutional nets, and as of this writing, advances in<br>deep learning have brought the latest top-5 error rate in this contest down to 3.6%,<br>as shown in Fig. 1.12.</p>\", 'id': 151, 'page': 23, 'text': 'The earliest deep models were used to recognize individual objects in tightly\\ncropped, extremely small images (Rumelhart et al., 1986a). Since then there has\\nbeen a gradual increase in the size of images neural networks could process. Modern\\nobject recognition networks process rich high-resolution photographs and do not\\nhave a requirement that the photo be cropped near the object to be recognized\\n(Krizhevsky et al., 2012). Similarly, the earliest networks could only recognize\\ntwo kinds of objects (or in some cases, the absence or presence of a single kind of\\nobject), while these modern networks typically recognize at least 1,000 different\\ncategories of objects. The largest contest in object recognition is the ImageNet\\nLarge-Scale Visual Recognition Challenge (ILSVRC) held each year. A dramatic\\nmoment in the meteoric rise of deep learning came when a convolutional network\\nwon this challenge for the first time and by a wide margin, bringing down the\\nstate-of-the-art top-5 error rate from 26.1% to 15.3% (Krizhevsky et al., 2012),\\nmeaning that the convolutional network produces a ranked list of possible categories\\nfor each image and the correct category appeared in the first five entries of this\\nlist for all but 15.3% of the test examples. Since then, these competitions are\\nconsistently won by deep convolutional nets, and as of this writing, advances in\\ndeep learning have brought the latest top-5 error rate in this contest down to 3.6%,\\nas shown in Fig. 1.12.'}, {'bounding_box': [{'x': 297, 'y': 2331}, {'x': 2242, 'y': 2331}, {'x': 2242, 'y': 2730}, {'x': 297, 'y': 2730}], 'category': 'paragraph', 'html': \"<br><p id='152' style='font-size:18px'>Deep learning has also had a dramatic impact on speech recognition. After<br>improving throughout the 1990s, the error rates for speech recognition stagnated<br>starting in about 2000. The introduction of deep learning (Dahl et al., 2010; Deng<br>et al., 2010b; Seide et al., 2011; Hinton et al., 2012a) to speech recognition resulted<br>in a sudden drop of error rates, with some error rates cut in half. We will explore<br>this history in more detail in Sec. 12.3.</p>\", 'id': 152, 'page': 23, 'text': 'Deep learning has also had a dramatic impact on speech recognition. After\\nimproving throughout the 1990s, the error rates for speech recognition stagnated\\nstarting in about 2000. The introduction of deep learning (Dahl et al., 2010; Deng\\net al., 2010b; Seide et al., 2011; Hinton et al., 2012a) to speech recognition resulted\\nin a sudden drop of error rates, with some error rates cut in half. We will explore\\nthis history in more detail in Sec. 12.3.'}, {'bounding_box': [{'x': 295, 'y': 2759}, {'x': 2246, 'y': 2759}, {'x': 2246, 'y': 2950}, {'x': 295, 'y': 2950}], 'category': 'paragraph', 'html': \"<br><p id='153' style='font-size:20px'>Deep networks have also had spectacular successes for pedestrian detection and<br>image segmentation (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al.,<br>2013) and yielded superhuman performance in traffic sign classification (Ciresan</p>\", 'id': 153, 'page': 23, 'text': 'Deep networks have also had spectacular successes for pedestrian detection and\\nimage segmentation (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al.,\\n2013) and yielded superhuman performance in traffic sign classification (Ciresan'}, {'bounding_box': [{'x': 1244, 'y': 3038}, {'x': 1295, 'y': 3038}, {'x': 1295, 'y': 3083}, {'x': 1244, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='154' style='font-size:14px'>23</footer>\", 'id': 154, 'page': 23, 'text': '23'}, {'bounding_box': [{'x': 294, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='155' style='font-size:20px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 155, 'page': 24, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 494, 'y': 692}, {'x': 2029, 'y': 692}, {'x': 2029, 'y': 1450}, {'x': 494, 'y': 1450}], 'category': 'figure', 'html': '<figure><img id=\\'156\\' style=\\'font-size:14px\\' alt=\"Number of connections per neuron over time\\n10 4\\nneuron\\nHuman\\n3\\nper 10\\nConnections 7 Cat\\n2\\nMouse\\n102\\n5 10\\n1\\n3\\n10 1 Fruit fly\\n1950\\n1985\\n2000\\n2015\" data-coord=\"top-left:(494,692); bottom-right:(2029,1450)\" /></figure>', 'id': 156, 'page': 24, 'text': 'Number of connections per neuron over time\\n10 4\\nneuron\\nHuman\\n3\\nper 10\\nConnections 7 Cat\\n2\\nMouse\\n102\\n5 10\\n1\\n3\\n10 1 Fruit fly\\n1950\\n1985\\n2000\\n2015'}, {'bounding_box': [{'x': 300, 'y': 1512}, {'x': 2252, 'y': 1512}, {'x': 2252, 'y': 1932}, {'x': 300, 'y': 1932}], 'category': 'paragraph', 'html': \"<p id='157' style='font-size:22px'>Figure 1.10: Initially, the number of connections between neurons in artificial neural<br>networks was limited by hardware capabilities. Today, the number of connections between<br>neurons is mostly a design consideration. Some artificial neural networks have nearly as<br>many connections per neuron as a cat, and it is quite common for other neural networks<br>to have as many connections per neuron as smaller mammals like mice. Even the human<br>brain does not have an exorbitant amount of connections per neuron. Biological neural<br>network sizes from Wikipedia (2015).</p>\", 'id': 157, 'page': 24, 'text': 'Figure 1.10: Initially, the number of connections between neurons in artificial neural\\nnetworks was limited by hardware capabilities. Today, the number of connections between\\nneurons is mostly a design consideration. Some artificial neural networks have nearly as\\nmany connections per neuron as a cat, and it is quite common for other neural networks\\nto have as many connections per neuron as smaller mammals like mice. Even the human\\nbrain does not have an exorbitant amount of connections per neuron. Biological neural\\nnetwork sizes from Wikipedia (2015).'}, {'bounding_box': [{'x': 372, 'y': 1990}, {'x': 1583, 'y': 1990}, {'x': 1583, 'y': 2552}, {'x': 372, 'y': 2552}], 'category': 'figure', 'html': '<figure><img id=\\'158\\' alt=\"\" data-coord=\"top-left:(372,1990); bottom-right:(1583,2552)\" /></figure>', 'id': 158, 'page': 24, 'text': ''}, {'bounding_box': [{'x': 368, 'y': 1990}, {'x': 1582, 'y': 1990}, {'x': 1582, 'y': 2553}, {'x': 368, 'y': 2553}], 'category': 'paragraph', 'html': \"<br><p id='159' style='font-size:16px'>1. Adaptive linear element (Widrow and Hoff, 1960)<br>2. Neocognitron (Fukushima, 1980)<br>3. GPU-accelerated convolutional network (Chellapilla et al., 2006)<br>4. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)<br>5. Unsupervised convolutional network (Jarrett et al., 2009)<br>6. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)<br>7. Distributed autoencoder (Le et al., 2012)<br>8. Multi-GPU convolutional network (Krizhevsky et al., 2012)<br>9. COTS HPC unsupervised convolutional network (Coates et al., 2013)<br>10. GoogLeNet (Szegedy et al., 2014a)</p>\", 'id': 159, 'page': 24, 'text': '1. Adaptive linear element (Widrow and Hoff, 1960)\\n2. Neocognitron (Fukushima, 1980)\\n3. GPU-accelerated convolutional network (Chellapilla et al., 2006)\\n4. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)\\n5. Unsupervised convolutional network (Jarrett et al., 2009)\\n6. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)\\n7. Distributed autoencoder (Le et al., 2012)\\n8. Multi-GPU convolutional network (Krizhevsky et al., 2012)\\n9. COTS HPC unsupervised convolutional network (Coates et al., 2013)\\n10. GoogLeNet (Szegedy et al., 2014a)'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1295, 'y': 3039}, {'x': 1295, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='160' style='font-size:18px'>24</footer>\", 'id': 160, 'page': 24, 'text': '24'}, {'bounding_box': [{'x': 294, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='161' style='font-size:14px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 161, 'page': 25, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 296, 'y': 317}, {'x': 598, 'y': 317}, {'x': 598, 'y': 371}, {'x': 296, 'y': 371}], 'category': 'paragraph', 'html': \"<p id='162' style='font-size:22px'>et al., 2012.</p>\", 'id': 162, 'page': 25, 'text': 'et al., 2012.'}, {'bounding_box': [{'x': 297, 'y': 395}, {'x': 2244, 'y': 395}, {'x': 2244, 'y': 1136}, {'x': 297, 'y': 1136}], 'category': 'paragraph', 'html': \"<br><p id='163' style='font-size:16px'>At the same time that the scale and accuracy of deep networks has increased,<br>SO has the complexity of the tasks that they can solve. Goodfellow et al. (2014d)<br>showed that neural networks could learn to output an entire sequence of characters<br>transcribed from an image, rather than just identifying a single object. Previously,<br>it was widely believed that this kind of learning required labeling of the individual<br>elements of the sequence (Gulehre and Bengio, 2013). Recurrent neural networks,<br>such as the LSTM sequence model mentioned above, are now used to model<br>relationships between sequences and other sequences rather than just fixed inputs.<br>This sequence-to-sequence learning seems to be on the cusp of revolutionizing<br>another application: machine translation (Sutskever et al., 2014; Bahdanau et al.,<br>2015).</p>\", 'id': 163, 'page': 25, 'text': 'At the same time that the scale and accuracy of deep networks has increased,\\nSO has the complexity of the tasks that they can solve. Goodfellow et al. (2014d)\\nshowed that neural networks could learn to output an entire sequence of characters\\ntranscribed from an image, rather than just identifying a single object. Previously,\\nit was widely believed that this kind of learning required labeling of the individual\\nelements of the sequence (Gulehre and Bengio, 2013). Recurrent neural networks,\\nsuch as the LSTM sequence model mentioned above, are now used to model\\nrelationships between sequences and other sequences rather than just fixed inputs.\\nThis sequence-to-sequence learning seems to be on the cusp of revolutionizing\\nanother application: machine translation (Sutskever et al., 2014; Bahdanau et al.,\\n2015).'}, {'bounding_box': [{'x': 298, 'y': 1161}, {'x': 2242, 'y': 1161}, {'x': 2242, 'y': 1631}, {'x': 298, 'y': 1631}], 'category': 'paragraph', 'html': \"<br><p id='164' style='font-size:16px'>This trend of increasing complexity has been pushed to its logical conclusion<br>with the introduction of neural Turing machines (Graves et al., 2014a) that learn<br>to read from memory cells and write arbitrary content to memory cells. Such<br>neural networks can learn simple programs from examples of desired behavior. For<br>example, they can learn to sort lists of numbers given examples of scrambled and<br>sorted sequences. This self-programming technology is in its infancy, but in the<br>future could in principle be applied to nearly any task.</p>\", 'id': 164, 'page': 25, 'text': 'This trend of increasing complexity has been pushed to its logical conclusion\\nwith the introduction of neural Turing machines (Graves et al., 2014a) that learn\\nto read from memory cells and write arbitrary content to memory cells. Such\\nneural networks can learn simple programs from examples of desired behavior. For\\nexample, they can learn to sort lists of numbers given examples of scrambled and\\nsorted sequences. This self-programming technology is in its infancy, but in the\\nfuture could in principle be applied to nearly any task.'}, {'bounding_box': [{'x': 298, 'y': 1655}, {'x': 2242, 'y': 1655}, {'x': 2242, 'y': 2191}, {'x': 298, 'y': 2191}], 'category': 'paragraph', 'html': \"<br><p id='165' style='font-size:18px'>Another crowning achievement of deep learning is its extension to the domain<br>of reinforcement learning. In the context of reinforcement learning, an autonomous<br>agent must learn to perform a task by trial and error, without any guidance from<br>the human operator. DeepMind demonstrated that a reinforcement learning system<br>based on deep learning is capable of learning to play Atari video games, reaching<br>human-level performance on many tasks (Mnih et al., 2015). Deep learning has<br>also significantly improved the performance of reinforcement learning for robotics<br>(Finn et al., 2015).</p>\", 'id': 165, 'page': 25, 'text': 'Another crowning achievement of deep learning is its extension to the domain\\nof reinforcement learning. In the context of reinforcement learning, an autonomous\\nagent must learn to perform a task by trial and error, without any guidance from\\nthe human operator. DeepMind demonstrated that a reinforcement learning system\\nbased on deep learning is capable of learning to play Atari video games, reaching\\nhuman-level performance on many tasks (Mnih et al., 2015). Deep learning has\\nalso significantly improved the performance of reinforcement learning for robotics\\n(Finn et al., 2015).'}, {'bounding_box': [{'x': 300, 'y': 2217}, {'x': 2245, 'y': 2217}, {'x': 2245, 'y': 2413}, {'x': 300, 'y': 2413}], 'category': 'paragraph', 'html': \"<br><p id='166' style='font-size:20px'>Many of these applications of deep learning are highly profitable. Deep learning<br>is now used by many top technology companies including Google, Microsoft,<br>Facebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC.</p>\", 'id': 166, 'page': 25, 'text': 'Many of these applications of deep learning are highly profitable. Deep learning\\nis now used by many top technology companies including Google, Microsoft,\\nFacebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC.'}, {'bounding_box': [{'x': 296, 'y': 2437}, {'x': 2243, 'y': 2437}, {'x': 2243, 'y': 2834}, {'x': 296, 'y': 2834}], 'category': 'paragraph', 'html': \"<br><p id='167' style='font-size:20px'>Advances in deep learning have also depended heavily on advances in software<br>infrastructure. Software libraries such as Theano (Bergstra et al., 2010; Bastien<br>et al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b),<br>DistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and<br>TensorFlow (Abadi et al., 2015) have all supported important research projects or<br>commercial products.</p>\", 'id': 167, 'page': 25, 'text': 'Advances in deep learning have also depended heavily on advances in software\\ninfrastructure. Software libraries such as Theano (Bergstra et al., 2010; Bastien\\net al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b),\\nDistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and\\nTensorFlow (Abadi et al., 2015) have all supported important research projects or\\ncommercial products.'}, {'bounding_box': [{'x': 299, 'y': 2862}, {'x': 2241, 'y': 2862}, {'x': 2241, 'y': 2989}, {'x': 299, 'y': 2989}], 'category': 'paragraph', 'html': \"<br><p id='168' style='font-size:16px'>Deep learning has also made contributions back to other sciences. Modern<br>convolutional networks for object recognition provide a model of visual processing</p>\", 'id': 168, 'page': 25, 'text': 'Deep learning has also made contributions back to other sciences. Modern\\nconvolutional networks for object recognition provide a model of visual processing'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3083}, {'x': 1243, 'y': 3083}], 'category': 'footer', 'html': \"<footer id='169' style='font-size:14px'>25</footer>\", 'id': 169, 'page': 25, 'text': '25'}, {'bounding_box': [{'x': 295, 'y': 121}, {'x': 998, 'y': 121}, {'x': 998, 'y': 170}, {'x': 295, 'y': 170}], 'category': 'header', 'html': \"<header id='170' style='font-size:16px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 170, 'page': 26, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 301, 'y': 311}, {'x': 2245, 'y': 311}, {'x': 2245, 'y': 848}, {'x': 301, 'y': 848}], 'category': 'paragraph', 'html': \"<p id='171' style='font-size:20px'>that neuroscientists can study (DiCarlo, 2013). Deep learning also provides useful<br>tools for processing massive amounts of data and making useful predictions in<br>scientific fields. It has been successfully used to predict how molecules will interact<br>in order to help pharmaceutical companies design new drugs (Dahl et al., 2014),<br>to search for subatomic particles (Baldi et al., 2014), and to automatically parse<br>microscope images used to construct a 3-D map of the human brain (Knowles-<br>Barley et al., 2014). We expect deep learning to appear in more and more scientific<br>fields in the future.</p>\", 'id': 171, 'page': 26, 'text': 'that neuroscientists can study (DiCarlo, 2013). Deep learning also provides useful\\ntools for processing massive amounts of data and making useful predictions in\\nscientific fields. It has been successfully used to predict how molecules will interact\\nin order to help pharmaceutical companies design new drugs (Dahl et al., 2014),\\nto search for subatomic particles (Baldi et al., 2014), and to automatically parse\\nmicroscope images used to construct a 3-D map of the human brain (Knowles-\\nBarley et al., 2014). We expect deep learning to appear in more and more scientific\\nfields in the future.'}, {'bounding_box': [{'x': 301, 'y': 872}, {'x': 2244, 'y': 872}, {'x': 2244, 'y': 1342}, {'x': 301, 'y': 1342}], 'category': 'paragraph', 'html': \"<br><p id='172' style='font-size:18px'>In summary, deep learning is an approach to machine learning that has drawn<br>heavily on our knowledge of the human brain, statistics and applied math as it<br>developed over the past several decades. In recent years, it has seen tremendous<br>growth in its popularity and usefulness, due in large part to more powerful com-<br>puters, larger datasets and techniques to train deeper networks. The years ahead<br>are full of challenges and opportunities to improve deep learning even further and<br>bring it to new frontiers.</p>\", 'id': 172, 'page': 26, 'text': 'In summary, deep learning is an approach to machine learning that has drawn\\nheavily on our knowledge of the human brain, statistics and applied math as it\\ndeveloped over the past several decades. In recent years, it has seen tremendous\\ngrowth in its popularity and usefulness, due in large part to more powerful com-\\nputers, larger datasets and techniques to train deeper networks. The years ahead\\nare full of challenges and opportunities to improve deep learning even further and\\nbring it to new frontiers.'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3082}, {'x': 1243, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='173' style='font-size:14px'>26</footer>\", 'id': 173, 'page': 26, 'text': '26'}, {'bounding_box': [{'x': 293, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 293, 'y': 170}], 'category': 'header', 'html': \"<header id='174' style='font-size:20px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 174, 'page': 27, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 499, 'y': 499}, {'x': 2057, 'y': 499}, {'x': 2057, 'y': 1257}, {'x': 499, 'y': 1257}], 'category': 'figure', 'html': '<figure><img id=\\'175\\' style=\\'font-size:14px\\' alt=\"Increasing neural network size over time\\nscale)\\n1011\\nHuman\\n1010\\n17 20\\n(logarithmic\\n109 16 19\\nOctopus\\n108 14\\n107 Frog\\n106 8\\nBee\\n105 3 \\nAnt\\nneurons\\n104\\n103\\nLeech\\n13\\n102\\n2\\nof 101 1 12\\n15 Roundworm\\n100 9\\nNumber\\n10\\n10-1 7\\n4\\n10-2\\nSponge\\n1950 1985 2000 2015 2056\" data-coord=\"top-left:(499,499); bottom-right:(2057,1257)\" /></figure>', 'id': 175, 'page': 27, 'text': 'Increasing neural network size over time\\nscale)\\n1011\\nHuman\\n1010\\n17 20\\n(logarithmic\\n109 16 19\\nOctopus\\n108 14\\n107 Frog\\n106 8\\nBee\\n105 3 \\nAnt\\nneurons\\n104\\n103\\nLeech\\n13\\n102\\n2\\nof 101 1 12\\n15 Roundworm\\n100 9\\nNumber\\n10\\n10-1 7\\n4\\n10-2\\nSponge\\n1950 1985 2000 2015 2056'}, {'bounding_box': [{'x': 298, 'y': 1319}, {'x': 2253, 'y': 1319}, {'x': 2253, 'y': 1442}, {'x': 298, 'y': 1442}], 'category': 'caption', 'html': \"<caption id='176'></caption>\", 'id': 176, 'page': 27, 'text': ''}, {'bounding_box': [{'x': 296, 'y': 1319}, {'x': 2253, 'y': 1319}, {'x': 2253, 'y': 1440}, {'x': 296, 'y': 1440}], 'category': 'paragraph', 'html': \"<br><p id='177' style='font-size:22px'>Figure 1.11: Since the introduction of hidden units, artificial neural networks have doubled<br>in size roughly every 2.4 years. Biological neural network sizes from Wikipedia (2015).</p>\", 'id': 177, 'page': 27, 'text': 'Figure 1.11: Since the introduction of hidden units, artificial neural networks have doubled\\nin size roughly every 2.4 years. Biological neural network sizes from Wikipedia (2015).'}, {'bounding_box': [{'x': 363, 'y': 1495}, {'x': 1723, 'y': 1495}, {'x': 1723, 'y': 2567}, {'x': 363, 'y': 2567}], 'category': 'paragraph', 'html': \"<p id='178' style='font-size:16px'>1. Perceptron (Rosenblatt, 1958, 1962)<br>2. Adaptive linear element (Widrow and Hoff, 1960)<br>3. Neocognitron (Fukushima, 1980)<br>4. Early back-propagation network (Rumelhart et al., 1986b)<br>5. Recurrent neural network for speech recognition (Robinson and Fallside, 1991)<br>6. Multilayer perceptron for speech recognition (Bengio et al., 1991)<br>7. Mean field sigmoid belief network (Saul et al., 1996)<br>8. LeNet-5 (LeCun et al., 1998b)<br>9. Echo state network (Jaeger and Haas, 2004)<br>10. Deep belief network (Hinton et al., 2006)<br>11. GPU-accelerated convolutional network (Chellapilla et al., 2006)<br>12. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)<br>13. GPU-accelerated deep belief network (Raina et al., 2009)<br>14. Unsupervised convolutional network (Jarrett et al., 2009)<br>15. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)<br>16. OMP-1 network (Coates and Ng, 2011)<br>17. Distributed autoencoder (Le et al., 2012)<br>18. Multi-GPU convolutional network (Krizhevsky et al., 2012)<br>19. COTS HPC unsupervised convolutional network (Coates et al., 2013)<br>20. GoogLeNet (Szegedy et al., 2014a)</p>\", 'id': 178, 'page': 27, 'text': '1. Perceptron (Rosenblatt, 1958, 1962)\\n2. Adaptive linear element (Widrow and Hoff, 1960)\\n3. Neocognitron (Fukushima, 1980)\\n4. Early back-propagation network (Rumelhart et al., 1986b)\\n5. Recurrent neural network for speech recognition (Robinson and Fallside, 1991)\\n6. Multilayer perceptron for speech recognition (Bengio et al., 1991)\\n7. Mean field sigmoid belief network (Saul et al., 1996)\\n8. LeNet-5 (LeCun et al., 1998b)\\n9. Echo state network (Jaeger and Haas, 2004)\\n10. Deep belief network (Hinton et al., 2006)\\n11. GPU-accelerated convolutional network (Chellapilla et al., 2006)\\n12. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)\\n13. GPU-accelerated deep belief network (Raina et al., 2009)\\n14. Unsupervised convolutional network (Jarrett et al., 2009)\\n15. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)\\n16. OMP-1 network (Coates and Ng, 2011)\\n17. Distributed autoencoder (Le et al., 2012)\\n18. Multi-GPU convolutional network (Krizhevsky et al., 2012)\\n19. COTS HPC unsupervised convolutional network (Coates et al., 2013)\\n20. GoogLeNet (Szegedy et al., 2014a)'}, {'bounding_box': [{'x': 1242, 'y': 3039}, {'x': 1294, 'y': 3039}, {'x': 1294, 'y': 3082}, {'x': 1242, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='179' style='font-size:18px'>27</footer>\", 'id': 179, 'page': 27, 'text': '27'}, {'bounding_box': [{'x': 294, 'y': 122}, {'x': 997, 'y': 122}, {'x': 997, 'y': 170}, {'x': 294, 'y': 170}], 'category': 'header', 'html': \"<header id='180' style='font-size:18px'>CHAPTER 1. INTRODUCTION</header>\", 'id': 180, 'page': 28, 'text': 'CHAPTER 1. INTRODUCTION'}, {'bounding_box': [{'x': 521, 'y': 1122}, {'x': 1956, 'y': 1122}, {'x': 1956, 'y': 1884}, {'x': 521, 'y': 1884}], 'category': 'figure', 'html': '<figure><img id=\\'181\\' style=\\'font-size:14px\\' alt=\"rate 0.30\\nDecreasing error rate over time\\nerror 0.25\\nclassification\\n0.20\\n0.15\\n0.10\\nILSVRC\\n0.05\\n0.00\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\" data-coord=\"top-left:(521,1122); bottom-right:(1956,1884)\" /></figure>', 'id': 181, 'page': 28, 'text': 'rate 0.30\\nDecreasing error rate over time\\nerror 0.25\\nclassification\\n0.20\\n0.15\\n0.10\\nILSVRC\\n0.05\\n0.00\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015'}, {'bounding_box': [{'x': 297, 'y': 1940}, {'x': 2251, 'y': 1940}, {'x': 2251, 'y': 2176}, {'x': 297, 'y': 2176}], 'category': 'caption', 'html': \"<caption id='182' style='font-size:20px'>Figure 1.12: Since deep networks reached the scale necessary to compete in the ImageNet<br>Large Scale Visual Recognition Challenge, they have consistently won the competition<br>every year, and yielded lower and lower error rates each time. Data from Russakovsky<br>et al. (2014b) and He et al. (2015).</caption>\", 'id': 182, 'page': 28, 'text': 'Figure 1.12: Since deep networks reached the scale necessary to compete in the ImageNet\\nLarge Scale Visual Recognition Challenge, they have consistently won the competition\\nevery year, and yielded lower and lower error rates each time. Data from Russakovsky\\net al. (2014b) and He et al. (2015).'}, {'bounding_box': [{'x': 1243, 'y': 3039}, {'x': 1293, 'y': 3039}, {'x': 1293, 'y': 3082}, {'x': 1243, 'y': 3082}], 'category': 'footer', 'html': \"<footer id='183' style='font-size:16px'>28</footer>\", 'id': 183, 'page': 28, 'text': '28'}, {'bounding_box': [{'x': 1119, 'y': 1104}, {'x': 1413, 'y': 1104}, {'x': 1413, 'y': 1188}, {'x': 1119, 'y': 1188}], 'category': 'paragraph', 'html': \"<p id='184' style='font-size:16px'>Part I</p>\", 'id': 184, 'page': 29, 'text': 'Part I'}, {'bounding_box': [{'x': 473, 'y': 1355}, {'x': 2066, 'y': 1355}, {'x': 2066, 'y': 1619}, {'x': 473, 'y': 1619}], 'category': 'paragraph', 'html': \"<p id='185' style='font-size:20px'>Applied Math and Machine<br>Learning Basics</p>\", 'id': 185, 'page': 29, 'text': 'Applied Math and Machine\\nLearning Basics'}, {'bounding_box': [{'x': 1240, 'y': 3031}, {'x': 1297, 'y': 3031}, {'x': 1297, 'y': 3078}, {'x': 1240, 'y': 3078}], 'category': 'footer', 'html': \"<footer id='186' style='font-size:14px'>29</footer>\", 'id': 186, 'page': 29, 'text': '29'}, {'bounding_box': [{'x': 297, 'y': 318}, {'x': 2237, 'y': 318}, {'x': 2237, 'y': 577}, {'x': 297, 'y': 577}], 'category': 'paragraph', 'html': \"<p id='187' style='font-size:16px'>This part of the book introduces the basic mathematical concepts needed to<br>understand deep learning. We begin with general ideas from applied math that<br>allow us to define functions of many variables, find the highest and lowest points<br>on these functions and quantify degrees of belief.</p>\", 'id': 187, 'page': 30, 'text': 'This part of the book introduces the basic mathematical concepts needed to\\nunderstand deep learning. We begin with general ideas from applied math that\\nallow us to define functions of many variables, find the highest and lowest points\\non these functions and quantify degrees of belief.'}, {'bounding_box': [{'x': 297, 'y': 604}, {'x': 2238, 'y': 604}, {'x': 2238, 'y': 867}, {'x': 297, 'y': 867}], 'category': 'paragraph', 'html': \"<br><p id='188' style='font-size:16px'>Next, we describe the fundamental goals of machine learning. We describe how<br>to accomplish these goals by specifying a model that represents certain beliefs,<br>designing a cost function that measures how well those beliefs correspond with<br>reality and using a training algorithm to minimize that cost function.</p>\", 'id': 188, 'page': 30, 'text': 'Next, we describe the fundamental goals of machine learning. We describe how\\nto accomplish these goals by specifying a model that represents certain beliefs,\\ndesigning a cost function that measures how well those beliefs correspond with\\nreality and using a training algorithm to minimize that cost function.'}, {'bounding_box': [{'x': 297, 'y': 896}, {'x': 2238, 'y': 896}, {'x': 2238, 'y': 1151}, {'x': 297, 'y': 1151}], 'category': 'paragraph', 'html': \"<p id='189' style='font-size:20px'>This elementary framework is the basis for a broad variety of machine learning<br>algorithms, including approaches to machine learning that are not deep. In the<br>subsequent parts of the book, we develop deep learning algorithms within this<br>framework.</p>\", 'id': 189, 'page': 30, 'text': 'This elementary framework is the basis for a broad variety of machine learning\\nalgorithms, including approaches to machine learning that are not deep. In the\\nsubsequent parts of the book, we develop deep learning algorithms within this\\nframework.'}, {'bounding_box': [{'x': 1238, 'y': 3041}, {'x': 1289, 'y': 3041}, {'x': 1289, 'y': 3080}, {'x': 1238, 'y': 3080}], 'category': 'footer', 'html': \"<footer id='190' style='font-size:14px'>30</footer>\", 'id': 190, 'page': 30, 'text': '30'}], 'html': '<p id=\\'0\\' style=\\'font-size:20px\\'>Chapter 1</p><p id=\\'1\\' style=\\'font-size:22px\\'>Introduction</p><p id=\\'2\\' style=\\'font-size:18px\\'>Inventors have long dreamed of creating machines that think. This desire dates<br>back to at least the time of ancient Greece. The mythical figures Pygmalion,<br>Daedalus, and Hephaestus may all be interpreted as legendary inventors, and<br>Galatea, Talos, and Pandora may all be regarded as artificial life (Ovid and Martin,<br>2004; Sparkes, 1996; Tandy, 1997).</p><p id=\\'3\\' style=\\'font-size:14px\\'>When programmable computers were first conceived, people wondered whether<br>they might become intelligent, over a hundred years before one was built (Lovelace,<br>1842). Today, artificial intelligence (AI) is a thriving field with many practical<br>applications and active research topics. We look to intelligent software to automate<br>routine labor, understand speech or images, make diagnoses in medicine and<br>support basic scientific research.</p><br><p id=\\'4\\' style=\\'font-size:16px\\'>In the early days of artificial intelligence, the field rapidly tackled and solved<br>problems that are intellectually difficult for human beings but relatively straight-<br>forward for computers problems that can be described by a list of formal, math-<br>ematical rules. The true challenge to artificial intelligence proved to be solving<br>the tasks that are easy for people to perform but hard for people to describe<br>formally problems that we solve intuitively, that feel automatic, like recognizing<br>spoken words or faces in images.</p><p id=\\'5\\' style=\\'font-size:14px\\'>This book is about a solution to these more intuitive problems. This solution is<br>to allow computers to learn from experience and understand the world in terms of a<br>hierarchy of concepts, with each concept defined in terms of its relation to simpler<br>concepts. By gathering knowledge from experience, this approach avoids the need<br>for human operators to formally specify all of the knowledge that the computer<br>needs. The hierarchy of concepts allows the computer to learn complicated concepts<br>by building them out of simpler ones. If we draw a graph showing how these</p><footer id=\\'6\\' style=\\'font-size:14px\\'>1</footer><header id=\\'7\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'8\\' style=\\'font-size:18px\\'>concepts are built on top of each other, the graph is deep, with many layers. For<br>this reason, we call this approach to AI deep learning.</p><br><p id=\\'9\\' style=\\'font-size:20px\\'>Many of the early successes of AI took place in relatively sterile and formal<br>environments and did not require computers to have much knowledge about<br>the world. For example, IBM\\'s Deep Blue chess-playing system defeated world<br>champion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simple<br>world, containing only sixty-four locations and thirty-two pieces that can move<br>in only rigidly circumscribed ways. Devising a successful chess strategy is a<br>tremendous accomplishment, but the challenge is not due to the difficulty of<br>describing the set of chess pieces and allowable moves to the computer. Chess<br>can be completely described by a very brief list of completely formal rules, easily<br>provided ahead of time by the programmer.</p><br><p id=\\'10\\' style=\\'font-size:18px\\'>Ironically, abstract and formal tasks that are among the most difficult mental<br>undertakings for a human being are among the easiest for a computer. Computers<br>have long been able to defeat even the best human chess player, but are only<br>recently matching some of the abilities of average human beings to recognize objects<br>or speech. A person\\'s everyday life requires an immense amount of knowledge<br>about the world. Much of this knowledge is subjective and intuitive, and therefore<br>difficult to articulate in a formal way. Computers need to capture this same<br>knowledge in order to behave in an intelligent way. One of the key challenges in<br>artificial intelligence is how to get this informal knowledge into a computer.</p><br><p id=\\'11\\' style=\\'font-size:18px\\'>Several artificial intelligence projects have sought to hard-code knowledge about<br>the world in formal languages. A computer can reason about statements in these<br>formal languages automatically using logical inference rules. This is known as the<br>knowledge base approach to artificial intelligence. None of these projects has led to<br>a major success. One of the most famous such projects is Cyc (Lenat and Guha,<br>1989). Cyc is an inference engine and a database of statements in a language<br>called CycL. These statements are entered by a staff of human supervisors. It is an<br>unwieldy process. People struggle to devise formal rules with enough complexity<br>to accurately describe the world. For example, Cyc failed to understand a story<br>about a person named Fred shaving in the morning (Linde, 1992). Its inference<br>engine detected an inconsistency in the story: it knew that people do not have<br>electrical parts, but because Fred was holding an electric razor, it believed the<br>entity \"FredWhileShaving\" contained electrical parts. It therefore asked whether<br>Fred was still a person while he was shaving.</p><br><p id=\\'12\\' style=\\'font-size:18px\\'>The difficulties faced by systems relying on hard-coded knowledge suggest that<br>AI systems need the ability to acquire their own knowledge, by extracting patterns<br>from raw data. This capability is known as machine learning. The introduction</p><footer id=\\'13\\' style=\\'font-size:14px\\'>2</footer><header id=\\'14\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'15\\' style=\\'font-size:22px\\'>of machine learning allowed computers to tackle problems involving knowledge<br>of the real world and make decisions that appear subjective. A simple machine<br>learning algorithm called logistic regression can determine whether to recommend<br>cesarean delivery (Mor- Yosef et al., 1990). A simple machine learning algorithm<br>called naive Bayes can separate legitimate e-mail from spam e-mail.</p><br><p id=\\'16\\' style=\\'font-size:20px\\'>The performance of these simple machine learning algorithms depends heavily<br>on the representation of the data they are given. For example, when logistic<br>regression is used to recommend cesarean delivery, the AI system does not examine<br>the patient directly. Instead, the doctor tells the system several pieces of relevant<br>information, such as the presence or absence of a uterine scar. Each piece of<br>information included in the representation of the patient is known as a feature.<br>Logistic regression learns how each of these features of the patient correlates with<br>various outcomes. However, it cannot influence the way that the features are<br>defined in any way. If logistic regression was given an MRI scan of the patient,<br>rather than the doctor\\'s formalized report, it would not be able to make useful<br>predictions. Individual pixels in an MRI scan have negligible correlation with any<br>complications that might occur during delivery.</p><br><p id=\\'17\\' style=\\'font-size:18px\\'>This dependence on representations is a general phenomenon that appears<br>throughout computer science and even daily life. In computer science, opera-<br>tions such as searching a collection of data can proceed exponentially faster if<br>the collection is structured and indexed intelligently. People can easily perform<br>arithmetic on Arabic numerals, but find arithmetic on Roman numerals much<br>more time-consuming. It is not surprising that the choice of representation has an<br>enormous effect on the performance of machine learning algorithms. For a simple<br>visual example, see Fig. 1.1.</p><br><p id=\\'18\\' style=\\'font-size:20px\\'>Many artificial intelligence tasks can be solved by designing the right set of<br>features to extract for that task, then providing these features to a simple machine<br>learning algorithm. For example, a useful feature for speaker identification from<br>sound is an estimate of the size of speaker\\'s vocal tract. It therefore gives a strong<br>clue as to whether the speaker is a man, woman, or child.</p><br><p id=\\'19\\' style=\\'font-size:18px\\'>However, for many tasks, it is difficult to know what features should be extracted.<br>For example, suppose that we would like to write a program to detect cars in<br>photographs. We know that cars have wheels, SO we might like to use the presence<br>of a wheel as a feature. Unfortunately, it is difficult to describe exactly what a<br>wheel looks like in terms of pixel values. A wheel has a simple geometric shape but<br>its image may be complicated by shadows falling on the wheel, the sun glaring off<br>the metal parts of the wheel, the fender of the car or an object in the foreground<br>obscuring part of the wheel, and SO on.</p><footer id=\\'20\\' style=\\'font-size:14px\\'>3</footer><header id=\\'21\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'22\\' style=\\'font-size:18px\\' alt=\"Cartesian coordinates Polar coordinates\" data-coord=\"top-left:(608,311); bottom-right:(1905,1064)\" /><figcaption id=\\'23\\' style=\\'font-size:16px\\'>Figure 1.1: Example of different representations: suppose we want to separate two<br>categories of data by drawing a line between them in a scatterplot. In the plot on the left,<br>we represent some data using Cartesian coordinates, and the task is impossible. In the plot<br>on the right, we represent the data with polar coordinates and the task becomes simple to<br>solve with a vertical line. (Figure produced in collaboration with David Warde-Farley)</figcaption></figure><p id=\\'24\\' style=\\'font-size:20px\\'>One solution to this problem is to use machine learning to discover not only<br>the mapping from representation to output but also the representation itself.<br>This approach is known as representation learning. Learned representations often<br>result in much better performance than can be obtained with hand-designed<br>representations. They also allow AI systems to rapidly adapt to new tasks, with<br>minimal human intervention. A representation learning algorithm can discover a<br>good set of features for a simple task in minutes, or a complex task in hours to<br>months. Manually designing features for a complex task requires a great deal of<br>human time and effort; it can take decades for an entire community of researchers.</p><br><p id=\\'25\\' style=\\'font-size:18px\\'>The quintessential example of a representation learning algorithm is the au-<br>toencoder. An autoencoder is the combination of an encoder function that converts<br>the input data into a different representation, and a decoder function that converts<br>the new representation back into the original format. Autoencoders are trained to<br>preserve as much information as possible when an input is run through the encoder<br>and then the decoder, but are also trained to make the new representation have<br>various nice properties. Different kinds of autoencoders aim to achieve different<br>kinds of properties.</p><br><p id=\\'26\\' style=\\'font-size:22px\\'>When designing features or algorithms for learning features, our goal is usually<br>to separate the factors of variation that explain the observed data. In this context,<br>we use the word \"factors\" simply to refer to separate sources of influence; the factors<br>are usually not combined by multiplication. Such factors are often not quantities</p><footer id=\\'27\\' style=\\'font-size:14px\\'>4</footer><header id=\\'28\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'29\\' style=\\'font-size:18px\\'>that are directly observed. Instead, they may exist either as unobserved objects<br>or unobserved forces in the physical world that affect observable quantities. They<br>may also exist as constructs in the human mind that provide useful simplifying<br>explanations or inferred causes of the observed data. They can be thought of as<br>concepts or abstractions that help us make sense of the rich variability in the data.<br>When analyzing a speech recording, the factors of variation include the speaker\\'s<br>age, their sex, their accent and the words that they are speaking. When analyzing<br>an image of a car, the factors of variation include the position of the car, its color,<br>and the angle and brightness of the sun.</p><p id=\\'30\\' style=\\'font-size:18px\\'>A major source of difficulty in many real-world artificial intelligence applications<br>is that many of the factors of variation influence every single piece of data we are<br>able to observe. The individual pixels in an image of a red car might be very close<br>to black at night. The shape of the car\\'s silhouette depends on the viewing angle.<br>Most applications require us to disentangle the factors of variation and discard the<br>ones that we do not care about.</p><br><p id=\\'31\\' style=\\'font-size:18px\\'>Of course, it can be very difficult to extract such high-level, abstract features<br>from raw data. Many of these factors of variation, such as a speaker\\'s accent,<br>can be identified only using sophisticated, nearly human-level understanding of<br>the data. When it is nearly as difficult to obtain a representation as to solve the<br>original problem, representation learning does not, at first glance, seem to help us.</p><br><p id=\\'32\\' style=\\'font-size:20px\\'>Deep learning solves this central problem in representation learning by introduc-<br>ing representations that are expressed in terms of other, simpler representations.<br>Deep learning allows the computer to build complex concepts out of simpler con-<br>cepts. Fig. 1.2 shows how a deep learning system can represent the concept of an<br>image of a person by combining simpler concepts, such as corners and contours,<br>which are in turn defined in terms of edges.</p><br><p id=\\'33\\' style=\\'font-size:20px\\'>The quintessential example of a deep learning model is the feedforward deep<br>network or multilayer perceptron (MLP). A multilayer perceptron is just a mathe-<br>matical function mapping some set of input values to output values. The function<br>is formed by composing many simpler functions. We can think of each application<br>of a different mathematical function as providing a new representation of the input.</p><br><p id=\\'34\\' style=\\'font-size:18px\\'>The idea of learning the right representation for the data provides one perspec-<br>tive on deep learning. Another perspective on deep learning is that depth allows the<br>computer to learn a multi-step computer program. Each layer of the representation<br>can be thought of as the state of the computer\\'s memory after executing another<br>set of instructions in parallel. Networks with greater depth can execute more<br>instructions in sequence. Sequential instructions offer great power because later<br>instructions can refer back to the results of earlier instructions. According to this</p><footer id=\\'35\\' style=\\'font-size:14px\\'>5</footer><header id=\\'36\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'37\\' style=\\'font-size:18px\\' alt=\"Output\\nCAR PERSON ANIMAL\\n(object identity)\\n3rd hidden layer\\n(object parts)\\n2nd hidden layer\\n(corners and\\ncontours)\\n1st hidden layer\\n(edges)\\nVisible layer\\n(input pixels)\" data-coord=\"top-left:(465,352); bottom-right:(2046,1679)\" /><figcaption id=\\'38\\'></figcaption></figure><br><p id=\\'39\\' style=\\'font-size:20px\\'>Figure 1.2: Illustration of a deep learning model. It is difficult for a computer to understand<br>the meaning of raw sensory input data, such as this image represented as a collection<br>of pixel values. The function mapping from a set of pixels to an object identity is very<br>complicated. Learning or evaluating this mapping seems insurmountable if tackled directly.<br>Deep learning resolves this difficulty by breaking the desired complicated mapping into a<br>series of nested simple mappings, each described by a different layer of the model. The<br>input is presented at the visible layer, SO named because it contains the variables that we<br>are able to observe. Then a series of hidden layers extracts increasingly abstract features<br>from the image. These layers are called \"hidden\" because their values are not given in<br>the data; instead the model must determine which concepts are useful for explaining<br>the relationships in the observed data. The images here are visualizations of the kind<br>of feature represented by each hidden unit. Given the pixels, the first layer can easily<br>identify edges, by comparing the brightness of neighboring pixels. Given the first hidden<br>layer\\'s description of the edges, the second hidden layer can easily search for corners and<br>extended contours, which are recognizable as collections of edges. Given the second hidden<br>layer\\'s description of the image in terms of corners and contours, the third hidden layer<br>can detect entire parts of specific objects, by finding specific collections of contours and<br>corners. Finally, this description of the image in terms of the object parts it contains can<br>be used to recognize the objects present in the image. Images reproduced with permission<br>from Zeiler and Fergus (2014).</p><footer id=\\'40\\' style=\\'font-size:14px\\'>6</footer><header id=\\'41\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'42\\' style=\\'font-size:14px\\' alt=\"Element\\nElement 0 Set\\nSet\\nLogistic Logistic\\nRegression Regression\\nw\\nX1 u X2\\nw 1\" data-coord=\"top-left:(495,297); bottom-right:(2039,1096)\" /><figcaption id=\\'43\\' style=\\'font-size:18px\\'>Figure 1.3: Illustration of computational graphs mapping an input to an output where<br>each node performs an operation. Depth is the length of the longest path from input to<br>output but depends on the definition of what constitutes a possible computational step.<br>The computation depicted in these graphs is the output of a logistic regression model,<br>o(wT x), where 0 is the logistic sigmoid function. If we use addition, multiplication and<br>logistic sigmoids as the elements of our computer language, then this model has depth<br>three. If we view logistic regression as an element itself, then this model has depth one.</figcaption></figure><p id=\\'44\\' style=\\'font-size:20px\\'>view of deep learning, not all of the information in a layer\\'s activations necessarily<br>encodes factors of variation that explain the input. The representation also stores<br>state information that helps to execute a program that can make sense of the input.<br>This state information could be analogous to a counter or pointer in a traditional<br>computer program. It has nothing to do with the content of the input specifically,<br>but it helps the model to organize its processing.</p><br><p id=\\'45\\' style=\\'font-size:20px\\'>There are two main ways of measuring the depth of a model. The first view is<br>based on the number of sequential instructions that must be executed to evaluate<br>the architecture. We can think of this as the length of the longest path through<br>a flow chart that describes how to compute each of the model\\'s outputs given<br>its inputs. Just as two equivalent computer programs will have different lengths<br>depending on which language the program is written in, the same function may be<br>drawn as a flowchart with different depths depending on which functions we allow<br>to be used as individual steps in the flowchart. Fig. 1.3 illustrates how this choice<br>of language can give two different measurements for the same architecture.</p><br><p id=\\'46\\' style=\\'font-size:22px\\'>Another approach, used by deep probabilistic models, regards the depth of a<br>model as being not the depth of the computational graph but the depth of the<br>graph describing how concepts are related to each other. In this case, the depth<br>of the flowchart of the computations needed to compute the representation of</p><header id=\\'47\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'48\\' style=\\'font-size:18px\\'>each concept may be much deeper than the graph of the concepts themselves.<br>This is because the system\\'s understanding of the simpler concepts can be refined<br>given information about the more complex concepts. For example, an AI system<br>observing an image of a face with one eye in shadow may initially only see one eye.<br>After detecting that a face is present, it can then infer that a second eye is probably<br>present as well. In this case, the graph of concepts only includes two layers -a<br>layer for eyes and a layer for faces- but the graph of computations includes 2n<br>layers if we refine our estimate of each concept given the other n times.</p><br><p id=\\'49\\' style=\\'font-size:20px\\'>Because it is not always clear which of these two views- the depth of the<br>computational graph, or the depth of the probabilistic modeling graph is most<br>relevant, and because different people choose different sets of smallest elements<br>from which to construct their graphs, there is no single correct value for the<br>depth of an architecture, just as there is no single correct value for the length of<br>a computer program. Nor is there a consensus about how much depth a model<br>requires to qualify as \"deep.\" However, deep learning can safely be regarded as the<br>study of models that either involve a greater amount of composition of learned<br>functions or learned concepts than traditional machine learning does.</p><br><p id=\\'50\\' style=\\'font-size:20px\\'>To summarize, deep learning, the subject of this book, is an approach to AI.<br>Specifically, it is a type of machine learning, a technique that allows computer<br>systems to improve with experience and data. According to the authors of this<br>book, machine learning is the only viable approach to building AI systems that<br>can operate in complicated, real-world environments. Deep learning is a particular<br>kind of machine learning that achieves great power and flexibility by learning to<br>represent the world as a nested hierarchy of concepts, with each concept defined in<br>relation to simpler concepts, and more abstract representations computed in terms<br>of less abstract ones. Fig. 1.4 illustrates the relationship between these different<br>AI disciplines. Fig. 1.5 gives a high-level schematic of how each works.</p><p id=\\'51\\' style=\\'font-size:22px\\'>1.1 Who Should Read This Book?</p><p id=\\'52\\' style=\\'font-size:20px\\'>This book can be useful for a variety of readers, but we wrote it with two main<br>target audiences in mind. One of these target audiences is university students<br>(undergraduate or graduate) learning about machine learning, including those who<br>are beginning a career in deep learning and artificial intelligence research. The<br>other target audience is software engineers who do not have a machine learning<br>or statistics background, but want to rapidly acquire one and begin using deep<br>learning in their product or platform. Deep learning has already proven useful in<br>many software disciplines including computer vision, speech and audio processing,</p><footer id=\\'53\\' style=\\'font-size:14px\\'>8</footer><header id=\\'54\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'55\\' style=\\'font-size:18px\\' alt=\"Deep learning Example:\\nShallow\\nExample: Example:\\nExample: autoencoders\\nLogistic Knowledge\\nMLPs\\nregression bases\\nRepresentation learning\\nMachine learning\\nAI\" data-coord=\"top-left:(514,749); bottom-right:(2032,2308)\" /><figcaption id=\\'56\\' style=\\'font-size:20px\\'>Figure 1.4: A Venn diagram showing how deep learning is a kind of representation learning,<br>which is in turn a kind of machine learning, which is used for many but not all approaches<br>to AI. Each section of the Venn diagram includes an example of an AI technology.</figcaption></figure><footer id=\\'57\\' style=\\'font-size:14px\\'>9</footer><header id=\\'58\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'59\\' style=\\'font-size:16px\\' alt=\"Output\\nMapping from\\nOutput Output\\nfeatures\\nAdditional\\nMapping from Mapping from layers of more\\nOutput\\nfeatures features abstract\\nfeatures\\nHand- Hand-\\nSimple\\ndesigned designed Features\\nfeatures\\nprogram features\\nInput Input Input Input\\nDeep\\nClassic\\nRule-based learning\\nmachine\\nsystems Representation\\nlearning\\nlearning\" data-coord=\"top-left:(543,481); bottom-right:(1993,2563)\" /><figcaption id=\\'60\\' style=\\'font-size:20px\\'>Figure 1.5: Flowcharts showing how the different parts of an AI system relate to each<br>other within different AI disciplines. Shaded boxes indicate components that are able to<br>learn from data.</figcaption></figure><footer id=\\'61\\' style=\\'font-size:14px\\'>10</footer><header id=\\'62\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'63\\' style=\\'font-size:20px\\'>natural language processing, robotics, bioinformatics and chemistry, video games,<br>search engines, online advertising and finance.</p><br><p id=\\'64\\' style=\\'font-size:18px\\'>This book has been organized into three parts in order to best accommodate a<br>variety of readers. Part I introduces basic mathematical tools and machine learning<br>concepts. Part II describes the most established deep learning algorithms that are<br>essentially solved technologies. Part III describes more speculative ideas that are<br>widely believed to be important for future research in deep learning.</p><br><p id=\\'65\\' style=\\'font-size:20px\\'>Readers should feel free to skip parts that are not relevant given their interests<br>or background. Readers familiar with linear algebra, probability, and fundamental<br>machine learning concepts can skip Part I, for example, while readers who just want<br>to implement a working system need not read beyond Part II. To help choose which<br>chapters to read, Fig. 1.6 provides a flowchart showing the high-level organization<br>of the book.</p><br><p id=\\'66\\' style=\\'font-size:18px\\'>We do assume that all readers come from a computer science background. We<br>assume familiarity with programming, a basic understanding of computational<br>performance issues, complexity theory, introductory level calculus and some of the<br>terminology of graph theory.</p><p id=\\'67\\' style=\\'font-size:22px\\'>1.2 Historical Trends in Deep Learning</p><p id=\\'68\\' style=\\'font-size:18px\\'>It is easiest to understand deep learning with some historical context. Rather than<br>providing a detailed history of deep learning, we identify a few key trends:</p><p id=\\'69\\' style=\\'font-size:18px\\'> Deep learning has had a long and rich history, but has gone by many names<br>reflecting different philosophical viewpoints, and has waxed and waned in<br>popularity.</p><p id=\\'70\\' style=\\'font-size:16px\\'> Deep learning has become more useful as the amount of available training<br>data has increased.</p><p id=\\'71\\' style=\\'font-size:16px\\'> Deep learning models have grown in size over time as computer hardware<br>and software infrastructure for deep learning has improved.</p><p id=\\'72\\' style=\\'font-size:20px\\'> Deep learning has solved increasingly complicated applications with increasing<br>accuracy over time.</p><footer id=\\'73\\' style=\\'font-size:14px\\'>11</footer><header id=\\'74\\' style=\\'font-size:20px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'75\\' style=\\'font-size:14px\\'>1. Introduction</p><caption id=\\'76\\' style=\\'font-size:18px\\'>Part I: Applied Math and Machine Learning Basics</caption><figure><img id=\\'77\\' style=\\'font-size:18px\\' alt=\"3. Probability and\\n2. Linear Algebra\\nInformation Theory\\n4. Numerical 5. Machine Learning\\nComputation Basics\\nPart II: Deep Networks: Modern Practices\\n6. Deep Feedforward\\nNetworks\\n7. Regularization 8. Optimization 9. CNNs 10. RNNs\\n11. Practical\\n12. Applications\\nMethodology\\nPart III: Deep Learning Research\\n13. Linear Factor 15. Representation\\n14. Autoencoders\\nModels Learning\\n16. Structured 17. Monte Carlo\\nProbabilistic Models Methods\\n18. Partition\\n19. Inference\\nFunction\\n20. Deep Generative\\nModels\" data-coord=\"top-left:(516,638); bottom-right:(2014,2819)\" /><figcaption id=\\'78\\' style=\\'font-size:22px\\'>Figure 1.6: The high-level organization of the book. An arrow from one chapter to another<br>indicates that the former chapter is prerequisite material for understanding the latter.</figcaption></figure><footer id=\\'79\\' style=\\'font-size:16px\\'>12</footer><header id=\\'80\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'81\\' style=\\'font-size:22px\\'>1.2.1 The Many N ames and Changing Fortunes of Neural Net-<br>works</p><p id=\\'82\\' style=\\'font-size:16px\\'>We expect that many readers of this book have heard of deep learning as an<br>exciting new technology, and are surprised to see a mention of \"history\" in a book<br>about an emerging field. In fact, deep learning dates back to the 1940s. Deep<br>learning only appears to be new, because it was relatively unpopular for several<br>years preceding its current popularity, and because it has gone through many<br>different names, and has only recently become called \"deep learning.\" The field<br>has been rebranded many times, reflecting the influence of different researchers<br>and different perspectives.</p><br><p id=\\'83\\' style=\\'font-size:20px\\'>A comprehensive history of deep learning is beyond the scope of this textbook.<br>However, some basic context is useful for understanding deep learning. Broadly<br>speaking, there have been three waves of development of deep learning: deep learn-<br>ing known as cybernetics in the 1940s-1960s, deep learning known as connectionism<br>in the 1980s-1990s, and the current resurgence under the name deep learning<br>beginning in 2006. This is quantitatively illustrated in Fig. 1.7.</p><br><p id=\\'84\\' style=\\'font-size:18px\\'>Some of the earliest learning algorithms we recognize today were intended<br>to be computational models of biological learning, i.e. models of how learning<br>happens or could happen in the brain. As a result, one of the names that deep<br>learning has gone by is artificial neural networks (ANNs). The corresponding<br>perspective on deep learning models is that they are engineered systems inspired<br>by the biological brain (whether the human brain or the brain of another animal).<br>While the kinds of neural networks used for machine learning have sometimes<br>been used to understand brain function (Hinton and Shallice, 1991), they are<br>generally not designed to be realistic models of biological function. The neural<br>perspective on deep learning is motivated by two main ideas. One idea is that<br>the brain provides a proof by example that intelligent behavior is possible, and a<br>conceptually straightforward path to building intelligence is to reverse engineer the<br>computational principles behind the brain and duplicate its functionality. Another<br>perspective is that it would be deeply interesting to understand the brain and the<br>principles that underlie human intelligence, SO machine learning models that shed<br>light on these basic scientific questions are useful apart from their ability to solve<br>engineering applications.</p><br><p id=\\'85\\' style=\\'font-size:16px\\'>The modern term \"deep learning\" goes beyond the neuroscientific perspective<br>on the current breed of machine learning models. It appeals to a more general<br>principle of learning multiple levels of composition, which can be applied in machine<br>learning frameworks that are not necessarily neurally inspired.</p><footer id=\\'86\\' style=\\'font-size:14px\\'>13</footer><header id=\\'87\\' style=\\'font-size:18px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'88\\' style=\\'font-size:14px\\' alt=\"Phrase 0.000250\\n0.000200 cybernetics\\nor\\nWord\\n0.000150\\n(connectionism + neural networks)\\nJo\\n0.000100\\nFrequency\\n0.000050\\n0.000000\\n1940\\n1950\\n1960\\n1970\\n1980\\nYear 1990\\n2000\" data-coord=\"top-left:(521,908); bottom-right:(2014,1610)\" /><figcaption id=\\'89\\' style=\\'font-size:20px\\'>Figure 1.7: The figure shows two of the three historical waves of artificial neural nets<br>research, as measured by the frequency of the phrases \"cybernetics\" and \"connectionism\" or<br>\"neural networks\" according to Google Books (the third wave is too recent to appear). The<br>first wave started with cybernetics in the 1940s-1960s, with the development of theories<br>of biological learning (McCulloch and Pitts, 1943; Hebb, 1949) and implementations of<br>the first models such as the perceptron (Rosenblatt, 1958) allowing the training of a single<br>neuron. The second wave started with the connectionist approach of the 1980-1995 period,<br>with back-propagation (Rumelhart et al., 1986a) to train a neural network with one or two<br>hidden layers. The current and third wave, deep learning, started around 2006 (Hinton<br>et al., 2006; Bengio et al., 2007; Ranzato et al., 2007a), and is just now appearing in book<br>form as of 2016. The other two waves similarly appeared in book form much later than<br>the corresponding scientific activity occurred.</figcaption></figure><footer id=\\'90\\' style=\\'font-size:16px\\'>14</footer><header id=\\'91\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'92\\' style=\\'font-size:16px\\'>The earliest predecessors of modern deep learning were simple linear models<br>motivated from a neuroscientific perspective. These models were designed to<br>take a set of n input values X1,    , Xn and associate them with an output y.<br>These models would learn a set of weights w1,    , Wn and compute their output<br>f(x, w) = x1w1 +    + Xn Wn. This first wave of neural networks research was<br>known as cybernetics, as illustrated in Fig. 1.7.</p><p id=\\'93\\' style=\\'font-size:22px\\'>The McCulloch-Pitts Neuron (McCulloch and Pitts, 1943) was an early model<br>of brain function. This linear model could recognize two different categories of<br>inputs by testing whether f (x, w) is positive or negative. Of course, for the model<br>to correspond to the desired definition of the categories, the weights needed to be<br>set correctly. These weights could be set by the human operator. In the 1950s,<br>the perceptron (Rosenblatt, 1958, 1962) became the first model that could learn<br>the weights defining the categories given examples of inputs from each category.<br>The adaptive linear element (ADALINE), which dates from about the same time,<br>simply returned the value of f(x) itself to predict a real number (Widrow and<br>Hoff, 1960), and could also learn to predict these numbers from data.</p><p id=\\'94\\' style=\\'font-size:22px\\'>These simple learning algorithms greatly affected the modern landscape of<br>machine learning. The training algorithm used to adapt the weights of the ADA-<br>LINE was a special case of an algorithm called stochastic gradient descent. Slightly<br>modified versions of the stochastic gradient descent algorithm remain the dominant<br>training algorithms for deep learning models today.</p><br><p id=\\'95\\' style=\\'font-size:20px\\'>Models based on the f(x, w) used by the perceptron and ADALINE are called<br>linear models. These models remain some of the most widely used machine learning<br>models, though in many cases they are trained in different ways than the original<br>models were trained.</p><p id=\\'96\\' style=\\'font-size:22px\\'>Linear models have many limitations. Most famously, they cannot learn the<br>XOR function, where f ([0,1] , w) = 1 and f([1, 0], w) = 1 but f([1, 1], w) = 0<br>and f ([0, 0], w) = 0. Critics who observed these flaws in linear models caused<br>a backlash against biologically inspired learning in general (Minsky and Papert,<br>1969). This was the first major dip in the popularity of neural networks.</p><br><p id=\\'97\\' style=\\'font-size:18px\\'>Today, neuroscience is regarded as an important source of inspiration for deep<br>learning researchers, but it is no longer the predominant guide for the field.</p><p id=\\'98\\' style=\\'font-size:18px\\'>The main reason for the diminished role of neuroscience in deep learning<br>research today is that we simply do not have enough information about the brain<br>to use it as a guide. To obtain a deep understanding of the actual algorithms used<br>by the brain, we would need to be able to monitor the activity of (at the very<br>least) thousands of interconnected neurons simultaneously. Because we are not<br>able to do this, we are far from understanding even some of the most simple and</p><footer id=\\'99\\' style=\\'font-size:14px\\'>15</footer><header id=\\'100\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'101\\' style=\\'font-size:20px\\'>well-studied parts of the brain (Olshausen and Field, 2005).</p><br><p id=\\'102\\' style=\\'font-size:18px\\'>Neuroscience has given us a reason to hope that a single deep learning algorithm<br>can solve many different tasks. Neuroscientists have found that ferrets can learn to<br>\"see\" with the auditory processing region of their brain if their brains are rewired<br>to send visual signals to that area (Von Melchner et al., 2000). This suggests that<br>much of the mammalian brain might use a single algorithm to solve most of the<br>different tasks that the brain solves. Before this hypothesis, machine learning<br>research was more fragmented, with different communities of researchers studying<br>natural language processing, vision, motion planning and speech recognition. Today,<br>these application communities are still separate, but it is common for deep learning<br>research groups to study many or even all of these application areas simultaneously.</p><br><p id=\\'103\\' style=\\'font-size:18px\\'>We are able to draw some rough guidelines from neuroscience. The basic idea of<br>having many computational units that become intelligent only via their interactions<br>with each other is inspired by the brain. The Neocognitron (Fukushima, 1980)<br>introduced a powerful model architecture for processing images that was inspired<br>by the structure of the mammalian visual system and later became the basis for<br>the modern convolutional network (LeCun et al., 1998b), as we will see in Sec. 9.10.<br>Most neural networks today are based on a model neuron called the rectified linear<br>unit. The original Cognitron (Fukushima, 1975) introduced a more complicated<br>version that was highly inspired by our knowledge of brain function. The simplified<br>modern version was developed incorporating ideas from many viewpoints, with Nair<br>and Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence, and<br>Jarrett et al. (2009) citing more engineering-oriented influences. While neuroscience<br>is an important source of inspiration, it need not be taken as a rigid guide. We<br>know that actual neurons compute very different functions than modern rectified<br>linear units, but greater neural realism has not yet led to an improvement in<br>machine learning performance. Also, while neuroscience has successfully inspired<br>several neural network architectures, we do not yet know enough about biological<br>learning for neuroscience to offer much guidance for the learning algorithms we<br>use to train these architectures.</p><br><p id=\\'104\\' style=\\'font-size:18px\\'>Media accounts often emphasize the similarity of deep learning to the brain.<br>While it is true that deep learning researchers are more likely to cite the brain as an<br>influence than researchers working in other machine learning fields such as kernel<br>machines or Bayesian statistics, one should not view deep learning as an attempt<br>to simulate the brain. Modern deep learning draws inspiration from many fields,<br>especially applied math fundamentals like linear algebra, probability, information<br>theory, and numerical optimization. While some deep learning researchers cite<br>neuroscience as an important source of inspiration, others are not concerned with</p><footer id=\\'105\\' style=\\'font-size:14px\\'>16</footer><header id=\\'106\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'107\\' style=\\'font-size:16px\\'>neuroscience at all.</p><br><p id=\\'108\\' style=\\'font-size:20px\\'>It is worth noting that the effort to understand how the brain works on<br>an algorithmic level is alive and well. This endeavor is primarily known as<br>\"computational neuroscience\" and is a separate field of study from deep learning.<br>It is common for researchers to move back and forth between both fields. The<br>field of deep learning is primarily concerned with how to build computer systems<br>that are able to successfully solve tasks requiring intelligence, while the field of<br>computational neuroscience is primarily concerned with building more accurate<br>models of how the brain actually works.</p><br><p id=\\'109\\' style=\\'font-size:22px\\'>In the 1980s, the second wave of neural network research emerged in great part<br>via a movement called connectionism or parallel distributed processing (Rumelhart<br>et al., 1986c; McClelland et al., 1995). Connectionism arose in the context of<br>cognitive science. Cognitive science is an interdisciplinary approach to understand-<br>ing the mind, combining multiple different levels of analysis. During the early<br>1980s, most cognitive scientists studied models of symbolic reasoning. Despite their<br>popularity, symbolic models were difficult to explain in terms of how the brain<br>could actually implement them using neurons. The connectionists began to study<br>models of cognition that could actually be grounded in neural implementations<br>(Touretzky and Minton, 1985), reviving many ideas dating back to the work of<br>psychologist Donald Hebb in the 1940s (Hebb, 1949).</p><br><p id=\\'110\\' style=\\'font-size:18px\\'>The central idea in connectionism is that a large number of simple computational<br>units can achieve intelligent behavior when networked together. This insight<br>applies equally to neurons in biological nervous systems and to hidden units in<br>computational models.</p><br><p id=\\'111\\' style=\\'font-size:20px\\'>Several key concepts arose during the connectionism movement of the 1980s<br>that remain central to today\\'s deep learning.</p><p id=\\'112\\' style=\\'font-size:18px\\'>One of these concepts is that of distributed representation (Hinton et al., 1986).<br>This is the idea that each input to a system should be represented by many features,<br>and each feature should be involved in the representation of many possible inputs.<br>For example, suppose we have a vision system that can recognize cars, trucks, and<br>birds and these objects can each be red, green, or blue. One way of representing<br>these inputs would be to have a separate neuron or hidden unit that activates for<br>each of the nine possible combinations: red truck, red car, red bird, green truck, and<br>SO on. This requires nine different neurons, and each neuron must independently<br>learn the concept of color and object identity. One way to improve on this situation<br>is to use a distributed representation, with three neurons describing the color and<br>three neurons describing the object identity. This requires only six neurons total<br>instead of nine, and the neuron describing redness is able to learn about redness</p><footer id=\\'113\\' style=\\'font-size:14px\\'>17</footer><header id=\\'114\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'115\\' style=\\'font-size:18px\\'>from images of cars, trucks and birds, not only from images of one specific category<br>of objects. The concept of distributed representation is central to this book, and<br>will be described in greater detail in Chapter 15.</p><br><p id=\\'116\\' style=\\'font-size:18px\\'>Another major accomplishment of the connectionist movement was the suc-<br>cessful use of back-propagation to train deep neural networks with internal repre-<br>sentations and the popularization of the back-propagation algorithm (Rumelhart<br>et al., 1986a; LeCun, 1987). This algorithm has waxed and waned in popularity<br>but as of this writing is currently the dominant approach to training deep models.</p><br><p id=\\'117\\' style=\\'font-size:20px\\'>During the 1990s, researchers made important advances in modeling sequences<br>with neural networks. Hochreiter (1991) and Bengio et al. (1994) identified some<br>of the fundamental mathematical difficulties in modeling long sequences, described<br>in Sec. 10.7. Hochreiter and Schmidhuber (1997) introduced the long short-term<br>memory or LSTM network to resolve some of these difficulties. Today, the LSTM<br>is widely used for many sequence modeling tasks, including many natural language<br>processing tasks at Google.</p><br><p id=\\'118\\' style=\\'font-size:20px\\'>The second wave of neural networks research lasted until the mid-1990s. Ven-<br>tures based on neural networks and other AI technologies began to make unrealisti-<br>cally ambitious claims while seeking investments. When AI research did not fulfill<br>these unreasonable expectations, investors were disappointed. Simultaneously,<br>other fields of machine learning made advances. Kernel machines (Boser et al.,<br>1992; Cortes and Vapnik, 1995; Scholkopf et al., 1999) and graphical models (Jor-<br>dan, 1998) both achieved good results on many important tasks. These two factors<br>led to a decline in the popularity of neural networks that lasted until 2007.</p><br><p id=\\'119\\' style=\\'font-size:22px\\'>During this time, neural networks continued to obtain impressive performance<br>on some tasks (LeCun et al., 1998b; Bengio et al., 2001). The Canadian Institute<br>for Advanced Research (CIFAR) helped to keep neural networks research alive<br>via its Neural Computation and Adaptive Perception (NCAP) research initiative.<br>This program united machine learning research groups led by Geoffrey Hinton<br>at University of Toronto, Yoshua Bengio at University of Montreal, and Yann<br>LeCun at New York University. The CIFAR NCAP research initiative had a<br>multi-disciplinary nature that also included neuroscientists and experts in human<br>and computer vision.</p><br><p id=\\'120\\' style=\\'font-size:18px\\'>At this point in time, deep networks were generally believed to be very difficult<br>to train. We now know that algorithms that have existed since the 1980s work<br>quite well, but this was not apparent circa 2006. The issue is perhaps simply that<br>these algorithms were too computationally costly to allow much experimentation<br>with the hardware available at the time.</p><br><p id=\\'121\\' style=\\'font-size:16px\\'>The third wave of neural networks research began with a breakthrough in</p><footer id=\\'122\\' style=\\'font-size:14px\\'>18</footer><header id=\\'123\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'124\\' style=\\'font-size:20px\\'>2006. Geoffrey Hinton showed that a kind of neural network called a deep belief<br>network could be efficiently trained using a strategy called greedy layer-wise<br>pretraining (Hinton et al., 2006), which will be described in more detail in Sec.<br>15.1. The other CIFAR-affiliated research groups quickly showed that the same<br>strategy could be used to train many other kinds of deep networks (Bengio et al.,<br>2007; Ranzato et al., 2007a) and systematically helped to improve generalization<br>on test examples. This wave of neural networks research popularized the use of the<br>term deep learning to emphasize that researchers were now able to train deeper<br>neural networks than had been possible before, and to focus attention on the<br>theoretical importance of depth (Bengio and LeCun, 2007; Delalleau and Bengio,<br>2011; Pascanu et al., 2014a; Montufar et al., 2014). At this time, deep neural<br>networks outperformed competing AI systems based on other machine learning<br>technologies as well as hand-designed functionality. This third wave of popularity<br>of neural networks continues to the time of this writing, though the focus of deep<br>learning research has changed dramatically within the time of this wave. The<br>third wave began with a focus on new unsupervised learning techniques and the<br>ability of deep models to generalize well from small datasets, but today there is<br>more interest in much older supervised learning algorithms and the ability of deep<br>models to leverage large labeled datasets.</p><p id=\\'125\\' style=\\'font-size:22px\\'>1.2.2 Increasing Dataset Sizes</p><p id=\\'126\\' style=\\'font-size:18px\\'>One may wonder why deep learning has only recently become recognized as a<br>crucial technology though the first experiments with artificial neural networks were<br>conducted in the 1950s. Deep learning has been successfully used in commercial<br>applications since the 1990s, but was often regarded as being more of an art than<br>a technology and something that only an expert could use, until recently. It is true<br>that some skill is required to get good performance from a deep learning algorithm.<br>Fortunately, the amount of skill required reduces as the amount of training data<br>increases. The learning algorithms reaching human performance on complex tasks<br>today are nearly identical to the learning algorithms that struggled to solve toy<br>problems in the 1980s, though the models we train with these algorithms have<br>undergone changes that simplify the training of very deep architectures. The most<br>important new development is that today we can provide these algorithms with<br>the resources they need to succeed. Fig. 1.8 shows how the size of benchmark<br>datasets has increased remarkably over time. This trend is driven by the increasing<br>digitization of society. As more and more of our activities take place on computers,<br>more and more of what we do is recorded. As our computers are increasingly<br>networked together, it becomes easier to centralize these records and curate them</p><footer id=\\'127\\' style=\\'font-size:14px\\'>19</footer><header id=\\'128\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'129\\' style=\\'font-size:20px\\'>into a dataset appropriate for machine learning applications. The age of \"Big<br>Data\" has made machine learning much easier because the key burden of statistical<br>estimation generalizing well to new data after observing only a small amount<br>of data has been considerably lightened. As of 2016, a rough rule of thumb<br>is that a supervised deep learning algorithm will generally achieve acceptable<br>performance with around 5,000 labeled examples per category, and will match or<br>exceed human performance when trained with a dataset containing at least 10<br>million labeled examples. Working successfully with datasets smaller than this is<br>an important research area, focusing in particular on how we can take advantage<br>of large quantities of unlabeled examples, with unsupervised or semi-supervised<br>learning.</p><p id=\\'130\\' style=\\'font-size:22px\\'>1.2.3 Increasing Model Sizes</p><p id=\\'131\\' style=\\'font-size:18px\\'>Another key reason that neural networks are wildly successful today after enjoying<br>comparatively little success since the 1980s is that we have the computational<br>resources to run much larger models today. One of the main insights of connection-<br>ism is that animals become intelligent when many of their neurons work together.<br>An individual neuron or small collection of neurons is not particularly useful.</p><br><p id=\\'132\\' style=\\'font-size:16px\\'>Biological neurons are not especially densely connected. As seen in Fig. 1.10,<br>our machine learning models have had a number of connections per neuron that<br>was within an order of magnitude of even mammalian brains for decades.</p><br><p id=\\'133\\' style=\\'font-size:20px\\'>In terms of the total number of neurons, neural networks have been astonishingly<br>small until quite recently, as shown in Fig. 1.11. Since the introduction of hidden<br>units, artificial neural networks have doubled in size roughly every 2.4 years. This<br>growth is driven by faster computers with larger memory and by the availability<br>of larger datasets. Larger networks are able to achieve higher accuracy on more<br>complex tasks. This trend looks set to continue for decades. Unless new technologies<br>allow faster scaling, artificial neural networks will not have the same number of<br>neurons as the human brain until at least the 2050s. Biological neurons may<br>represent more complicated functions than current artificial neurons, SO biological<br>neural networks may be even larger than this plot portrays.</p><br><p id=\\'134\\' style=\\'font-size:20px\\'>In retrospect, it is not particularly surprising that neural networks with fewer<br>neurons than a leech were unable to solve sophisticated artificial intelligence prob-<br>lems. Even today\\'s networks, which we consider quite large from a computational<br>systems point of view, are smaller than the nervous system of even relatively<br>primitive vertebrate animals like frogs.</p><br><p id=\\'135\\' style=\\'font-size:18px\\'>The increase in model size over time, due to the availability of faster CPUs,</p><footer id=\\'136\\' style=\\'font-size:14px\\'>20</footer><header id=\\'137\\' style=\\'font-size:18px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'138\\' style=\\'font-size:14px\\' alt=\"Increasing dataset size over time\\n109\\nexamples) 107\\n108 Canadian Hansard\\nWMT Sports-1M\\nImageNet10k\\n106 Publie SVHN\\n(number\\n105 Criminals ILSVRC 2014\\nImageNet\\n104\\nMNIST CIF AR-10\\nsize\\n103\\nDataset\\n102 Rotated T VS C\\nTvs Gvs F\\nIris\\n101\\n10\\n1900 1950 1985 2000 2015\" data-coord=\"top-left:(527,629); bottom-right:(1970,1397)\" /><figcaption id=\\'139\\'></figcaption></figure><br><p id=\\'140\\' style=\\'font-size:20px\\'>Figure 1.8: Dataset sizes have increased greatly over time. In the early 1900s, statisticians<br>studied datasets using hundreds or thousands of manually compiled measurements (Garson,<br>1900; Gosset, 1908; Anderson, 1935; Fisher, 1936). In the 1950s through 1980s, the pioneers<br>of biologically inspired machine learning often worked with small, synthetic datasets, such<br>as low-resolution bitmaps of letters, that were designed to incur low computational cost and<br>demonstrate that neural networks were able to learn specific kinds of functions (Widrow<br>and Hoff, 1960; Rumelhart et al., 1986b). In the 1980s and 1990s, machine learning<br>became more statistical in nature and began to leverage larger datasets containing tens<br>of thousands of examples such as the MNIST dataset (shown in Fig. 1.9) of scans of<br>handwritten numbers (LeCun et al. , 1998b). In the first decade of the 2000s, more<br>sophisticated datasets of this same size, such as the CIFAR-10 dataset (Krizhevsky and<br>Hinton, 2009) continued to be produced. Toward the end of that decade and throughout<br>the first half of the 2010s, significantly larger datasets, containing hundreds of thousands<br>to tens of millions of examples, completely changed what was possible with deep learning.<br>These datasets included the public Street View House Numbers dataset (Netzer et al.,<br>2011), various versions of the ImageNet dataset (Deng et al., 2009, 2010a; Russakovsky<br>et al., 2014a), and the Sports-1M dataset (Karpathy et al., 2014). At the top of the<br>graph, we see that datasets of translated sentences, such as IBM\\'s dataset constructed<br>from the Canadian Hansard (Brown et al., 1990) and the WMT 2014 English to French<br>dataset (Schwenk, 2014) are typically far ahead of other dataset sizes.</p><footer id=\\'141\\' style=\\'font-size:16px\\'>21</footer><header id=\\'142\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'143\\' style=\\'font-size:20px\\' alt=\"8 9 0 1 2 3 7 8 9 0 1 2 3 6 7 8 6\\n4 2 6 4 7 / 7 9 2 9 3 2 0 5\\n0 7 0 4 7  0 5 0 8\\n3 0 4 / 6\\n7 5 7 9 2 5\\n3 7 7 0\\n/ 2 9\\n3 7 6\\n1 0 6\\n8 7 4 /\\n6 6 7\\n8  5\\n4 7 O\\n4 2 1\\n7\\n/ 8 8 4\\n7 5 7 I\\n9  X 2 3\\n4 3\\n9 9 3 7 7 9 4 4\\n4 7 5 8 / 4 4 / 8 6 6 6 3 7 2 5 9\" data-coord=\"top-left:(475,530); bottom-right:(2047,2105)\" /><figcaption id=\\'144\\' style=\\'font-size:20px\\'>Figure 1.9: Example inputs from the MNIST dataset. The \"NIST\" stands for National<br>Institute of Standards and Technology, the agency that originally collected this data.<br>The \"M\" stands for \"modified,\" since the data has been preprocessed for easier use with<br>machine learning algorithms. The MNIST dataset consists of scans of handwritten digits<br>and associated labels describing which digit 0-9 is contained in each image. This simple<br>classification problem is one of the simplest and most widely used tests in deep learning<br>research. It remains popular despite being quite easy for modern techniques to solve.<br>Geoffrey Hinton has described it as \"the drosophila of machine learning,\" meaning that<br>it allows machine learning researchers to study their algorithms in controlled laboratory<br>conditions, much as biologists often study fruit flies.</figcaption></figure><br><p id=\\'145\\'></p><footer id=\\'146\\' style=\\'font-size:14px\\'>22</footer><header id=\\'147\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'148\\' style=\\'font-size:18px\\'>the advent of general purpose GPUs (described in Sec. 12.1.2), faster network<br>connectivity and better software infrastructure for distributed computing, is one of<br>the most important trends in the history of deep learning. This trend is generally<br>expected to continue well into the future.</p><p id=\\'149\\' style=\\'font-size:22px\\'>1.2.4 Increasing Accuracy, Complexity and Real- World Impact</p><p id=\\'150\\' style=\\'font-size:18px\\'>Since the 1980s, deep learning has consistently improved in its ability to provide<br>accurate recognition or prediction. Moreover, deep learning has consistently been<br>applied with success to broader and broader sets of applications.</p><br><p id=\\'151\\' style=\\'font-size:18px\\'>The earliest deep models were used to recognize individual objects in tightly<br>cropped, extremely small images (Rumelhart et al., 1986a). Since then there has<br>been a gradual increase in the size of images neural networks could process. Modern<br>object recognition networks process rich high-resolution photographs and do not<br>have a requirement that the photo be cropped near the object to be recognized<br>(Krizhevsky et al., 2012). Similarly, the earliest networks could only recognize<br>two kinds of objects (or in some cases, the absence or presence of a single kind of<br>object), while these modern networks typically recognize at least 1,000 different<br>categories of objects. The largest contest in object recognition is the ImageNet<br>Large-Scale Visual Recognition Challenge (ILSVRC) held each year. A dramatic<br>moment in the meteoric rise of deep learning came when a convolutional network<br>won this challenge for the first time and by a wide margin, bringing down the<br>state-of-the-art top-5 error rate from 26.1% to 15.3% (Krizhevsky et al., 2012),<br>meaning that the convolutional network produces a ranked list of possible categories<br>for each image and the correct category appeared in the first five entries of this<br>list for all but 15.3% of the test examples. Since then, these competitions are<br>consistently won by deep convolutional nets, and as of this writing, advances in<br>deep learning have brought the latest top-5 error rate in this contest down to 3.6%,<br>as shown in Fig. 1.12.</p><br><p id=\\'152\\' style=\\'font-size:18px\\'>Deep learning has also had a dramatic impact on speech recognition. After<br>improving throughout the 1990s, the error rates for speech recognition stagnated<br>starting in about 2000. The introduction of deep learning (Dahl et al., 2010; Deng<br>et al., 2010b; Seide et al., 2011; Hinton et al., 2012a) to speech recognition resulted<br>in a sudden drop of error rates, with some error rates cut in half. We will explore<br>this history in more detail in Sec. 12.3.</p><br><p id=\\'153\\' style=\\'font-size:20px\\'>Deep networks have also had spectacular successes for pedestrian detection and<br>image segmentation (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al.,<br>2013) and yielded superhuman performance in traffic sign classification (Ciresan</p><footer id=\\'154\\' style=\\'font-size:14px\\'>23</footer><header id=\\'155\\' style=\\'font-size:20px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'156\\' style=\\'font-size:14px\\' alt=\"Number of connections per neuron over time\\n10 4\\nneuron\\nHuman\\n3\\nper 10\\nConnections 7 Cat\\n2\\nMouse\\n102\\n5 10\\n1\\n3\\n10 1 Fruit fly\\n1950\\n1985\\n2000\\n2015\" data-coord=\"top-left:(494,692); bottom-right:(2029,1450)\" /><figcaption id=\\'157\\' style=\\'font-size:22px\\'>Figure 1.10: Initially, the number of connections between neurons in artificial neural<br>networks was limited by hardware capabilities. Today, the number of connections between<br>neurons is mostly a design consideration. Some artificial neural networks have nearly as<br>many connections per neuron as a cat, and it is quite common for other neural networks<br>to have as many connections per neuron as smaller mammals like mice. Even the human<br>brain does not have an exorbitant amount of connections per neuron. Biological neural<br>network sizes from Wikipedia (2015).</figcaption></figure><figure><img id=\\'158\\' alt=\"\" data-coord=\"top-left:(372,1990); bottom-right:(1583,2552)\" /></figure><br><p id=\\'159\\' style=\\'font-size:16px\\'>1. Adaptive linear element (Widrow and Hoff, 1960)<br>2. Neocognitron (Fukushima, 1980)<br>3. GPU-accelerated convolutional network (Chellapilla et al., 2006)<br>4. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)<br>5. Unsupervised convolutional network (Jarrett et al., 2009)<br>6. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)<br>7. Distributed autoencoder (Le et al., 2012)<br>8. Multi-GPU convolutional network (Krizhevsky et al., 2012)<br>9. COTS HPC unsupervised convolutional network (Coates et al., 2013)<br>10. GoogLeNet (Szegedy et al., 2014a)</p><footer id=\\'160\\' style=\\'font-size:18px\\'>24</footer><header id=\\'161\\' style=\\'font-size:14px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'162\\' style=\\'font-size:22px\\'>et al., 2012.</p><br><p id=\\'163\\' style=\\'font-size:16px\\'>At the same time that the scale and accuracy of deep networks has increased,<br>SO has the complexity of the tasks that they can solve. Goodfellow et al. (2014d)<br>showed that neural networks could learn to output an entire sequence of characters<br>transcribed from an image, rather than just identifying a single object. Previously,<br>it was widely believed that this kind of learning required labeling of the individual<br>elements of the sequence (Gulehre and Bengio, 2013). Recurrent neural networks,<br>such as the LSTM sequence model mentioned above, are now used to model<br>relationships between sequences and other sequences rather than just fixed inputs.<br>This sequence-to-sequence learning seems to be on the cusp of revolutionizing<br>another application: machine translation (Sutskever et al., 2014; Bahdanau et al.,<br>2015).</p><br><p id=\\'164\\' style=\\'font-size:16px\\'>This trend of increasing complexity has been pushed to its logical conclusion<br>with the introduction of neural Turing machines (Graves et al., 2014a) that learn<br>to read from memory cells and write arbitrary content to memory cells. Such<br>neural networks can learn simple programs from examples of desired behavior. For<br>example, they can learn to sort lists of numbers given examples of scrambled and<br>sorted sequences. This self-programming technology is in its infancy, but in the<br>future could in principle be applied to nearly any task.</p><br><p id=\\'165\\' style=\\'font-size:18px\\'>Another crowning achievement of deep learning is its extension to the domain<br>of reinforcement learning. In the context of reinforcement learning, an autonomous<br>agent must learn to perform a task by trial and error, without any guidance from<br>the human operator. DeepMind demonstrated that a reinforcement learning system<br>based on deep learning is capable of learning to play Atari video games, reaching<br>human-level performance on many tasks (Mnih et al., 2015). Deep learning has<br>also significantly improved the performance of reinforcement learning for robotics<br>(Finn et al., 2015).</p><br><p id=\\'166\\' style=\\'font-size:20px\\'>Many of these applications of deep learning are highly profitable. Deep learning<br>is now used by many top technology companies including Google, Microsoft,<br>Facebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC.</p><br><p id=\\'167\\' style=\\'font-size:20px\\'>Advances in deep learning have also depended heavily on advances in software<br>infrastructure. Software libraries such as Theano (Bergstra et al., 2010; Bastien<br>et al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b),<br>DistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and<br>TensorFlow (Abadi et al., 2015) have all supported important research projects or<br>commercial products.</p><br><p id=\\'168\\' style=\\'font-size:16px\\'>Deep learning has also made contributions back to other sciences. Modern<br>convolutional networks for object recognition provide a model of visual processing</p><footer id=\\'169\\' style=\\'font-size:14px\\'>25</footer><header id=\\'170\\' style=\\'font-size:16px\\'>CHAPTER 1. INTRODUCTION</header><p id=\\'171\\' style=\\'font-size:20px\\'>that neuroscientists can study (DiCarlo, 2013). Deep learning also provides useful<br>tools for processing massive amounts of data and making useful predictions in<br>scientific fields. It has been successfully used to predict how molecules will interact<br>in order to help pharmaceutical companies design new drugs (Dahl et al., 2014),<br>to search for subatomic particles (Baldi et al., 2014), and to automatically parse<br>microscope images used to construct a 3-D map of the human brain (Knowles-<br>Barley et al., 2014). We expect deep learning to appear in more and more scientific<br>fields in the future.</p><br><p id=\\'172\\' style=\\'font-size:18px\\'>In summary, deep learning is an approach to machine learning that has drawn<br>heavily on our knowledge of the human brain, statistics and applied math as it<br>developed over the past several decades. In recent years, it has seen tremendous<br>growth in its popularity and usefulness, due in large part to more powerful com-<br>puters, larger datasets and techniques to train deeper networks. The years ahead<br>are full of challenges and opportunities to improve deep learning even further and<br>bring it to new frontiers.</p><footer id=\\'173\\' style=\\'font-size:14px\\'>26</footer><header id=\\'174\\' style=\\'font-size:20px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'175\\' style=\\'font-size:14px\\' alt=\"Increasing neural network size over time\\nscale)\\n1011\\nHuman\\n1010\\n17 20\\n(logarithmic\\n109 16 19\\nOctopus\\n108 14\\n107 Frog\\n106 8\\nBee\\n105 3 \\nAnt\\nneurons\\n104\\n103\\nLeech\\n13\\n102\\n2\\nof 101 1 12\\n15 Roundworm\\n100 9\\nNumber\\n10\\n10-1 7\\n4\\n10-2\\nSponge\\n1950 1985 2000 2015 2056\" data-coord=\"top-left:(499,499); bottom-right:(2057,1257)\" /><figcaption id=\\'176\\'></figcaption></figure><br><p id=\\'177\\' style=\\'font-size:22px\\'>Figure 1.11: Since the introduction of hidden units, artificial neural networks have doubled<br>in size roughly every 2.4 years. Biological neural network sizes from Wikipedia (2015).</p><p id=\\'178\\' style=\\'font-size:16px\\'>1. Perceptron (Rosenblatt, 1958, 1962)<br>2. Adaptive linear element (Widrow and Hoff, 1960)<br>3. Neocognitron (Fukushima, 1980)<br>4. Early back-propagation network (Rumelhart et al., 1986b)<br>5. Recurrent neural network for speech recognition (Robinson and Fallside, 1991)<br>6. Multilayer perceptron for speech recognition (Bengio et al., 1991)<br>7. Mean field sigmoid belief network (Saul et al., 1996)<br>8. LeNet-5 (LeCun et al., 1998b)<br>9. Echo state network (Jaeger and Haas, 2004)<br>10. Deep belief network (Hinton et al., 2006)<br>11. GPU-accelerated convolutional network (Chellapilla et al., 2006)<br>12. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)<br>13. GPU-accelerated deep belief network (Raina et al., 2009)<br>14. Unsupervised convolutional network (Jarrett et al., 2009)<br>15. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)<br>16. OMP-1 network (Coates and Ng, 2011)<br>17. Distributed autoencoder (Le et al., 2012)<br>18. Multi-GPU convolutional network (Krizhevsky et al., 2012)<br>19. COTS HPC unsupervised convolutional network (Coates et al., 2013)<br>20. GoogLeNet (Szegedy et al., 2014a)</p><footer id=\\'179\\' style=\\'font-size:18px\\'>27</footer><header id=\\'180\\' style=\\'font-size:18px\\'>CHAPTER 1. INTRODUCTION</header><figure><img id=\\'181\\' style=\\'font-size:14px\\' alt=\"rate 0.30\\nDecreasing error rate over time\\nerror 0.25\\nclassification\\n0.20\\n0.15\\n0.10\\nILSVRC\\n0.05\\n0.00\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\" data-coord=\"top-left:(521,1122); bottom-right:(1956,1884)\" /><figcaption id=\\'182\\' style=\\'font-size:20px\\'>Figure 1.12: Since deep networks reached the scale necessary to compete in the ImageNet<br>Large Scale Visual Recognition Challenge, they have consistently won the competition<br>every year, and yielded lower and lower error rates each time. Data from Russakovsky<br>et al. (2014b) and He et al. (2015).</figcaption></figure><footer id=\\'183\\' style=\\'font-size:16px\\'>28</footer><p id=\\'184\\' style=\\'font-size:16px\\'>Part I</p><p id=\\'185\\' style=\\'font-size:20px\\'>Applied Math and Machine<br>Learning Basics</p><footer id=\\'186\\' style=\\'font-size:14px\\'>29</footer><p id=\\'187\\' style=\\'font-size:16px\\'>This part of the book introduces the basic mathematical concepts needed to<br>understand deep learning. We begin with general ideas from applied math that<br>allow us to define functions of many variables, find the highest and lowest points<br>on these functions and quantify degrees of belief.</p><br><p id=\\'188\\' style=\\'font-size:16px\\'>Next, we describe the fundamental goals of machine learning. We describe how<br>to accomplish these goals by specifying a model that represents certain beliefs,<br>designing a cost function that measures how well those beliefs correspond with<br>reality and using a training algorithm to minimize that cost function.</p><p id=\\'189\\' style=\\'font-size:20px\\'>This elementary framework is the basis for a broad variety of machine learning<br>algorithms, including approaches to machine learning that are not deep. In the<br>subsequent parts of the book, we develop deep learning algorithms within this<br>framework.</p><footer id=\\'190\\' style=\\'font-size:14px\\'>30</footer>', 'mimetype': 'multipart/form-data', 'model': 'layout-analyzer-0.1.0', 'text': 'Chapter 1\\nIntroduction\\nInventors have long dreamed of creating machines that think. This desire dates\\nback to at least the time of ancient Greece. The mythical figures Pygmalion,\\nDaedalus, and Hephaestus may all be interpreted as legendary inventors, and\\nGalatea, Talos, and Pandora may all be regarded as artificial life (Ovid and Martin,\\n2004; Sparkes, 1996; Tandy, 1997).\\nWhen programmable computers were first conceived, people wondered whether\\nthey might become intelligent, over a hundred years before one was built (Lovelace,\\n1842). Today, artificial intelligence (AI) is a thriving field with many practical\\napplications and active research topics. We look to intelligent software to automate\\nroutine labor, understand speech or images, make diagnoses in medicine and\\nsupport basic scientific research.\\nIn the early days of artificial intelligence, the field rapidly tackled and solved\\nproblems that are intellectually difficult for human beings but relatively straight-\\nforward for computers problems that can be described by a list of formal, math-\\nematical rules. The true challenge to artificial intelligence proved to be solving\\nthe tasks that are easy for people to perform but hard for people to describe\\nformally problems that we solve intuitively, that feel automatic, like recognizing\\nspoken words or faces in images.\\nThis book is about a solution to these more intuitive problems. This solution is\\nto allow computers to learn from experience and understand the world in terms of a\\nhierarchy of concepts, with each concept defined in terms of its relation to simpler\\nconcepts. By gathering knowledge from experience, this approach avoids the need\\nfor human operators to formally specify all of the knowledge that the computer\\nneeds. The hierarchy of concepts allows the computer to learn complicated concepts\\nby building them out of simpler ones. If we draw a graph showing how these\\n1\\nCHAPTER 1. INTRODUCTION\\nconcepts are built on top of each other, the graph is deep, with many layers. For\\nthis reason, we call this approach to AI deep learning.\\nMany of the early successes of AI took place in relatively sterile and formal\\nenvironments and did not require computers to have much knowledge about\\nthe world. For example, IBM\\'s Deep Blue chess-playing system defeated world\\nchampion Garry Kasparov in 1997 (Hsu, 2002). Chess is of course a very simple\\nworld, containing only sixty-four locations and thirty-two pieces that can move\\nin only rigidly circumscribed ways. Devising a successful chess strategy is a\\ntremendous accomplishment, but the challenge is not due to the difficulty of\\ndescribing the set of chess pieces and allowable moves to the computer. Chess\\ncan be completely described by a very brief list of completely formal rules, easily\\nprovided ahead of time by the programmer.\\nIronically, abstract and formal tasks that are among the most difficult mental\\nundertakings for a human being are among the easiest for a computer. Computers\\nhave long been able to defeat even the best human chess player, but are only\\nrecently matching some of the abilities of average human beings to recognize objects\\nor speech. A person\\'s everyday life requires an immense amount of knowledge\\nabout the world. Much of this knowledge is subjective and intuitive, and therefore\\ndifficult to articulate in a formal way. Computers need to capture this same\\nknowledge in order to behave in an intelligent way. One of the key challenges in\\nartificial intelligence is how to get this informal knowledge into a computer.\\nSeveral artificial intelligence projects have sought to hard-code knowledge about\\nthe world in formal languages. A computer can reason about statements in these\\nformal languages automatically using logical inference rules. This is known as the\\nknowledge base approach to artificial intelligence. None of these projects has led to\\na major success. One of the most famous such projects is Cyc (Lenat and Guha,\\n1989). Cyc is an inference engine and a database of statements in a language\\ncalled CycL. These statements are entered by a staff of human supervisors. It is an\\nunwieldy process. People struggle to devise formal rules with enough complexity\\nto accurately describe the world. For example, Cyc failed to understand a story\\nabout a person named Fred shaving in the morning (Linde, 1992). Its inference\\nengine detected an inconsistency in the story: it knew that people do not have\\nelectrical parts, but because Fred was holding an electric razor, it believed the\\nentity \"FredWhileShaving\" contained electrical parts. It therefore asked whether\\nFred was still a person while he was shaving.\\nThe difficulties faced by systems relying on hard-coded knowledge suggest that\\nAI systems need the ability to acquire their own knowledge, by extracting patterns\\nfrom raw data. This capability is known as machine learning. The introduction\\n2\\nCHAPTER 1. INTRODUCTION\\nof machine learning allowed computers to tackle problems involving knowledge\\nof the real world and make decisions that appear subjective. A simple machine\\nlearning algorithm called logistic regression can determine whether to recommend\\ncesarean delivery (Mor- Yosef et al., 1990). A simple machine learning algorithm\\ncalled naive Bayes can separate legitimate e-mail from spam e-mail.\\nThe performance of these simple machine learning algorithms depends heavily\\non the representation of the data they are given. For example, when logistic\\nregression is used to recommend cesarean delivery, the AI system does not examine\\nthe patient directly. Instead, the doctor tells the system several pieces of relevant\\ninformation, such as the presence or absence of a uterine scar. Each piece of\\ninformation included in the representation of the patient is known as a feature.\\nLogistic regression learns how each of these features of the patient correlates with\\nvarious outcomes. However, it cannot influence the way that the features are\\ndefined in any way. If logistic regression was given an MRI scan of the patient,\\nrather than the doctor\\'s formalized report, it would not be able to make useful\\npredictions. Individual pixels in an MRI scan have negligible correlation with any\\ncomplications that might occur during delivery.\\nThis dependence on representations is a general phenomenon that appears\\nthroughout computer science and even daily life. In computer science, opera-\\ntions such as searching a collection of data can proceed exponentially faster if\\nthe collection is structured and indexed intelligently. People can easily perform\\narithmetic on Arabic numerals, but find arithmetic on Roman numerals much\\nmore time-consuming. It is not surprising that the choice of representation has an\\nenormous effect on the performance of machine learning algorithms. For a simple\\nvisual example, see Fig. 1.1.\\nMany artificial intelligence tasks can be solved by designing the right set of\\nfeatures to extract for that task, then providing these features to a simple machine\\nlearning algorithm. For example, a useful feature for speaker identification from\\nsound is an estimate of the size of speaker\\'s vocal tract. It therefore gives a strong\\nclue as to whether the speaker is a man, woman, or child.\\nHowever, for many tasks, it is difficult to know what features should be extracted.\\nFor example, suppose that we would like to write a program to detect cars in\\nphotographs. We know that cars have wheels, SO we might like to use the presence\\nof a wheel as a feature. Unfortunately, it is difficult to describe exactly what a\\nwheel looks like in terms of pixel values. A wheel has a simple geometric shape but\\nits image may be complicated by shadows falling on the wheel, the sun glaring off\\nthe metal parts of the wheel, the fender of the car or an object in the foreground\\nobscuring part of the wheel, and SO on.\\n3\\nCHAPTER 1. INTRODUCTION\\nCartesian coordinates Polar coordinates\\nFigure 1.1: Example of different representations: suppose we want to separate two\\ncategories of data by drawing a line between them in a scatterplot. In the plot on the left,\\nwe represent some data using Cartesian coordinates, and the task is impossible. In the plot\\non the right, we represent the data with polar coordinates and the task becomes simple to\\nsolve with a vertical line. (Figure produced in collaboration with David Warde-Farley)\\nOne solution to this problem is to use machine learning to discover not only\\nthe mapping from representation to output but also the representation itself.\\nThis approach is known as representation learning. Learned representations often\\nresult in much better performance than can be obtained with hand-designed\\nrepresentations. They also allow AI systems to rapidly adapt to new tasks, with\\nminimal human intervention. A representation learning algorithm can discover a\\ngood set of features for a simple task in minutes, or a complex task in hours to\\nmonths. Manually designing features for a complex task requires a great deal of\\nhuman time and effort; it can take decades for an entire community of researchers.\\nThe quintessential example of a representation learning algorithm is the au-\\ntoencoder. An autoencoder is the combination of an encoder function that converts\\nthe input data into a different representation, and a decoder function that converts\\nthe new representation back into the original format. Autoencoders are trained to\\npreserve as much information as possible when an input is run through the encoder\\nand then the decoder, but are also trained to make the new representation have\\nvarious nice properties. Different kinds of autoencoders aim to achieve different\\nkinds of properties.\\nWhen designing features or algorithms for learning features, our goal is usually\\nto separate the factors of variation that explain the observed data. In this context,\\nwe use the word \"factors\" simply to refer to separate sources of influence; the factors\\nare usually not combined by multiplication. Such factors are often not quantities\\n4\\nCHAPTER 1. INTRODUCTION\\nthat are directly observed. Instead, they may exist either as unobserved objects\\nor unobserved forces in the physical world that affect observable quantities. They\\nmay also exist as constructs in the human mind that provide useful simplifying\\nexplanations or inferred causes of the observed data. They can be thought of as\\nconcepts or abstractions that help us make sense of the rich variability in the data.\\nWhen analyzing a speech recording, the factors of variation include the speaker\\'s\\nage, their sex, their accent and the words that they are speaking. When analyzing\\nan image of a car, the factors of variation include the position of the car, its color,\\nand the angle and brightness of the sun.\\nA major source of difficulty in many real-world artificial intelligence applications\\nis that many of the factors of variation influence every single piece of data we are\\nable to observe. The individual pixels in an image of a red car might be very close\\nto black at night. The shape of the car\\'s silhouette depends on the viewing angle.\\nMost applications require us to disentangle the factors of variation and discard the\\nones that we do not care about.\\nOf course, it can be very difficult to extract such high-level, abstract features\\nfrom raw data. Many of these factors of variation, such as a speaker\\'s accent,\\ncan be identified only using sophisticated, nearly human-level understanding of\\nthe data. When it is nearly as difficult to obtain a representation as to solve the\\noriginal problem, representation learning does not, at first glance, seem to help us.\\nDeep learning solves this central problem in representation learning by introduc-\\ning representations that are expressed in terms of other, simpler representations.\\nDeep learning allows the computer to build complex concepts out of simpler con-\\ncepts. Fig. 1.2 shows how a deep learning system can represent the concept of an\\nimage of a person by combining simpler concepts, such as corners and contours,\\nwhich are in turn defined in terms of edges.\\nThe quintessential example of a deep learning model is the feedforward deep\\nnetwork or multilayer perceptron (MLP). A multilayer perceptron is just a mathe-\\nmatical function mapping some set of input values to output values. The function\\nis formed by composing many simpler functions. We can think of each application\\nof a different mathematical function as providing a new representation of the input.\\nThe idea of learning the right representation for the data provides one perspec-\\ntive on deep learning. Another perspective on deep learning is that depth allows the\\ncomputer to learn a multi-step computer program. Each layer of the representation\\ncan be thought of as the state of the computer\\'s memory after executing another\\nset of instructions in parallel. Networks with greater depth can execute more\\ninstructions in sequence. Sequential instructions offer great power because later\\ninstructions can refer back to the results of earlier instructions. According to this\\n5\\nCHAPTER 1. INTRODUCTION\\nOutput\\nCAR PERSON ANIMAL\\n(object identity)\\n3rd hidden layer\\n(object parts)\\n2nd hidden layer\\n(corners and\\ncontours)\\n1st hidden layer\\n(edges)\\nVisible layer\\n(input pixels)\\n\\nFigure 1.2: Illustration of a deep learning model. It is difficult for a computer to understand\\nthe meaning of raw sensory input data, such as this image represented as a collection\\nof pixel values. The function mapping from a set of pixels to an object identity is very\\ncomplicated. Learning or evaluating this mapping seems insurmountable if tackled directly.\\nDeep learning resolves this difficulty by breaking the desired complicated mapping into a\\nseries of nested simple mappings, each described by a different layer of the model. The\\ninput is presented at the visible layer, SO named because it contains the variables that we\\nare able to observe. Then a series of hidden layers extracts increasingly abstract features\\nfrom the image. These layers are called \"hidden\" because their values are not given in\\nthe data; instead the model must determine which concepts are useful for explaining\\nthe relationships in the observed data. The images here are visualizations of the kind\\nof feature represented by each hidden unit. Given the pixels, the first layer can easily\\nidentify edges, by comparing the brightness of neighboring pixels. Given the first hidden\\nlayer\\'s description of the edges, the second hidden layer can easily search for corners and\\nextended contours, which are recognizable as collections of edges. Given the second hidden\\nlayer\\'s description of the image in terms of corners and contours, the third hidden layer\\ncan detect entire parts of specific objects, by finding specific collections of contours and\\ncorners. Finally, this description of the image in terms of the object parts it contains can\\nbe used to recognize the objects present in the image. Images reproduced with permission\\nfrom Zeiler and Fergus (2014).\\n6\\nCHAPTER 1. INTRODUCTION\\nElement\\nElement 0 Set\\nSet\\nLogistic Logistic\\nRegression Regression\\nw\\nX1 u X2\\nw 1\\nFigure 1.3: Illustration of computational graphs mapping an input to an output where\\neach node performs an operation. Depth is the length of the longest path from input to\\noutput but depends on the definition of what constitutes a possible computational step.\\nThe computation depicted in these graphs is the output of a logistic regression model,\\no(wT x), where 0 is the logistic sigmoid function. If we use addition, multiplication and\\nlogistic sigmoids as the elements of our computer language, then this model has depth\\nthree. If we view logistic regression as an element itself, then this model has depth one.\\nview of deep learning, not all of the information in a layer\\'s activations necessarily\\nencodes factors of variation that explain the input. The representation also stores\\nstate information that helps to execute a program that can make sense of the input.\\nThis state information could be analogous to a counter or pointer in a traditional\\ncomputer program. It has nothing to do with the content of the input specifically,\\nbut it helps the model to organize its processing.\\nThere are two main ways of measuring the depth of a model. The first view is\\nbased on the number of sequential instructions that must be executed to evaluate\\nthe architecture. We can think of this as the length of the longest path through\\na flow chart that describes how to compute each of the model\\'s outputs given\\nits inputs. Just as two equivalent computer programs will have different lengths\\ndepending on which language the program is written in, the same function may be\\ndrawn as a flowchart with different depths depending on which functions we allow\\nto be used as individual steps in the flowchart. Fig. 1.3 illustrates how this choice\\nof language can give two different measurements for the same architecture.\\nAnother approach, used by deep probabilistic models, regards the depth of a\\nmodel as being not the depth of the computational graph but the depth of the\\ngraph describing how concepts are related to each other. In this case, the depth\\nof the flowchart of the computations needed to compute the representation of\\nCHAPTER 1. INTRODUCTION\\neach concept may be much deeper than the graph of the concepts themselves.\\nThis is because the system\\'s understanding of the simpler concepts can be refined\\ngiven information about the more complex concepts. For example, an AI system\\nobserving an image of a face with one eye in shadow may initially only see one eye.\\nAfter detecting that a face is present, it can then infer that a second eye is probably\\npresent as well. In this case, the graph of concepts only includes two layers -a\\nlayer for eyes and a layer for faces- but the graph of computations includes 2n\\nlayers if we refine our estimate of each concept given the other n times.\\nBecause it is not always clear which of these two views- the depth of the\\ncomputational graph, or the depth of the probabilistic modeling graph is most\\nrelevant, and because different people choose different sets of smallest elements\\nfrom which to construct their graphs, there is no single correct value for the\\ndepth of an architecture, just as there is no single correct value for the length of\\na computer program. Nor is there a consensus about how much depth a model\\nrequires to qualify as \"deep.\" However, deep learning can safely be regarded as the\\nstudy of models that either involve a greater amount of composition of learned\\nfunctions or learned concepts than traditional machine learning does.\\nTo summarize, deep learning, the subject of this book, is an approach to AI.\\nSpecifically, it is a type of machine learning, a technique that allows computer\\nsystems to improve with experience and data. According to the authors of this\\nbook, machine learning is the only viable approach to building AI systems that\\ncan operate in complicated, real-world environments. Deep learning is a particular\\nkind of machine learning that achieves great power and flexibility by learning to\\nrepresent the world as a nested hierarchy of concepts, with each concept defined in\\nrelation to simpler concepts, and more abstract representations computed in terms\\nof less abstract ones. Fig. 1.4 illustrates the relationship between these different\\nAI disciplines. Fig. 1.5 gives a high-level schematic of how each works.\\n1.1 Who Should Read This Book?\\nThis book can be useful for a variety of readers, but we wrote it with two main\\ntarget audiences in mind. One of these target audiences is university students\\n(undergraduate or graduate) learning about machine learning, including those who\\nare beginning a career in deep learning and artificial intelligence research. The\\nother target audience is software engineers who do not have a machine learning\\nor statistics background, but want to rapidly acquire one and begin using deep\\nlearning in their product or platform. Deep learning has already proven useful in\\nmany software disciplines including computer vision, speech and audio processing,\\n8\\nCHAPTER 1. INTRODUCTION\\nDeep learning Example:\\nShallow\\nExample: Example:\\nExample: autoencoders\\nLogistic Knowledge\\nMLPs\\nregression bases\\nRepresentation learning\\nMachine learning\\nAI\\nFigure 1.4: A Venn diagram showing how deep learning is a kind of representation learning,\\nwhich is in turn a kind of machine learning, which is used for many but not all approaches\\nto AI. Each section of the Venn diagram includes an example of an AI technology.\\n9\\nCHAPTER 1. INTRODUCTION\\nOutput\\nMapping from\\nOutput Output\\nfeatures\\nAdditional\\nMapping from Mapping from layers of more\\nOutput\\nfeatures features abstract\\nfeatures\\nHand- Hand-\\nSimple\\ndesigned designed Features\\nfeatures\\nprogram features\\nInput Input Input Input\\nDeep\\nClassic\\nRule-based learning\\nmachine\\nsystems Representation\\nlearning\\nlearning\\nFigure 1.5: Flowcharts showing how the different parts of an AI system relate to each\\nother within different AI disciplines. Shaded boxes indicate components that are able to\\nlearn from data.\\n10\\nCHAPTER 1. INTRODUCTION\\nnatural language processing, robotics, bioinformatics and chemistry, video games,\\nsearch engines, online advertising and finance.\\nThis book has been organized into three parts in order to best accommodate a\\nvariety of readers. Part I introduces basic mathematical tools and machine learning\\nconcepts. Part II describes the most established deep learning algorithms that are\\nessentially solved technologies. Part III describes more speculative ideas that are\\nwidely believed to be important for future research in deep learning.\\nReaders should feel free to skip parts that are not relevant given their interests\\nor background. Readers familiar with linear algebra, probability, and fundamental\\nmachine learning concepts can skip Part I, for example, while readers who just want\\nto implement a working system need not read beyond Part II. To help choose which\\nchapters to read, Fig. 1.6 provides a flowchart showing the high-level organization\\nof the book.\\nWe do assume that all readers come from a computer science background. We\\nassume familiarity with programming, a basic understanding of computational\\nperformance issues, complexity theory, introductory level calculus and some of the\\nterminology of graph theory.\\n1.2 Historical Trends in Deep Learning\\nIt is easiest to understand deep learning with some historical context. Rather than\\nproviding a detailed history of deep learning, we identify a few key trends:\\n Deep learning has had a long and rich history, but has gone by many names\\nreflecting different philosophical viewpoints, and has waxed and waned in\\npopularity.\\n Deep learning has become more useful as the amount of available training\\ndata has increased.\\n Deep learning models have grown in size over time as computer hardware\\nand software infrastructure for deep learning has improved.\\n Deep learning has solved increasingly complicated applications with increasing\\naccuracy over time.\\n11\\nCHAPTER 1. INTRODUCTION\\n1. Introduction\\nPart I: Applied Math and Machine Learning Basics\\n3. Probability and\\n2. Linear Algebra\\nInformation Theory\\n4. Numerical 5. Machine Learning\\nComputation Basics\\nPart II: Deep Networks: Modern Practices\\n6. Deep Feedforward\\nNetworks\\n7. Regularization 8. Optimization 9. CNNs 10. RNNs\\n11. Practical\\n12. Applications\\nMethodology\\nPart III: Deep Learning Research\\n13. Linear Factor 15. Representation\\n14. Autoencoders\\nModels Learning\\n16. Structured 17. Monte Carlo\\nProbabilistic Models Methods\\n18. Partition\\n19. Inference\\nFunction\\n20. Deep Generative\\nModels\\nFigure 1.6: The high-level organization of the book. An arrow from one chapter to another\\nindicates that the former chapter is prerequisite material for understanding the latter.\\n12\\nCHAPTER 1. INTRODUCTION\\n1.2.1 The Many N ames and Changing Fortunes of Neural Net-\\nworks\\nWe expect that many readers of this book have heard of deep learning as an\\nexciting new technology, and are surprised to see a mention of \"history\" in a book\\nabout an emerging field. In fact, deep learning dates back to the 1940s. Deep\\nlearning only appears to be new, because it was relatively unpopular for several\\nyears preceding its current popularity, and because it has gone through many\\ndifferent names, and has only recently become called \"deep learning.\" The field\\nhas been rebranded many times, reflecting the influence of different researchers\\nand different perspectives.\\nA comprehensive history of deep learning is beyond the scope of this textbook.\\nHowever, some basic context is useful for understanding deep learning. Broadly\\nspeaking, there have been three waves of development of deep learning: deep learn-\\ning known as cybernetics in the 1940s-1960s, deep learning known as connectionism\\nin the 1980s-1990s, and the current resurgence under the name deep learning\\nbeginning in 2006. This is quantitatively illustrated in Fig. 1.7.\\nSome of the earliest learning algorithms we recognize today were intended\\nto be computational models of biological learning, i.e. models of how learning\\nhappens or could happen in the brain. As a result, one of the names that deep\\nlearning has gone by is artificial neural networks (ANNs). The corresponding\\nperspective on deep learning models is that they are engineered systems inspired\\nby the biological brain (whether the human brain or the brain of another animal).\\nWhile the kinds of neural networks used for machine learning have sometimes\\nbeen used to understand brain function (Hinton and Shallice, 1991), they are\\ngenerally not designed to be realistic models of biological function. The neural\\nperspective on deep learning is motivated by two main ideas. One idea is that\\nthe brain provides a proof by example that intelligent behavior is possible, and a\\nconceptually straightforward path to building intelligence is to reverse engineer the\\ncomputational principles behind the brain and duplicate its functionality. Another\\nperspective is that it would be deeply interesting to understand the brain and the\\nprinciples that underlie human intelligence, SO machine learning models that shed\\nlight on these basic scientific questions are useful apart from their ability to solve\\nengineering applications.\\nThe modern term \"deep learning\" goes beyond the neuroscientific perspective\\non the current breed of machine learning models. It appeals to a more general\\nprinciple of learning multiple levels of composition, which can be applied in machine\\nlearning frameworks that are not necessarily neurally inspired.\\n13\\nCHAPTER 1. INTRODUCTION\\nPhrase 0.000250\\n0.000200 cybernetics\\nor\\nWord\\n0.000150\\n(connectionism + neural networks)\\nJo\\n0.000100\\nFrequency\\n0.000050\\n0.000000\\n1940\\n1950\\n1960\\n1970\\n1980\\nYear 1990\\n2000\\nFigure 1.7: The figure shows two of the three historical waves of artificial neural nets\\nresearch, as measured by the frequency of the phrases \"cybernetics\" and \"connectionism\" or\\n\"neural networks\" according to Google Books (the third wave is too recent to appear). The\\nfirst wave started with cybernetics in the 1940s-1960s, with the development of theories\\nof biological learning (McCulloch and Pitts, 1943; Hebb, 1949) and implementations of\\nthe first models such as the perceptron (Rosenblatt, 1958) allowing the training of a single\\nneuron. The second wave started with the connectionist approach of the 1980-1995 period,\\nwith back-propagation (Rumelhart et al., 1986a) to train a neural network with one or two\\nhidden layers. The current and third wave, deep learning, started around 2006 (Hinton\\net al., 2006; Bengio et al., 2007; Ranzato et al., 2007a), and is just now appearing in book\\nform as of 2016. The other two waves similarly appeared in book form much later than\\nthe corresponding scientific activity occurred.\\n14\\nCHAPTER 1. INTRODUCTION\\nThe earliest predecessors of modern deep learning were simple linear models\\nmotivated from a neuroscientific perspective. These models were designed to\\ntake a set of n input values X1,    , Xn and associate them with an output y.\\nThese models would learn a set of weights w1,    , Wn and compute their output\\nf(x, w) = x1w1 +    + Xn Wn. This first wave of neural networks research was\\nknown as cybernetics, as illustrated in Fig. 1.7.\\nThe McCulloch-Pitts Neuron (McCulloch and Pitts, 1943) was an early model\\nof brain function. This linear model could recognize two different categories of\\ninputs by testing whether f (x, w) is positive or negative. Of course, for the model\\nto correspond to the desired definition of the categories, the weights needed to be\\nset correctly. These weights could be set by the human operator. In the 1950s,\\nthe perceptron (Rosenblatt, 1958, 1962) became the first model that could learn\\nthe weights defining the categories given examples of inputs from each category.\\nThe adaptive linear element (ADALINE), which dates from about the same time,\\nsimply returned the value of f(x) itself to predict a real number (Widrow and\\nHoff, 1960), and could also learn to predict these numbers from data.\\nThese simple learning algorithms greatly affected the modern landscape of\\nmachine learning. The training algorithm used to adapt the weights of the ADA-\\nLINE was a special case of an algorithm called stochastic gradient descent. Slightly\\nmodified versions of the stochastic gradient descent algorithm remain the dominant\\ntraining algorithms for deep learning models today.\\nModels based on the f(x, w) used by the perceptron and ADALINE are called\\nlinear models. These models remain some of the most widely used machine learning\\nmodels, though in many cases they are trained in different ways than the original\\nmodels were trained.\\nLinear models have many limitations. Most famously, they cannot learn the\\nXOR function, where f ([0,1] , w) = 1 and f([1, 0], w) = 1 but f([1, 1], w) = 0\\nand f ([0, 0], w) = 0. Critics who observed these flaws in linear models caused\\na backlash against biologically inspired learning in general (Minsky and Papert,\\n1969). This was the first major dip in the popularity of neural networks.\\nToday, neuroscience is regarded as an important source of inspiration for deep\\nlearning researchers, but it is no longer the predominant guide for the field.\\nThe main reason for the diminished role of neuroscience in deep learning\\nresearch today is that we simply do not have enough information about the brain\\nto use it as a guide. To obtain a deep understanding of the actual algorithms used\\nby the brain, we would need to be able to monitor the activity of (at the very\\nleast) thousands of interconnected neurons simultaneously. Because we are not\\nable to do this, we are far from understanding even some of the most simple and\\n15\\nCHAPTER 1. INTRODUCTION\\nwell-studied parts of the brain (Olshausen and Field, 2005).\\nNeuroscience has given us a reason to hope that a single deep learning algorithm\\ncan solve many different tasks. Neuroscientists have found that ferrets can learn to\\n\"see\" with the auditory processing region of their brain if their brains are rewired\\nto send visual signals to that area (Von Melchner et al., 2000). This suggests that\\nmuch of the mammalian brain might use a single algorithm to solve most of the\\ndifferent tasks that the brain solves. Before this hypothesis, machine learning\\nresearch was more fragmented, with different communities of researchers studying\\nnatural language processing, vision, motion planning and speech recognition. Today,\\nthese application communities are still separate, but it is common for deep learning\\nresearch groups to study many or even all of these application areas simultaneously.\\nWe are able to draw some rough guidelines from neuroscience. The basic idea of\\nhaving many computational units that become intelligent only via their interactions\\nwith each other is inspired by the brain. The Neocognitron (Fukushima, 1980)\\nintroduced a powerful model architecture for processing images that was inspired\\nby the structure of the mammalian visual system and later became the basis for\\nthe modern convolutional network (LeCun et al., 1998b), as we will see in Sec. 9.10.\\nMost neural networks today are based on a model neuron called the rectified linear\\nunit. The original Cognitron (Fukushima, 1975) introduced a more complicated\\nversion that was highly inspired by our knowledge of brain function. The simplified\\nmodern version was developed incorporating ideas from many viewpoints, with Nair\\nand Hinton (2010) and Glorot et al. (2011a) citing neuroscience as an influence, and\\nJarrett et al. (2009) citing more engineering-oriented influences. While neuroscience\\nis an important source of inspiration, it need not be taken as a rigid guide. We\\nknow that actual neurons compute very different functions than modern rectified\\nlinear units, but greater neural realism has not yet led to an improvement in\\nmachine learning performance. Also, while neuroscience has successfully inspired\\nseveral neural network architectures, we do not yet know enough about biological\\nlearning for neuroscience to offer much guidance for the learning algorithms we\\nuse to train these architectures.\\nMedia accounts often emphasize the similarity of deep learning to the brain.\\nWhile it is true that deep learning researchers are more likely to cite the brain as an\\ninfluence than researchers working in other machine learning fields such as kernel\\nmachines or Bayesian statistics, one should not view deep learning as an attempt\\nto simulate the brain. Modern deep learning draws inspiration from many fields,\\nespecially applied math fundamentals like linear algebra, probability, information\\ntheory, and numerical optimization. While some deep learning researchers cite\\nneuroscience as an important source of inspiration, others are not concerned with\\n16\\nCHAPTER 1. INTRODUCTION\\nneuroscience at all.\\nIt is worth noting that the effort to understand how the brain works on\\nan algorithmic level is alive and well. This endeavor is primarily known as\\n\"computational neuroscience\" and is a separate field of study from deep learning.\\nIt is common for researchers to move back and forth between both fields. The\\nfield of deep learning is primarily concerned with how to build computer systems\\nthat are able to successfully solve tasks requiring intelligence, while the field of\\ncomputational neuroscience is primarily concerned with building more accurate\\nmodels of how the brain actually works.\\nIn the 1980s, the second wave of neural network research emerged in great part\\nvia a movement called connectionism or parallel distributed processing (Rumelhart\\net al., 1986c; McClelland et al., 1995). Connectionism arose in the context of\\ncognitive science. Cognitive science is an interdisciplinary approach to understand-\\ning the mind, combining multiple different levels of analysis. During the early\\n1980s, most cognitive scientists studied models of symbolic reasoning. Despite their\\npopularity, symbolic models were difficult to explain in terms of how the brain\\ncould actually implement them using neurons. The connectionists began to study\\nmodels of cognition that could actually be grounded in neural implementations\\n(Touretzky and Minton, 1985), reviving many ideas dating back to the work of\\npsychologist Donald Hebb in the 1940s (Hebb, 1949).\\nThe central idea in connectionism is that a large number of simple computational\\nunits can achieve intelligent behavior when networked together. This insight\\napplies equally to neurons in biological nervous systems and to hidden units in\\ncomputational models.\\nSeveral key concepts arose during the connectionism movement of the 1980s\\nthat remain central to today\\'s deep learning.\\nOne of these concepts is that of distributed representation (Hinton et al., 1986).\\nThis is the idea that each input to a system should be represented by many features,\\nand each feature should be involved in the representation of many possible inputs.\\nFor example, suppose we have a vision system that can recognize cars, trucks, and\\nbirds and these objects can each be red, green, or blue. One way of representing\\nthese inputs would be to have a separate neuron or hidden unit that activates for\\neach of the nine possible combinations: red truck, red car, red bird, green truck, and\\nSO on. This requires nine different neurons, and each neuron must independently\\nlearn the concept of color and object identity. One way to improve on this situation\\nis to use a distributed representation, with three neurons describing the color and\\nthree neurons describing the object identity. This requires only six neurons total\\ninstead of nine, and the neuron describing redness is able to learn about redness\\n17\\nCHAPTER 1. INTRODUCTION\\nfrom images of cars, trucks and birds, not only from images of one specific category\\nof objects. The concept of distributed representation is central to this book, and\\nwill be described in greater detail in Chapter 15.\\nAnother major accomplishment of the connectionist movement was the suc-\\ncessful use of back-propagation to train deep neural networks with internal repre-\\nsentations and the popularization of the back-propagation algorithm (Rumelhart\\net al., 1986a; LeCun, 1987). This algorithm has waxed and waned in popularity\\nbut as of this writing is currently the dominant approach to training deep models.\\nDuring the 1990s, researchers made important advances in modeling sequences\\nwith neural networks. Hochreiter (1991) and Bengio et al. (1994) identified some\\nof the fundamental mathematical difficulties in modeling long sequences, described\\nin Sec. 10.7. Hochreiter and Schmidhuber (1997) introduced the long short-term\\nmemory or LSTM network to resolve some of these difficulties. Today, the LSTM\\nis widely used for many sequence modeling tasks, including many natural language\\nprocessing tasks at Google.\\nThe second wave of neural networks research lasted until the mid-1990s. Ven-\\ntures based on neural networks and other AI technologies began to make unrealisti-\\ncally ambitious claims while seeking investments. When AI research did not fulfill\\nthese unreasonable expectations, investors were disappointed. Simultaneously,\\nother fields of machine learning made advances. Kernel machines (Boser et al.,\\n1992; Cortes and Vapnik, 1995; Scholkopf et al., 1999) and graphical models (Jor-\\ndan, 1998) both achieved good results on many important tasks. These two factors\\nled to a decline in the popularity of neural networks that lasted until 2007.\\nDuring this time, neural networks continued to obtain impressive performance\\non some tasks (LeCun et al., 1998b; Bengio et al., 2001). The Canadian Institute\\nfor Advanced Research (CIFAR) helped to keep neural networks research alive\\nvia its Neural Computation and Adaptive Perception (NCAP) research initiative.\\nThis program united machine learning research groups led by Geoffrey Hinton\\nat University of Toronto, Yoshua Bengio at University of Montreal, and Yann\\nLeCun at New York University. The CIFAR NCAP research initiative had a\\nmulti-disciplinary nature that also included neuroscientists and experts in human\\nand computer vision.\\nAt this point in time, deep networks were generally believed to be very difficult\\nto train. We now know that algorithms that have existed since the 1980s work\\nquite well, but this was not apparent circa 2006. The issue is perhaps simply that\\nthese algorithms were too computationally costly to allow much experimentation\\nwith the hardware available at the time.\\nThe third wave of neural networks research began with a breakthrough in\\n18\\nCHAPTER 1. INTRODUCTION\\n2006. Geoffrey Hinton showed that a kind of neural network called a deep belief\\nnetwork could be efficiently trained using a strategy called greedy layer-wise\\npretraining (Hinton et al., 2006), which will be described in more detail in Sec.\\n15.1. The other CIFAR-affiliated research groups quickly showed that the same\\nstrategy could be used to train many other kinds of deep networks (Bengio et al.,\\n2007; Ranzato et al., 2007a) and systematically helped to improve generalization\\non test examples. This wave of neural networks research popularized the use of the\\nterm deep learning to emphasize that researchers were now able to train deeper\\nneural networks than had been possible before, and to focus attention on the\\ntheoretical importance of depth (Bengio and LeCun, 2007; Delalleau and Bengio,\\n2011; Pascanu et al., 2014a; Montufar et al., 2014). At this time, deep neural\\nnetworks outperformed competing AI systems based on other machine learning\\ntechnologies as well as hand-designed functionality. This third wave of popularity\\nof neural networks continues to the time of this writing, though the focus of deep\\nlearning research has changed dramatically within the time of this wave. The\\nthird wave began with a focus on new unsupervised learning techniques and the\\nability of deep models to generalize well from small datasets, but today there is\\nmore interest in much older supervised learning algorithms and the ability of deep\\nmodels to leverage large labeled datasets.\\n1.2.2 Increasing Dataset Sizes\\nOne may wonder why deep learning has only recently become recognized as a\\ncrucial technology though the first experiments with artificial neural networks were\\nconducted in the 1950s. Deep learning has been successfully used in commercial\\napplications since the 1990s, but was often regarded as being more of an art than\\na technology and something that only an expert could use, until recently. It is true\\nthat some skill is required to get good performance from a deep learning algorithm.\\nFortunately, the amount of skill required reduces as the amount of training data\\nincreases. The learning algorithms reaching human performance on complex tasks\\ntoday are nearly identical to the learning algorithms that struggled to solve toy\\nproblems in the 1980s, though the models we train with these algorithms have\\nundergone changes that simplify the training of very deep architectures. The most\\nimportant new development is that today we can provide these algorithms with\\nthe resources they need to succeed. Fig. 1.8 shows how the size of benchmark\\ndatasets has increased remarkably over time. This trend is driven by the increasing\\ndigitization of society. As more and more of our activities take place on computers,\\nmore and more of what we do is recorded. As our computers are increasingly\\nnetworked together, it becomes easier to centralize these records and curate them\\n19\\nCHAPTER 1. INTRODUCTION\\ninto a dataset appropriate for machine learning applications. The age of \"Big\\nData\" has made machine learning much easier because the key burden of statistical\\nestimation generalizing well to new data after observing only a small amount\\nof data has been considerably lightened. As of 2016, a rough rule of thumb\\nis that a supervised deep learning algorithm will generally achieve acceptable\\nperformance with around 5,000 labeled examples per category, and will match or\\nexceed human performance when trained with a dataset containing at least 10\\nmillion labeled examples. Working successfully with datasets smaller than this is\\nan important research area, focusing in particular on how we can take advantage\\nof large quantities of unlabeled examples, with unsupervised or semi-supervised\\nlearning.\\n1.2.3 Increasing Model Sizes\\nAnother key reason that neural networks are wildly successful today after enjoying\\ncomparatively little success since the 1980s is that we have the computational\\nresources to run much larger models today. One of the main insights of connection-\\nism is that animals become intelligent when many of their neurons work together.\\nAn individual neuron or small collection of neurons is not particularly useful.\\nBiological neurons are not especially densely connected. As seen in Fig. 1.10,\\nour machine learning models have had a number of connections per neuron that\\nwas within an order of magnitude of even mammalian brains for decades.\\nIn terms of the total number of neurons, neural networks have been astonishingly\\nsmall until quite recently, as shown in Fig. 1.11. Since the introduction of hidden\\nunits, artificial neural networks have doubled in size roughly every 2.4 years. This\\ngrowth is driven by faster computers with larger memory and by the availability\\nof larger datasets. Larger networks are able to achieve higher accuracy on more\\ncomplex tasks. This trend looks set to continue for decades. Unless new technologies\\nallow faster scaling, artificial neural networks will not have the same number of\\nneurons as the human brain until at least the 2050s. Biological neurons may\\nrepresent more complicated functions than current artificial neurons, SO biological\\nneural networks may be even larger than this plot portrays.\\nIn retrospect, it is not particularly surprising that neural networks with fewer\\nneurons than a leech were unable to solve sophisticated artificial intelligence prob-\\nlems. Even today\\'s networks, which we consider quite large from a computational\\nsystems point of view, are smaller than the nervous system of even relatively\\nprimitive vertebrate animals like frogs.\\nThe increase in model size over time, due to the availability of faster CPUs,\\n20\\nCHAPTER 1. INTRODUCTION\\nIncreasing dataset size over time\\n109\\nexamples) 107\\n108 Canadian Hansard\\nWMT Sports-1M\\nImageNet10k\\n106 Publie SVHN\\n(number\\n105 Criminals ILSVRC 2014\\nImageNet\\n104\\nMNIST CIF AR-10\\nsize\\n103\\nDataset\\n102 Rotated T VS C\\nTvs Gvs F\\nIris\\n101\\n10\\n1900 1950 1985 2000 2015\\n\\nFigure 1.8: Dataset sizes have increased greatly over time. In the early 1900s, statisticians\\nstudied datasets using hundreds or thousands of manually compiled measurements (Garson,\\n1900; Gosset, 1908; Anderson, 1935; Fisher, 1936). In the 1950s through 1980s, the pioneers\\nof biologically inspired machine learning often worked with small, synthetic datasets, such\\nas low-resolution bitmaps of letters, that were designed to incur low computational cost and\\ndemonstrate that neural networks were able to learn specific kinds of functions (Widrow\\nand Hoff, 1960; Rumelhart et al., 1986b). In the 1980s and 1990s, machine learning\\nbecame more statistical in nature and began to leverage larger datasets containing tens\\nof thousands of examples such as the MNIST dataset (shown in Fig. 1.9) of scans of\\nhandwritten numbers (LeCun et al. , 1998b). In the first decade of the 2000s, more\\nsophisticated datasets of this same size, such as the CIFAR-10 dataset (Krizhevsky and\\nHinton, 2009) continued to be produced. Toward the end of that decade and throughout\\nthe first half of the 2010s, significantly larger datasets, containing hundreds of thousands\\nto tens of millions of examples, completely changed what was possible with deep learning.\\nThese datasets included the public Street View House Numbers dataset (Netzer et al.,\\n2011), various versions of the ImageNet dataset (Deng et al., 2009, 2010a; Russakovsky\\net al., 2014a), and the Sports-1M dataset (Karpathy et al., 2014). At the top of the\\ngraph, we see that datasets of translated sentences, such as IBM\\'s dataset constructed\\nfrom the Canadian Hansard (Brown et al., 1990) and the WMT 2014 English to French\\ndataset (Schwenk, 2014) are typically far ahead of other dataset sizes.\\n21\\nCHAPTER 1. INTRODUCTION\\n8 9 0 1 2 3 7 8 9 0 1 2 3 6 7 8 6\\n4 2 6 4 7 / 7 9 2 9 3 2 0 5\\n0 7 0 4 7  0 5 0 8\\n3 0 4 / 6\\n7 5 7 9 2 5\\n3 7 7 0\\n/ 2 9\\n3 7 6\\n1 0 6\\n8 7 4 /\\n6 6 7\\n8  5\\n4 7 O\\n4 2 1\\n7\\n/ 8 8 4\\n7 5 7 I\\n9  X 2 3\\n4 3\\n9 9 3 7 7 9 4 4\\n4 7 5 8 / 4 4 / 8 6 6 6 3 7 2 5 9\\nFigure 1.9: Example inputs from the MNIST dataset. The \"NIST\" stands for National\\nInstitute of Standards and Technology, the agency that originally collected this data.\\nThe \"M\" stands for \"modified,\" since the data has been preprocessed for easier use with\\nmachine learning algorithms. The MNIST dataset consists of scans of handwritten digits\\nand associated labels describing which digit 0-9 is contained in each image. This simple\\nclassification problem is one of the simplest and most widely used tests in deep learning\\nresearch. It remains popular despite being quite easy for modern techniques to solve.\\nGeoffrey Hinton has described it as \"the drosophila of machine learning,\" meaning that\\nit allows machine learning researchers to study their algorithms in controlled laboratory\\nconditions, much as biologists often study fruit flies.\\n\\n22\\nCHAPTER 1. INTRODUCTION\\nthe advent of general purpose GPUs (described in Sec. 12.1.2), faster network\\nconnectivity and better software infrastructure for distributed computing, is one of\\nthe most important trends in the history of deep learning. This trend is generally\\nexpected to continue well into the future.\\n1.2.4 Increasing Accuracy, Complexity and Real- World Impact\\nSince the 1980s, deep learning has consistently improved in its ability to provide\\naccurate recognition or prediction. Moreover, deep learning has consistently been\\napplied with success to broader and broader sets of applications.\\nThe earliest deep models were used to recognize individual objects in tightly\\ncropped, extremely small images (Rumelhart et al., 1986a). Since then there has\\nbeen a gradual increase in the size of images neural networks could process. Modern\\nobject recognition networks process rich high-resolution photographs and do not\\nhave a requirement that the photo be cropped near the object to be recognized\\n(Krizhevsky et al., 2012). Similarly, the earliest networks could only recognize\\ntwo kinds of objects (or in some cases, the absence or presence of a single kind of\\nobject), while these modern networks typically recognize at least 1,000 different\\ncategories of objects. The largest contest in object recognition is the ImageNet\\nLarge-Scale Visual Recognition Challenge (ILSVRC) held each year. A dramatic\\nmoment in the meteoric rise of deep learning came when a convolutional network\\nwon this challenge for the first time and by a wide margin, bringing down the\\nstate-of-the-art top-5 error rate from 26.1% to 15.3% (Krizhevsky et al., 2012),\\nmeaning that the convolutional network produces a ranked list of possible categories\\nfor each image and the correct category appeared in the first five entries of this\\nlist for all but 15.3% of the test examples. Since then, these competitions are\\nconsistently won by deep convolutional nets, and as of this writing, advances in\\ndeep learning have brought the latest top-5 error rate in this contest down to 3.6%,\\nas shown in Fig. 1.12.\\nDeep learning has also had a dramatic impact on speech recognition. After\\nimproving throughout the 1990s, the error rates for speech recognition stagnated\\nstarting in about 2000. The introduction of deep learning (Dahl et al., 2010; Deng\\net al., 2010b; Seide et al., 2011; Hinton et al., 2012a) to speech recognition resulted\\nin a sudden drop of error rates, with some error rates cut in half. We will explore\\nthis history in more detail in Sec. 12.3.\\nDeep networks have also had spectacular successes for pedestrian detection and\\nimage segmentation (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al.,\\n2013) and yielded superhuman performance in traffic sign classification (Ciresan\\n23\\nCHAPTER 1. INTRODUCTION\\nNumber of connections per neuron over time\\n10 4\\nneuron\\nHuman\\n3\\nper 10\\nConnections 7 Cat\\n2\\nMouse\\n102\\n5 10\\n1\\n3\\n10 1 Fruit fly\\n1950\\n1985\\n2000\\n2015\\nFigure 1.10: Initially, the number of connections between neurons in artificial neural\\nnetworks was limited by hardware capabilities. Today, the number of connections between\\nneurons is mostly a design consideration. Some artificial neural networks have nearly as\\nmany connections per neuron as a cat, and it is quite common for other neural networks\\nto have as many connections per neuron as smaller mammals like mice. Even the human\\nbrain does not have an exorbitant amount of connections per neuron. Biological neural\\nnetwork sizes from Wikipedia (2015).\\n\\n1. Adaptive linear element (Widrow and Hoff, 1960)\\n2. Neocognitron (Fukushima, 1980)\\n3. GPU-accelerated convolutional network (Chellapilla et al., 2006)\\n4. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)\\n5. Unsupervised convolutional network (Jarrett et al., 2009)\\n6. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)\\n7. Distributed autoencoder (Le et al., 2012)\\n8. Multi-GPU convolutional network (Krizhevsky et al., 2012)\\n9. COTS HPC unsupervised convolutional network (Coates et al., 2013)\\n10. GoogLeNet (Szegedy et al., 2014a)\\n24\\nCHAPTER 1. INTRODUCTION\\net al., 2012.\\nAt the same time that the scale and accuracy of deep networks has increased,\\nSO has the complexity of the tasks that they can solve. Goodfellow et al. (2014d)\\nshowed that neural networks could learn to output an entire sequence of characters\\ntranscribed from an image, rather than just identifying a single object. Previously,\\nit was widely believed that this kind of learning required labeling of the individual\\nelements of the sequence (Gulehre and Bengio, 2013). Recurrent neural networks,\\nsuch as the LSTM sequence model mentioned above, are now used to model\\nrelationships between sequences and other sequences rather than just fixed inputs.\\nThis sequence-to-sequence learning seems to be on the cusp of revolutionizing\\nanother application: machine translation (Sutskever et al., 2014; Bahdanau et al.,\\n2015).\\nThis trend of increasing complexity has been pushed to its logical conclusion\\nwith the introduction of neural Turing machines (Graves et al., 2014a) that learn\\nto read from memory cells and write arbitrary content to memory cells. Such\\nneural networks can learn simple programs from examples of desired behavior. For\\nexample, they can learn to sort lists of numbers given examples of scrambled and\\nsorted sequences. This self-programming technology is in its infancy, but in the\\nfuture could in principle be applied to nearly any task.\\nAnother crowning achievement of deep learning is its extension to the domain\\nof reinforcement learning. In the context of reinforcement learning, an autonomous\\nagent must learn to perform a task by trial and error, without any guidance from\\nthe human operator. DeepMind demonstrated that a reinforcement learning system\\nbased on deep learning is capable of learning to play Atari video games, reaching\\nhuman-level performance on many tasks (Mnih et al., 2015). Deep learning has\\nalso significantly improved the performance of reinforcement learning for robotics\\n(Finn et al., 2015).\\nMany of these applications of deep learning are highly profitable. Deep learning\\nis now used by many top technology companies including Google, Microsoft,\\nFacebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA and NEC.\\nAdvances in deep learning have also depended heavily on advances in software\\ninfrastructure. Software libraries such as Theano (Bergstra et al., 2010; Bastien\\net al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b),\\nDistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015), and\\nTensorFlow (Abadi et al., 2015) have all supported important research projects or\\ncommercial products.\\nDeep learning has also made contributions back to other sciences. Modern\\nconvolutional networks for object recognition provide a model of visual processing\\n25\\nCHAPTER 1. INTRODUCTION\\nthat neuroscientists can study (DiCarlo, 2013). Deep learning also provides useful\\ntools for processing massive amounts of data and making useful predictions in\\nscientific fields. It has been successfully used to predict how molecules will interact\\nin order to help pharmaceutical companies design new drugs (Dahl et al., 2014),\\nto search for subatomic particles (Baldi et al., 2014), and to automatically parse\\nmicroscope images used to construct a 3-D map of the human brain (Knowles-\\nBarley et al., 2014). We expect deep learning to appear in more and more scientific\\nfields in the future.\\nIn summary, deep learning is an approach to machine learning that has drawn\\nheavily on our knowledge of the human brain, statistics and applied math as it\\ndeveloped over the past several decades. In recent years, it has seen tremendous\\ngrowth in its popularity and usefulness, due in large part to more powerful com-\\nputers, larger datasets and techniques to train deeper networks. The years ahead\\nare full of challenges and opportunities to improve deep learning even further and\\nbring it to new frontiers.\\n26\\nCHAPTER 1. INTRODUCTION\\nIncreasing neural network size over time\\nscale)\\n1011\\nHuman\\n1010\\n17 20\\n(logarithmic\\n109 16 19\\nOctopus\\n108 14\\n107 Frog\\n106 8\\nBee\\n105 3 \\nAnt\\nneurons\\n104\\n103\\nLeech\\n13\\n102\\n2\\nof 101 1 12\\n15 Roundworm\\n100 9\\nNumber\\n10\\n10-1 7\\n4\\n10-2\\nSponge\\n1950 1985 2000 2015 2056\\n\\nFigure 1.11: Since the introduction of hidden units, artificial neural networks have doubled\\nin size roughly every 2.4 years. Biological neural network sizes from Wikipedia (2015).\\n1. Perceptron (Rosenblatt, 1958, 1962)\\n2. Adaptive linear element (Widrow and Hoff, 1960)\\n3. Neocognitron (Fukushima, 1980)\\n4. Early back-propagation network (Rumelhart et al., 1986b)\\n5. Recurrent neural network for speech recognition (Robinson and Fallside, 1991)\\n6. Multilayer perceptron for speech recognition (Bengio et al., 1991)\\n7. Mean field sigmoid belief network (Saul et al., 1996)\\n8. LeNet-5 (LeCun et al., 1998b)\\n9. Echo state network (Jaeger and Haas, 2004)\\n10. Deep belief network (Hinton et al., 2006)\\n11. GPU-accelerated convolutional network (Chellapilla et al., 2006)\\n12. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)\\n13. GPU-accelerated deep belief network (Raina et al., 2009)\\n14. Unsupervised convolutional network (Jarrett et al., 2009)\\n15. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)\\n16. OMP-1 network (Coates and Ng, 2011)\\n17. Distributed autoencoder (Le et al., 2012)\\n18. Multi-GPU convolutional network (Krizhevsky et al., 2012)\\n19. COTS HPC unsupervised convolutional network (Coates et al., 2013)\\n20. GoogLeNet (Szegedy et al., 2014a)\\n27\\nCHAPTER 1. INTRODUCTION\\nrate 0.30\\nDecreasing error rate over time\\nerror 0.25\\nclassification\\n0.20\\n0.15\\n0.10\\nILSVRC\\n0.05\\n0.00\\n2010\\n2011\\n2012\\n2013\\n2014\\n2015\\nFigure 1.12: Since deep networks reached the scale necessary to compete in the ImageNet\\nLarge Scale Visual Recognition Challenge, they have consistently won the competition\\nevery year, and yielded lower and lower error rates each time. Data from Russakovsky\\net al. (2014b) and He et al. (2015).\\n28\\nPart I\\nApplied Math and Machine\\nLearning Basics\\n29\\nThis part of the book introduces the basic mathematical concepts needed to\\nunderstand deep learning. We begin with general ideas from applied math that\\nallow us to define functions of many variables, find the highest and lowest points\\non these functions and quantify degrees of belief.\\nNext, we describe the fundamental goals of machine learning. We describe how\\nto accomplish these goals by specifying a model that represents certain beliefs,\\ndesigning a cost function that measures how well those beliefs correspond with\\nreality and using a training algorithm to minimize that cost function.\\nThis elementary framework is the basis for a broad variety of machine learning\\nalgorithms, including approaches to machine learning that are not deep. In the\\nsubsequent parts of the book, we develop deep learning algorithms within this\\nframework.\\n30'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os \n",
    "\n",
    "def get_element_json_from_pdf(file_filename):\n",
    "    UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "    url = \"https://api.upstage.ai/v1/document-ai/layout-analyzer\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {UPSTAGE_API_KEY}\"}\n",
    "    files = {\"document\": open(file_filename, \"rb\")}\n",
    "    response = requests.post(url, headers=headers, files=files)\n",
    "    return response.json()\n",
    "\n",
    "r = get_element_json_from_pdf(\"sample_data/dl15.pdf\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diagrammatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
